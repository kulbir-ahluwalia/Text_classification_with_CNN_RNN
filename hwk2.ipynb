{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSy-sfxOsclS"
   },
   "source": [
    "# CS 447 Homework 2 $-$ Text Classification with Neural Networks\n",
    "In this homework, you will build machine learning models to detect the sentiment of movie reviews using the IMDb movie reviews dataset. Specifically, you will implement classifiers based on Convolutional Neural Networks (CNN's) and Recurrent Neural Networks (RNN's).\n",
    "\n",
    "In addition to the Pytorch tutorial we have provided on Coursera, we highly recommend that you take a look at the PyTorch tutorials before starting this assignment:\n",
    "<ul>\n",
    "<li><a href=\"https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html</a>\n",
    "<li><a href=\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\">https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</a>\n",
    "<li><a href=\"https://github.com/yunjey/pytorch-tutorial\">https://github.com/yunjey/pytorch-tutorial</a>\n",
    "</ul>\n",
    "\n",
    "<font color='green'>While you work, we suggest that you keep your hardware accelerator set to \"CPU\" (the default for Colab). However, when you have finished debugging and are ready to train your models, you should select \"GPU\" as your runtime type. This will speed up the training of your models. You can find this by going to <TT>Runtime > Change Runtime Type</TT> and select \"GPU\" from the dropdown menu.</font>\n",
    "\n",
    "As usual, you should not import any other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EyCOvTRQ1nb-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHbJ1-aDsWCG"
   },
   "source": [
    "# Step 1: Download the Data\n",
    "First we will download the dataset using [torchtext](https://torchtext.readthedocs.io/en/latest/index.html), which is a package that supports NLP for PyTorch. \n",
    "\n",
    "Unfortunately, you have to install the <TT>torchdata</TT> package on the Colab machine in order to access the data. To do this, run the cell below (you may need to click the \"Restart Runtime\" button when it finishes). You will have to do this every time you return to work on the homework.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rT4n4QzHAYe_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (0.4.1)\r\n",
      "Requirement already satisfied: requests in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (2.28.1)\r\n",
      "Requirement already satisfied: torch==1.12.1 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (1.12.1)\r\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (1.26.11)\r\n",
      "Requirement already satisfied: portalocker>=2.0.0 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (2.5.1)\r\n",
      "Requirement already satisfied: typing_extensions in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torch==1.12.1->torchdata) (4.3.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from requests->torchdata) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from requests->torchdata) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from requests->torchdata) (2022.9.24)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMVBA0ijAUgt"
   },
   "source": [
    "The following cell will get you `train_data` and `test_data`. It also does some basic tokenization.\n",
    "\n",
    "*   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n",
    "*   To access the label for the *i*th example, use `train_data[i][0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dfX3bNby8FYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Train Examples: 20000\n",
      "Num. Test Examples: 5000\n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Zentropa', 'has', 'much', 'in', 'common', 'with', 'The', 'Third', 'Man', ',', 'another', 'noir-like', 'film', 'set', 'among', 'the', 'rubble', 'of', 'postwar', 'Europe', '.', 'Like', 'TTM', ',', 'there', 'is', 'much', 'inventive', 'camera', 'work', '.', 'There', 'is', 'an', 'innocent', 'American', 'who', 'gets', 'emotionally', 'involved', 'with', 'a', 'woman', 'he', \"doesn't\", 'really', 'understand', ',', 'and', 'whose', 'naivety', 'is', 'all', 'the', 'more', 'striking', 'in', 'contrast', 'with', 'the', 'natives.<br', '/><br', '/>But', \"I'd\", 'have', 'to', 'say', 'that', 'The', 'Third', 'Man', 'has', 'a', 'more', 'well-crafted', 'storyline', '.', 'Zentropa', 'is', 'a', 'bit', 'disjointed', 'in', 'this', 'respect', '.', 'Perhaps', 'this', 'is', 'intentional', ':', 'it', 'is', 'presented', 'as', 'a', 'dream/nightmare', ',', 'and', 'making', 'it', 'too', 'coherent', 'would', 'spoil', 'the', 'effect', '.', '<br', '/><br', '/>This', 'movie', 'is', 'unrelentingly', 'grim--\"noir', '\"', 'in', 'more', 'than', 'one', 'sense', ';', 'one', 'never', 'sees', 'the', 'sun', 'shine', '.', 'Grim', ',', 'but', 'intriguing', ',', 'and', 'frightening', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Zentropa', 'is', 'the', 'most', 'original', 'movie', \"I've\", 'seen', 'in', 'years', '.', 'If', 'you', 'like', 'unique', 'thrillers', 'that', 'are', 'influenced', 'by', 'film', 'noir', ',', 'then', 'this', 'is', 'just', 'the', 'right', 'cure', 'for', 'all', 'of', 'those', 'Hollywood', 'summer', 'blockbusters', 'clogging', 'the', 'theaters', 'these', 'days', '.', 'Von', \"Trier's\", 'follow-ups', 'like', 'Breaking', 'the', 'Waves', 'have', 'gotten', 'more', 'acclaim', ',', 'but', 'this', 'is', 'really', 'his', 'best', 'work', '.', 'It', 'is', 'flashy', 'without', 'being', 'distracting', 'and', 'offers', 'the', 'perfect', 'combination', 'of', 'suspense', 'and', 'dark', 'humor', '.', \"It's\", 'too', 'bad', 'he', 'decided', 'handheld', 'cameras', 'were', 'the', 'wave', 'of', 'the', 'future', '.', \"It's\", 'hard', 'to', 'say', 'who', 'talked', 'him', 'away', 'from', 'the', 'style', 'he', 'exhibits', 'here', ',', 'but', \"it's\", \"everyone's\", 'loss', 'that', 'he', 'went', 'into', 'his', 'heavily', 'theoretical', 'dogma', 'direction', 'instead', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Lars', 'Von', 'Trier', 'is', 'never', 'backward', 'in', 'trying', 'out', 'new', 'techniques', '.', 'Some', 'of', 'them', 'are', 'very', 'original', 'while', 'others', 'are', 'best', 'forgotten.<br', '/><br', '/>He', 'depicts', 'postwar', 'Germany', 'as', 'a', 'nightmarish', 'train', 'journey', '.', 'With', 'so', 'many', 'cities', 'lying', 'in', 'ruins', ',', 'Leo', 'Kessler', 'a', 'young', 'American', 'of', 'German', 'descent', 'feels', 'obliged', 'to', 'help', 'in', 'their', 'restoration', '.', 'It', 'is', 'not', 'a', 'simple', 'task', 'as', 'he', 'quickly', 'finds', 'out.<br', '/><br', '/>His', 'uncle', 'finds', 'him', 'a', 'job', 'as', 'a', 'night', 'conductor', 'on', 'the', 'Zentropa', 'Railway', 'Line', '.', 'His', 'job', 'is', 'to', 'attend', 'to', 'the', 'needs', 'of', 'the', 'passengers', '.', 'When', 'the', 'shoes', 'are', 'polished', 'a', 'chalk', 'mark', 'is', 'made', 'on', 'the', 'soles', '.', 'A', 'terrible', 'argument', 'ensues', 'when', 'a', \"passenger's\", 'shoes', 'are', 'not', 'chalked', 'despite', 'the', 'fact', 'they', 'have', 'been', 'polished', '.', 'There', 'are', 'many', 'allusions', 'to', 'the', 'German', 'fanaticism', 'of', 'adherence', 'to', 'such', 'stupid', 'details.<br', '/><br', '/>The', 'railway', 'journey', 'is', 'like', 'an', 'allegory', 'representing', \"man's\", 'procession', 'through', 'life', 'with', 'all', 'its', 'trials', 'and', 'tribulations', '.', 'In', 'one', 'sequence', 'Leo', 'dashes', 'through', 'the', 'back', 'carriages', 'to', 'discover', 'them', 'filled', 'with', 'half-starved', 'bodies', 'appearing', 'to', 'have', 'just', 'escaped', 'from', 'Auschwitz', '', '.', 'These', 'images', ',', 'horrible', 'as', 'they', 'are', ',', 'are', 'fleeting', 'as', 'in', 'a', 'dream', ',', 'each', 'with', 'its', 'own', 'terrible', 'impact', 'yet', 'unconnected.<br', '/><br', '/>At', 'a', 'station', 'called', 'Urmitz', 'Leo', 'jumps', 'from', 'the', 'train', 'with', 'a', 'parceled', 'bomb', '.', 'In', 'view', 'of', 'many', 'by-standers', 'he', 'connects', 'the', 'bomb', 'to', 'the', 'underside', 'of', 'a', 'carriage', '.', 'He', 'returns', 'to', 'his', 'cabin', 'and', 'makes', 'a', 'connection', 'to', 'a', 'time', 'clock', '.', 'Later', 'he', 'jumps', 'from', 'the', 'train', '(', 'at', 'high', 'speed', ')', 'and', 'lies', 'in', 'the', 'cool', 'grass', 'on', 'a', 'river', 'bank', '.', 'Looking', 'at', 'the', 'stars', 'above', 'he', 'decides', 'that', 'his', 'job', 'is', 'to', 'build', 'and', 'not', 'destroy', '.', 'Subsequently', 'as', 'he', 'sees', 'the', 'train', 'approaching', 'a', 'giant', 'bridge', 'he', 'runs', 'at', 'breakneck', 'speed', 'to', 'board', 'the', 'train', 'and', 'stop', 'the', 'clock', '.', 'If', 'you', 'care', 'to', 'analyse', 'the', 'situation', 'it', 'is', 'a', 'completely', 'impossible', 'task', '.', 'Quite', 'ridiculous', 'in', 'fact', '.', 'It', 'could', 'only', 'happen', 'in', 'a', 'dream.<br', '/><br', \"/>It's\", 'strange', 'how', 'one', 'remembers', 'little', 'details', 'such', 'as', 'a', 'row', 'of', 'cups', 'hanging', 'on', 'hooks', 'and', 'rattling', 'away', 'with', 'the', 'swaying', 'of', 'the', 'train.<br', '/><br', '/>Despite', 'the', 'fact', 'that', 'this', 'film', 'is', 'widely', 'acclaimed', ',', 'I', 'prefer', 'Lars', 'Von', \"Trier's\", 'later', 'films', '(', 'Breaking', 'the', 'Waves', 'and', 'The', 'Idiots)', '.', 'The', 'bomb', 'scene', 'described', 'above', 'really', 'put', 'me', 'off', '.', 'Perhaps', \"I'm\", 'a', 'realist', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['*Contains', 'spoilers', 'due', 'to', 'me', 'having', 'to', 'describe', 'some', 'film', 'techniques', ',', 'so', 'read', 'at', 'your', 'own', 'risk!*<br', '/><br', '/>I', 'loved', 'this', 'film', '.', 'The', 'use', 'of', 'tinting', 'in', 'some', 'of', 'the', 'scenes', 'makes', 'it', 'seem', 'like', 'an', 'old', 'photograph', 'come', 'to', 'life', '.', 'I', 'also', 'enjoyed', 'the', 'projection', 'of', 'people', 'on', 'a', 'back', 'screen', '.', 'For', 'instance', ',', 'in', 'one', 'scene', ',', 'Leopold', 'calls', 'his', 'wife', 'and', 'she', 'is', 'projected', 'behind', 'him', 'rather', 'than', 'in', 'a', 'typical', 'split', 'screen', '.', 'Her', 'face', 'is', 'huge', 'in', 'the', 'back', 'and', \"Leo's\", 'is', 'in', 'the', 'foreground.<br', '/><br', '/>One', 'of', 'the', 'best', 'uses', 'of', 'this', 'is', 'when', 'the', 'young', 'boys', 'kill', 'the', 'Ravensteins', 'on', 'the', 'train', ',', 'a', 'scene', 'shot', 'in', 'an', 'almost', 'political', 'poster', 'style', ',', 'with', 'facial', 'close', 'ups', '.', 'It', 'reminded', 'me', 'of', 'Battleship', 'Potemkin', ',', 'that', 'intense', 'constant', 'style', 'coupled', 'with', 'the', 'spray', 'of', 'red', 'to', 'convey', 'tons', 'of', 'horror', 'without', 'much', 'gore', '.', 'Same', 'with', 'the', 'scene', 'when', 'Katharina', 'finds', 'her', 'father', 'dead', 'in', 'the', 'bathtub...you', 'can', 'only', 'see', 'the', 'red', 'water', 'on', 'the', 'side', '.', 'It', 'is', 'one', 'of', 'the', 'things', 'I', 'love', 'about', 'Von', 'Trier', ',', 'his', 'understatement', 'of', 'horror', ',', 'which', 'ends', 'up', 'making', 'it', 'all', 'the', 'more', 'creepy.<br', '/><br', '/>The', 'use', 'of', 'text', 'in', 'the', 'film', 'was', 'unique', ',', 'like', 'when', \"Leo's\", 'character', 'is', 'pushed', 'by', 'the', 'word', ',', '\"', 'Werewolf.', '\"', 'I', 'have', 'never', 'seen', 'anything', 'like', 'that', 'in', 'a', 'film.<br', '/><br', '/>The', 'use', 'of', 'black', 'comedy', 'in', 'this', 'film', 'was', 'well', 'done', '.', 'Ernst-Hugo', 'Järegård', 'is', 'great', 'as', \"Leo's\", 'uncle', '.', 'It', 'brings', 'up', 'the', 'snickers', 'I', 'got', 'from', 'his', 'role', 'in', 'the', 'Kingdom', '(', 'Riget.', ')', 'This', 'humor', 'makes', 'the', 'plotline', 'of', 'absurd', 'anal', 'retentiveness', 'of', 'train', 'conductors', 'against', 'the', 'terrible', 'backdrop', 'of', 'WW2', 'and', 'all', 'the', 'chaos', ',', 'easier', 'to', 'take', '.', 'It', 'reminds', 'me', 'of', 'Riget', 'in', 'the', 'way', 'the', 'hospital', 'administrator', 'is', 'trying', 'to', 'maintain', 'a', 'normalcy', 'at', 'the', 'end', 'of', 'part', 'one', 'when', 'everything', 'is', 'going', 'crazy', '.', 'It', 'shows', 'that', 'some', 'people', 'are', 'truly', 'oblivious', 'to', 'the', 'awful', 'things', 'happening', 'around', 'them', '.', 'Yet', 'some', 'people', ',', 'like', 'Leo', ',', 'are', 'tuned', 'in', ',', 'but', 'do', 'nothing', 'positive', 'about', 'it.<br', '/><br', '/>The', 'voice', 'over', ',', 'done', 'expertly', 'well', 'by', 'Max', 'von', 'Sydow', ',', 'is', 'amusing', 'too', '.', 'It', 'draws', 'you', 'into', 'the', 'story', 'and', 'makes', 'you', 'jump', 'into', \"Leo's\", 'head', ',', 'which', 'at', 'times', 'is', 'a', 'scary', 'place', 'to', 'be.<br', '/><br', '/>The', 'movie', 'brings', 'up', 'the', 'point', 'that', 'one', 'is', 'a', 'coward', 'if', 'they', \"don't\", 'choose', 'a', 'side', '.', 'I', 'see', 'the', 'same', 'idea', 'used', 'in', 'Dancer', 'in', 'the', 'Dark', ',', 'where', \"Bjork's\", 'character', \"doesn't\", 'speak', 'up', 'for', 'herself', 'and', 'ends', 'up', 'being', 'her', 'own', 'destruction', '.', 'Actually', ',', 'at', 'one', 'time', ',', 'Von', 'Trier', 'seemed', 'anti-woman', 'to', 'me', ',', 'by', 'making', 'Breaking', 'the', 'Waves', 'and', 'Dancer', ',', 'but', 'now', 'I', 'know', 'his', 'male', 'characters', \"don't\", 'fare', 'well', 'either', '!', 'I', 'found', 'myself', 'at', 'the', 'same', 'place', 'during', 'the', 'end', 'of', 'Dancer', ',', 'when', 'you', 'seriously', 'want', 'the', 'main', 'character', 'to', 'rethink', 'their', 'actions', ',', 'but', 'of', 'course', ',', 'they', 'never', 'do', '!'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['That', 'was', 'the', 'first', 'thing', 'that', 'sprang', 'to', 'mind', 'as', 'I', 'watched', 'the', 'closing', 'credits', 'to', 'Europa', 'make', 'there', 'was', 'across', 'the', 'screen', ',', 'never', 'in', 'my', 'entire', 'life', 'have', 'I', 'seen', 'a', 'film', 'of', 'such', 'technical', 'genius', ',', 'the', 'visuals', 'of', 'Europa', 'are', 'so', 'impressive', 'that', 'any', 'film', 'I', 'watch', 'in', \"it's\", 'wake', 'will', 'only', 'pale', 'in', 'comparison', ',', 'forget', 'your', 'Michael', 'Bay', ',', 'Ridley', 'Scott', 'slick', 'Hollywood', 'cinematography', ',', 'Europa', 'has', 'more', 'ethereal', 'beauty', 'than', 'anything', 'those', 'two', 'could', 'conjure', 'up', 'in', 'a', 'million', 'years', '.', 'Now', \"I'd\", 'be', 'the', 'first', 'to', 'hail', 'Lars', 'von', 'Trier', 'a', 'genius', 'just', 'off', 'the', 'back', 'of', 'his', 'films', 'Breaking', 'the', 'Waves', 'and', 'Dancer', 'in', 'the', 'Dark', ',', 'but', 'this', 'is', 'stupid', ',', 'the', 'fact', 'that', 'Europa', 'has', 'gone', 'un-noticed', 'by', 'film', 'experts', 'for', 'so', 'long', 'is', 'a', 'crime', 'against', 'cinema', ',', 'whilst', 'overrated', 'rubbish', 'like', 'Crouching', 'Tiger', ',', 'Hidden', 'Dragon', 'and', 'Life', 'is', 'Beautiful', 'clean', 'up', 'at', 'the', 'academy', 'awards', '(', 'but', 'what', 'do', 'the', 'know', ')', 'Europa', 'has', 'been', 'hidden', 'away', ',', 'absent', 'form', 'video', 'stores', 'and', '(', 'until', 'recently', ')', 'any', 'British', 'TV', 'channels', '.', '<br', '/><br', '/>The', 'visuals', 'in', 'Europa', 'are', 'not', 'MTV', 'gloss', ';', \"it's\", 'not', 'a', 'case', 'of', 'style', 'over', 'substance', ',', 'its', 'more', 'a', 'case', 'of', 'substance', 'dictating', 'style', '.', 'Much', 'like', 'his', 'first', 'film', 'The', 'Element', 'of', 'Crime', ',', 'von', 'Trier', 'uses', 'the', 'perspective', 'of', 'the', 'main', 'character', 'to', 'draw', 'us', 'into', 'his', 'world', ',', 'and', 'much', 'like', 'Element', ',', 'the', 'film', 'begins', 'with', 'the', 'main', 'character', '(', 'or', 'in', 'the', 'case', 'of', 'Europa', ',', 'we', 'the', 'audience', ')', 'being', 'hypnotized', '.', 'As', 'we', 'move', 'down', 'the', 'tracks', ',', 'the', 'voice', 'of', 'the', 'Narrator', '(', 'Max', 'von', 'Sydow', ')', 'counts', 'us', 'down', 'into', 'a', 'deep', 'sleep', ',', 'until', 'we', 'awake', 'in', 'Europa', '.', 'This', 'allows', 'von', 'Trier', 'and', 'his', 'three', 'cinematographers', 'to', 'pay', 'with', 'the', 'conventions', 'of', 'time', 'and', 'imagery', ',', 'there', 'are', 'many', 'scenes', 'in', 'Europa', 'when', 'a', 'character', 'in', 'the', 'background', ',', 'who', 'is', 'in', 'black', 'and', 'white', ',', 'will', 'interact', 'with', 'a', 'person', 'in', 'the', 'foreground', 'who', 'will', 'be', 'colour', ',', 'von', 'Trier', 'is', 'trying', 'to', 'show', 'us', 'how', 'much', 'precedence', 'the', 'coloured', 'item', 'or', 'person', 'has', 'over', 'the', 'plot', ',', 'for', 'instance', ',', \"it's\", 'no', 'surprise', 'that', 'the', 'first', 'shot', 'of', 'Leopold', 'Kessler', '(', 'Jean-marc', 'Barr', ')', 'is', 'in', 'colour', ',', 'since', 'he', 'is', 'the', 'only', 'character', \"who's\", 'actions', 'have', 'superiority', 'over', 'the', 'film', '.', '<br', '/><br', '/>The', 'performances', 'are', 'good', ',', 'they', 'may', 'not', 'be', 'on', 'par', 'with', 'performances', 'in', 'later', 'von', 'Trier', 'films', ',', 'but', \"that's\", 'just', 'because', 'the', 'images', 'are', 'sometimes', 'so', 'distracting', 'that', 'you', \"don't\", 'really', 'pick', 'up', 'on', 'them', 'the', 'first', 'time', 'round', '.', 'But', 'I', 'would', 'like', 'to', 'point', 'out', 'the', 'fantastic', 'performance', 'of', 'Jean-Marc', 'Barr', 'in', 'the', 'lead', 'role', ',', 'whose', 'blind', 'idealism', 'is', 'slowly', 'warn', 'down', 'by', 'the', 'two', 'opposing', 'sides', ',', 'until', 'he', 'erupts', 'in', 'the', 'films', 'final', 'act', '.', 'Again', ',', 'muck', 'like', 'The', 'Element', 'of', 'Crime', ',', 'the', 'film', 'ends', 'with', 'our', 'hero', 'unable', 'to', 'wake', 'up', 'from', 'his', 'nightmare', 'state', ',', 'left', 'in', 'this', 'terrible', 'place', ',', 'with', 'only', 'the', 'continuing', 'narration', 'of', 'von', 'Sydow', 'to', 'seal', 'his', 'fate', '.', 'Europa', 'is', 'a', 'tremendous', 'film', ',', 'and', 'I', 'cant', 'help', 'thinking', 'what', 'a', 'shame', 'that', 'von', 'Trier', 'has', 'abandoned', 'this', 'way', 'of', 'filming', ',', 'since', 'he', 'was', 'clearly', 'one', 'of', 'the', 'most', 'talented', 'visual', 'directors', 'working', 'at', 'that', 'time', ',', 'Europa', ',', 'much', 'like', 'the', 'rest', 'of', 'his', 'cinematic', 'cannon', 'is', 'filled', 'with', 'a', 'wealth', 'of', 'iconic', 'scenes', '.', 'His', 'dedication', 'to', 'composition', 'and', 'mise-en-scene', 'is', 'unrivalled', ',', 'not', 'to', 'mention', 'his', 'use', 'of', 'sound', 'and', 'production', 'design', '.', 'But', 'since', 'his', 'no-frills', 'melodramas', 'turned', 'out', 'to', 'be', 'Breaking', 'the', 'Waves', 'and', 'Dancer', 'in', 'the', 'Dark', 'then', 'who', 'can', 'argue', ',', 'but', 'it', 'does', 'seems', 'like', 'a', 'waste', 'of', 'an', 'imaginative', 'talent', '.', '10/10'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['I', 'had', 'started', 'to', 'lose', 'my', 'faith', 'in', 'films', 'of', 'recent', 'being', 'inundated', 'with', 'the', 'typical', 'Genre', 'Hollywood', 'film', '.', 'Story', 'lines', 'fail', ',', 'and', 'camera', 'work', 'is', 'merely', 'copied', 'from', 'the', 'last', 'film', 'of', 'similiar', 'taste', '.', 'But', ',', 'then', 'I', 'saw', 'Zentropa', '(', 'Europa', ')', 'and', 'my', 'faith', 'was', 'renewed', '.', 'Not', 'only', 'is', 'the', 'metaphorical', 'storyline', 'enthralling', 'but', 'the', 'use', 'of', 'color', 'and', 'black', 'and', 'white', 'is', 'visually', 'stimulating', '.', 'The', 'narrator', '(', 'Max', 'Von', 'Sydow', ')', 'takes', 'you', 'through', 'a', 'spellbounding', 'journey', 'every', 'step', 'of', 'the', 'way', 'and', 'engrosses', 'you', 'into', 'Europa', '1945', '.', 'We', 'have', 'all', 'seen', 'death', 'put', 'on', 'screen', 'in', 'a', 'hundred', 'thousand', 'ways', 'but', 'the', 'beauty', 'of', 'this', 'film', 'is', 'how', 'it', 'takes', 'you', 'through', 'every', 'slow-moving', 'moment', 'that', 'leads', 'you', 'to', 'death', '.', 'Unlike', 'many', 'films', 'it', \"doesn't\", 'cut', 'after', 'one', 'second', 'of', 'showing', '(', 'for', 'example', ')', 'a', 'knife', 'but', 'forces', 'you', 'to', 'watch', 'the', 'devastating', 'yet', 'sensuous', 'beauty', 'of', 'a', \"man's\", 'final', 'moments', '.', 'I', 'think', 'we', 'can', 'all', 'take', 'something', 'different', 'away', 'from', 'what', 'this', 'movie', 'is', 'trying', 'to', 'say', 'but', 'it', 'is', 'definitely', 'worth', 'taking', 'the', 'time', 'to', 'find', 'out', 'what', 'it', 'all', 'really', 'means', '.', 'I', 'would', 'love', 'to', 'talk', 'more', 'in', 'depth', 'about', 'the', 'film', 'for', 'any', 'one', 'who', 'wishes', 'to', 'send', 'me', 'an', 'email', '.', 'Enjoy', 'it', '!'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Critics', 'need', 'to', 'review', 'what', 'they', 'class', 'as', 'a', 'quality', 'movie', '.', 'I', 'think', 'the', 'critics', 'have', 'seen', 'too', 'many', 'actions', 'films', 'and', 'have', 'succumbed', 'to', 'the', 'Matrix', 'style', 'of', 'films', '.', 'Europa', 'is', 'a', 'breath', 'of', 'fresh', 'air', ',', 'a', 'film', 'with', 'so', 'many', 'layers', 'that', 'one', 'viewing', 'is', 'not', 'enough', 'to', 'understand', 'or', 'appreciate', 'this', 'outstanding', 'film', '.', 'Lars', 'von', 'Trier', 'shows', 'that', 'old', 'styles', 'of', 'filming', 'can', 'produce', 'marvellous', 'cinema', 'and', 'build', 'drama', 'and', 'tension', '.', 'The', 'back', 'projection', 'effect', 'he', 'uses', 'during', 'the', 'film', 'arouses', 'and', 'enhances', 'the', 'characters', ',', 'and', 'the', 'focus', 'of', 'the', 'conversation', 'they', 'are', 'having', '.', 'Other', 'effects', 'he', 'uses', 'such', 'as', 'the', 'colour', 'and', 'black', 'and', 'white', 'in', 'one', 'scene', 'much', 'like', 'Hitchcock', 'and', 'the', 'girl', 'with', 'the', 'red', 'coat', 'grabs', 'attention', 'and', 'enhances', 'the', 'drama', 'and', 'meaning', 'of', 'the', 'scene', '.', 'The', 'commentary', 'is', 'superb', 'and', 'has', 'a', 'hypnotic', 'effect', ',', 'again', 'maintaining', 'the', 'focus', 'on', 'the', 'central', 'characters', 'in', 'the', 'scene', 'and', 'there', 'actions.<br', '/><br', '/>I', 'could', 'talk', 'about', 'the', 'effects', 'more', 'but', 'I', 'think', 'you', 'all', 'would', 'agree', 'they', 'push', 'this', 'film', 'into', 'a', 'category', 'of', 'its', 'own', ',', 'and', 'really', 'heighten', 'the', 'drama', 'of', 'the', 'film', '.', 'A', 'film', 'to', 'buy', 'if', 'you', \"don't\", 'own', 'already', 'and', 'one', 'to', 'see', 'if', 'you', 'have', 'not.<br', '/><br', '/>10/10', \"Don't\", 'miss', 'this', 'artistic', 'noir', 'film', 'from', 'one', 'of', 'the', 'great', 'film', 'directors', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['It', 'is', 'not', 'every', \"film's\", 'job', 'to', 'stimulate', 'you', 'superficially', '.', 'I', 'will', 'take', 'an', 'ambitious', 'failure', 'over', 'a', 'mass-market', 'hit', 'any', 'day', '.', 'While', 'this', 'really', \"can't\", 'be', 'described', 'as', 'a', 'failure', ',', 'the', 'sum', 'of', 'its', 'parts', 'remains', 'ambiguous', '.', 'That', 'indecipherable', 'quality', 'tantalizes', 'me', 'into', 'watching', 'it', 'again', 'and', 'again', '.', 'This', 'is', 'a', 'challenging', ',', 'provocative', 'movie', 'that', 'does', 'not', 'wrap', 'things', 'up', 'neatly', '.', 'The', 'problem', 'with', 'the', 'movie', 'is', 'in', 'its', 'structure', '.', 'Its', 'inpenetrable', 'plot', 'seems', 'to', 'be', 'winding', 'up', ',', 'just', 'as', 'a', 'second', 'ending', 'is', 'tacked', 'on', '.', 'Though', 'everything', 'is', 'technically', 'dazzling', ',', 'the', 'movie', 'is', 'exactly', 'too', 'long', 'by', 'that', 'unit', '.', 'The', 'long-delayed', 'climax', 'of', \"Leo's\", 'awakening', 'comes', 'about', '20', 'minutes', 'late.<br', '/><br', '/>Great', 'cinematography', 'often', 'comes', 'at', 'the', 'expense', 'of', 'a', 'decent', 'script', ',', 'but', 'here', 'the', 'innovative', 'camera', 'technique', 'offers', 'a', 'wealth', 'of', 'visual', 'ideas', '.', 'The', 'compositing', 'artifice', 'is', 'provocative', 'and', 'engaging', ';', 'A', 'character', 'is', 'rear-projected', 'but', 'his', 'own', 'hand', 'in', 'the', 'foreground', \"isn't\", '.', 'The', 'world', 'depicted', 'is', 'deliberate', ',', 'treacherous', 'and', 'absurd', '.', 'Keep', 'your', 'eyes', 'peeled', 'for', 'a', 'memorable', ',', 'technically', 'astonishing', 'assassination', 'that', 'will', 'make', 'your', 'jaw', 'drop.<br', '/><br', '/>The', 'compositions', 'are', 'stunning', '.', 'Whomever', 'chose', 'to', 'release', 'the', '(', 'out', 'of', 'print', ')', 'videotape', 'in', 'the', 'pan', '&', 'scan', 'format', 'must', 'have', 'never', 'seen', 'it', '.', 'Where', 'is', 'the', 'DVD?<br', '/><br', '/>It', 'is', 'unfathomable', 'how', 'anyone', 'could', 'give', 'this', 'much', 'originality', 'a', 'bad', 'review', '.', 'You', 'should', 'see', 'it', 'at', 'least', 'once', '.', 'You', 'get', 'the', 'sense', 'that', 'von', 'Trier', 'bit', 'off', 'more', 'than', 'he', 'could', 'chew', ',', 'but', 'this', 'movie', 'ends', 'up', 'being', 'richer', 'for', 'it', '.', 'I', 'suspect', 'he', 'is', 'familiar', 'with', \"Hitchcock's\", 'Foreign', 'Correspondent', 'in', 'which', 'devious', 'Europeans', 'also', 'manipulate', 'an', 'American', 'dupe', 'and', 'several', 'Welles', 'movies', 'that', 'take', 'delirious', 'joy', 'in', 'technique', 'as', 'much', 'as', 'he', 'does', '.', 'All', 'von', 'Trier', 'movies', 'explore', 'the', 'plight', 'of', 'the', 'naif', 'amidst', 'unforgiving', 'societies', '.', 'After', 'Zentropa', ',', 'von', 'Trier', 'moved', 'away', 'from', 'this', 'type', 'of', 'audacious', 'technical', 'experiment', 'towards', 'dreary', ',', 'over-rated', ',', 'un-nuanced', 'sap', 'like', 'Breaking', 'the', 'Waves', 'and', 'Dancer', 'in', 'the', 'Dark', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['The', 'best', 'way', 'for', 'me', 'to', 'describe', 'Europa', ',', 'which', 'is', 'high', 'on', 'the', 'list', 'of', 'my', 'favourite', 'films', ',', 'is', 'the', 'exclamation', 'that', 'came', 'from', 'a', 'companion', 'after', 'the', 'film', 'ended', ':', '\"', 'I', \"didn't\", 'know', 'films', 'could', 'be', 'made', 'like', 'that\"', '.', 'Entirely', 'original', 'in', \"it's\", 'visual', 'style', ',', 'it', 'is', 'one', 'of', 'the', 'best', 'examples', 'of', 'what', 'cinema', 'can', 'be', '.', \"It's\", 'as', 'far', 'away', 'from', 'the', '\"', 'master', 'and', 'coverage', '\"', 'style', 'of', 'shooting', 'as', 'one', 'can', 'get', ';', 'perfectly', 'integrating', 'many', 'layers', 'of', 'image', ',', 'sound', ',', 'effects', ',', 'props', ',', 'dialogue', ',', 'voice', 'over', ',', 'performance', ',', 'editing', ',', 'lighting', ',', 'etc..', '.', 'all', 'equal', ',', 'none', 'predominant', '.', 'Despite', \"Hollywood's\", '\"', 'dialogue', '\"', 'myopia', ',', 'cinema', 'is', 'not', 'about', 'dialogue', ',', 'nor', 'is', 'it', 'about', 'beautiful', 'lighting', ',', 'action', 'or', 'music', '.', 'It', 'works', 'best', 'when', 'all', 'the', 'elements', 'are', 'on', 'an', 'equal', 'footing', ',', 'where', 'ONLY', 'the', 'BLENDING', 'of', 'those', 'elements', ',', 'in', 'the', 'order', 'or', 'combination', 'in', 'which', 'they', 'are', 'presented', ',', 'will', 'communicate', 'the', 'idea', '.', 'Reduce', 'or', 'eliminate', 'the', 'contribution', 'of', 'one', 'element', ',', 'and', 'the', 'film', 'has', 'no', 'meaning', '.', '\"', 'Europa', '\"', 'is', 'what', 'cinema', 'should', 'strive', 'to', 'be', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Released', 'as', 'Zentropa', 'in', 'North', 'America', 'to', 'avoid', 'confusion', 'with', 'Agniezska', \"Holland's\", 'own', 'Holocaust', 'film', 'Europa', 'Europa', ',', 'this', 'third', 'theatrical', 'feature', 'by', 'a', 'filmmaker', 'who', 'never', 'ceases', 'to', 'surprise', ',', 'inspire', 'or', 'downright', 'shock', 'is', 'a', 'bizarre', ',', 'nostalgic', ',', 'elaborate', 'film', 'about', 'a', 'naive', 'American', 'in', 'Germany', 'shortly', 'following', 'the', 'end', 'of', 'WWII', '.', 'The', 'American', ',', 'named', 'Leo', ',', \"doesn't\", 'fully', 'get', 'what', \"he's\", 'doing', 'there', '.', 'He', 'has', 'come', 'to', 'take', 'part', 'in', 'fixing', 'up', 'the', 'country', 'since', ',', 'in', 'his', 'mind', ',', \"it's\", 'about', 'time', 'Germany', 'was', 'shown', 'some', 'charity', '.', 'No', 'matter', 'how', 'that', 'sounds', ',', 'he', 'is', 'not', 'a', 'Nazi', 'sympathizer', 'or', 'so', 'much', 'as', 'especially', 'pro-German', ',', 'merely', 'mixed', 'up', '.', 'His', 'uncle', ',', 'who', 'works', 'on', 'the', 'railroad', ',', 'gets', 'Leo', 'a', 'job', 'as', 'a', 'helmsman', 'on', 'a', 'sleeping', 'car', ',', 'and', 'he', 'is', 'increasingly', 'enmeshed', 'in', 'a', 'vortex', 'of', '1945', \"Germany's\", 'horrors', 'and', 'enigmas.<br', '/><br', '/>This', 'progression', 'starts', 'when', 'Leo', ',', 'played', 'rather', 'memorably', 'by', 'the', 'calm', 'yet', 'restless', 'actor', 'Jean-Marc', 'Barr', ',', 'meets', 'a', 'sultry', 'heiress', 'on', 'the', 'train', 'played', 'by', 'Barbara', 'Sukowa', ',', 'an', 'actress', 'with', 'gentility', 'on', 'the', 'surface', 'but', 'internal', 'vigor', '.', 'She', 'seduces', 'him', 'and', 'then', 'takes', 'him', 'home', 'to', 'meet', 'her', 'family', ',', 'which', 'owns', 'the', 'company', 'which', 'manufactures', 'the', 'trains', '.', 'These', 'were', 'the', 'precise', 'trains', 'that', 'took', 'Jews', 'to', 'their', 'deaths', 'during', 'the', 'war', ',', 'but', 'now', 'they', 'run', 'a', 'drab', 'day-to-day', 'timetable', ',', 'and', 'the', \"woman's\", 'Uncle', 'Kessler', 'postures', 'as', 'another', 'one', 'of', 'those', 'good', 'Germans', 'who', 'were', 'just', 'doing', 'their', 'jobs', '.', 'There', 'is', 'also', 'Udo', 'Kier', ',', 'the', 'tremendous', 'actor', 'who', 'blew', 'me', 'away', 'in', 'Von', \"Trier's\", 'shocking', 'second', 'film', 'Epidemic', ',', 'though', 'here', 'he', 'is', 'mere', 'scenery.<br', '/><br', '/>Another', 'guest', 'at', 'the', 'house', 'is', 'Eddie', 'Constantine', ',', 'an', 'actor', 'with', 'a', 'quiet', 'strength', ',', 'playing', 'a', 'somber', 'American', 'intelligence', 'man', '.', 'He', 'can', 'confirm', 'that', 'Uncle', 'Kessler', 'was', 'a', 'war', 'criminal', ',', 'though', 'it', 'is', 'all', 'completely', 'baffling', 'to', 'Leo', '.', 'Americans', 'have', 'been', 'characterized', 'as', 'gullible', 'rubes', 'out', 'of', 'their', 'element', 'for', 'decades', ',', 'but', 'little', 'have', 'they', 'been', 'more', 'blithely', 'unconcerned', 'than', 'Leo', ',', 'who', 'goes', 'back', 'to', 'his', 'job', 'on', 'what', 'gradually', 'looks', 'like', 'his', 'own', 'customized', 'death', 'train.<br', '/><br', '/>The', 'story', 'is', 'told', 'in', 'a', 'purposely', 'uncoordinated', 'manner', 'by', 'the', \"film's\", 'Danish', 'director', ',', 'Lars', 'Von', 'Trier', ',', 'whose', 'anchor', 'is', 'in', 'the', \"film's\", 'breathtaking', 'editing', 'and', 'cinematography', '.', 'He', 'shoots', 'in', 'black', 'and', 'white', 'and', 'color', ',', 'he', 'uses', 'double-exposures', ',', 'optical', 'effects', 'and', 'trick', 'photography', ',', 'having', 'actors', 'interact', 'with', 'rear-projected', 'footage', ',', 'he', 'places', 'his', 'characters', 'inside', 'a', 'richly', 'shaded', 'visceral', 'world', 'so', 'that', 'they', 'sometimes', 'feel', 'like', 'insects', ',', 'caught', 'between', 'glass', 'for', 'our', 'more', 'precise', 'survey.<br', '/><br', '/>This', 'Grand', 'Jury', 'Prize-winning', 'surrealist', 'work', 'is', 'allegorical', ',', 'but', 'maybe', 'in', 'a', 'distinct', 'tone', 'for', 'every', 'viewer', '.', 'I', 'interpret', 'it', 'as', 'a', 'film', 'about', 'the', 'last', 'legs', 'of', 'Nazism', ',', 'symbolized', 'by', 'the', 'train', ',', 'and', 'the', 'ethical', 'accountability', 'of', 'Americans', 'and', 'others', 'who', 'appeared', 'too', 'late', 'to', 'salvage', 'the', 'martyrs', 'of', 'these', 'trains', 'and', 'the', 'camps', 'where', 'they', 'distributed', 'their', 'condemned', 'shiploads', '.', 'During', 'the', 'time', 'frame', 'of', 'the', 'movie', ',', 'and', 'the', 'Nazi', 'state', ',', 'and', 'such', 'significance', 'to', 'the', 'train', ',', 'are', 'dead', ',', 'but', 'like', 'decapitated', 'chickens', 'they', 'persist', 'in', 'jolting', 'through', 'their', 'reflexes.<br', '/><br', '/>The', 'characters', ',', 'music', ',', 'dialogue', ',', 'and', 'plot', 'are', 'deliberately', 'hammy', 'and', 'almost', 'satirically', 'procured', 'from', 'film', 'noir', 'conventions', '.', 'The', 'most', 'entrancing', 'points', 'in', 'the', 'movie', 'are', 'the', 'entirely', 'cinematographic', 'ones', '.', 'Two', 'trains', 'halting', 'back', 'and', 'forth', ',', 'Barr', 'on', 'one', 'and', 'Sukowa', 'on', 'another', '.', 'An', 'underwater', 'shot', 'of', 'proliferating', 'blood', '.', 'An', 'uncommonly', 'expressive', 'sequence', 'on', 'what', 'it', 'must', 'be', 'like', 'to', 'drown', '.', 'And', 'most', 'metaphysically', 'affecting', 'of', 'all', ',', 'an', 'anesthetic', 'shot', 'of', 'train', 'tracks', ',', 'as', 'Max', 'von', \"Sydow's\", 'voice', 'allures', 'us', 'to', 'hark', 'back', 'to', 'Europe', 'with', 'him', ',', 'and', 'abandon', 'our', 'personal', 'restraint', '.'] \n",
      "\n",
      "SAMPLE DATA:\n",
      "Sample text: ['My', 'friend', 'and', 'I', 'picked', '\"', 'Paperhouse', '\"', 'out', 'of', 'a', 'random', 'pile', 'of', 'movies', 'on', 'our', 'weekly', 'excursion', 'to', 'the', 'Horror', 'section--', 'neither', 'of', 'us', 'had', 'heard', 'of', 'it', ',', 'but', 'the', 'blurb', 'on', 'the', 'box', 'was', 'really', 'promising', '.', 'And', 'the', 'movie', \"didn't\", 'disappoint', ',', 'though', 'I', 'still', 'probably', \"wouldn't\", 'call', 'it', 'a', 'horror', 'movie', 'exclusively.<br', '/><br', '/>11-year', 'old', 'Anna', 'Madden', 'draws', 'a', 'house', ',', 'and', 'visits', 'it', 'in', 'her', 'dreams', '.', 'She', 'is', 'definitely', 'asleep', 'when', \"she's\", 'seeing', 'the', 'house', ',', 'but', \"it's\", 'so', 'real', 'in', 'a', 'sense', 'that', \"it's\", 'almost', 'like', 'a', 'completely', 'separate', 'reality', '.', 'Which', ',', 'in', 'view', 'of', 'later', 'events', ',', \"doesn't\", 'seem', 'like', 'a', 'far', 'cry', 'from', 'the', 'truth', '.', 'Anyhow', ',', 'she', 'finds', 'she', 'can', 'add', 'to', 'the', 'house', ',', 'its', 'contents', 'and', 'its', 'surroundings', 'by', 'simply', 'adding', 'to', 'the', 'picture', '.', '<br', '/><br', '/>While', 'this', 'is', 'going', 'on', ',', 'Anna', 'is', 'getting', 'increasingly', 'more', 'ill', 'with', 'a', 'fever', ',', 'and', 'besides', 'that', 'is', 'getting', 'totally', 'obsessed', 'with', 'the', 'house', 'and', 'her', 'drawing', '.', 'On', 'top', 'of', 'that', ',', 'she', 'and', 'her', 'mother', 'are', 'also', 'dealing', 'with', 'her', 'absent', 'father', ';', 'he', 'has', 'a', 'job', 'that', 'takes', 'him', 'away', 'for', 'long', 'stretches', ',', 'though', 'one', 'gets', 'the', 'impression', \"there's\", 'actually', 'more', 'to', 'the', 'story', 'than', 'that.<br', '/><br', '/>OK', ',', 'so', 'the', 'drawing', 'stuff', 'sounds', 'nice', 'enough--', 'but', 'frankly', \"there's\", 'something', 'really', 'menacing', 'about', 'it', '.', 'The', 'dreamworld', 'is', 'eerily', 'surreal', '--', 'the', 'house', ',', 'for', 'instance', ',', 'is', 'just', 'a', 'grey', 'block', 'in', 'the', 'middle', 'of', 'a', 'desolate', 'field', '.', 'The', 'folks', 'who', 'made', 'the', 'movie', 'did', 'a', 'great', 'job', 'of', 'making', 'us', 'very', 'uncomfortable', 'with', 'this', 'alternate', 'world/ongoing', 'dream...<br', '/><br', '/>One', 'of', 'the', 'things', 'Anna', 'adds', 'to', 'the', 'house', 'is', 'a', 'boy', ',', 'Mark', ',', 'who', 'seems', 'to', 'be', 'the', 'same', 'patient', 'her', 'doctor', 'keeps', 'talking', 'about', '(', \"I'm\", 'not', 'giving', 'that', 'away', ',', 'you', 'know', 'from', 'the', 'moment', 'he', 'appears', 'that', \"it's\", 'the', 'same', 'kid)', '.', 'In', 'reality', ',', 'Mark', \"can't\", 'walk', 'due', 'to', 'an', 'illness', ';', 'in', \"Anna's\", 'drawing-world', ',', 'he', \"can't\", 'walk', 'because', 'she', \"didn't\", 'draw', 'him', 'any', 'legs', '.', 'She', 'blames', 'herself', 'for', 'his', 'real-life', 'illness', ',', 'and', 'tries', 'to', 'rectify', 'the', 'situation', ',', 'but..', '.', 'everything', 'starts', 'getting', 'really', 'weird', '.', 'She', 'even', 'brings', 'her', 'absent', 'father', 'into', 'the', 'drawing', ',', 'with', 'disastrous', 'results', '.', 'The', 'bits', 'with', 'the', 'father', 'are', 'really', 'terrifying.<br', '/><br', '/>I', \"don't\", 'want', 'to', 'give', 'anything', 'away', ',', 'so', \"I'll\", 'stop', 'there..', '.', 'There', 'seems', 'to', 'be', 'a', 'lot', 'going', 'on', 'in', 'this', 'film', '.', \"I'm\", 'sure', \"you'll\", 'have', 'a', 'ball', 'analyzing', 'this', 'thing', 'do', 'death', 'with', 'your', 'pals', 'after', 'you', 'watch', 'it--', 'Is', 'it', 'a', 'simple', 'a', 'story', 'as', 'it', 'seems', ',', 'or', 'are', 'there', 'actually', 'layers', 'of', 'meaning', '?', 'I', \"don't\", 'know', ',', 'but', 'either', 'way', \"it's\", 'quite', 'fascinating', '.', 'There', 'was', 'a', '\"', 'Nightmare', 'On', 'Elm', 'Street\"-ish', 'quality', 'about', 'it', ',', 'in', 'that', 'at', 'a', 'certain', 'point', 'reality', 'and', 'dreams', 'intersect', '.', 'I', 'love', 'things', 'like', 'that.<br', '/><br', '/>My', 'only', 'complaint', 'is', 'that', 'it', 'feels', 'like', 'it', 'COULD', 'have', 'ended', 'many', 'times', ',', 'but', \"didn't\", '.', \"I'm\", 'satisfied', 'with', 'the', 'ending', 'it', 'had', '(', 'some', 'of', 'you', 'sensitive', 'types', 'might', 'want', 'to', 'have', 'Kleenex', 'handy!)', ',', 'though', 'it', 'really', 'could', 'have', 'a', 'variety', 'of', 'conclusions', '.', 'Anyway', ',', 'it', \"doesn't\", 'exactly', 'feel', 'drawn', 'out', 'once', \"it's\", 'actually', 'over', ',', 'but', 'while', \"you're\", 'watching', 'and', 'it', 'keeps', 'fading', 'back', 'in', ',', \"it's\", 'a', 'little', 'nerve', 'wracking.<br', '/><br', '/>Still', ',', '\"', 'Paperhouse', '\"', 'is', 'a', 'really', 'GOOD', 'film', '.', \"It's\", 'well', 'done', ',', 'and', 'acting--', 'especially', 'Charlotte', 'Burke', 'as', 'Anna--', 'is', 'top', 'notch', '.', 'Burke', ',', 'who', 'has', 'never', 'before', 'or', 'since', 'appeared', 'in', 'a', 'film', ',', 'is', 'a', 'real', 'gem', '.', 'I', \"don't\", 'know', 'why', 'she', 'never', 'went', 'onto', 'do', 'anything', 'else', ',', 'but', 'either', 'way', \"she's\", 'really', 'convincing', 'and', 'enjoyable', 'to', 'watch.<br', '/><br', '/>\"Paperhouse', '\"', \"isn't\", 'exactly', 'a', 'horror', 'movie', ',', \"it's\", 'sort', 'of', 'a', 'fantasy/suspense/something', 'else', 'type', 'of', 'movie', ',', 'with', 'some', 'definite', 'horroresque', 'moments--', 'but', 'you', 'can', 'still', 'watch', 'it', 'with', 'your', 'family', 'and', 'not', 'be', 'worried', 'that', 'your', 'little', 'brother', 'or', 'grandmother', 'will', 'get', 'grossed', 'out', 'by', 'blood', 'splashing', 'or', 'something.<br', '/><br', '/>Give', 'it', 'a', 'chance', ',', 'you', \"won't\", 'regret', 'it', '!', 'And', 'maybe', 'you', 'should', 'read', 'the', 'book', ',', 'too..', '.']\n",
      "Sample label: pos \n",
      "\n",
      "Sample text: ['Ah', 'yes', 'the', '1980s', '', ',', 'a', 'time', 'of', 'Reaganomics', 'and', 'Sly', '', ',', 'Chuck', 'and', 'a', 'host', 'of', 'other', 'action', 'stars', 'hiding', 'in', 'a', 'remote', 'jungle', 'blowing', 'away', 'commies', '', '.', 'At', 'the', 'time', 'I', 'couldn`t', 'believe', 'how', 'movies', 'like', 'RAMBO', '', ',', 'MISSING', 'IN', 'ACTION', 'and', 'UNCOMMON', 'VALOR', '(', '', 'And', 'who', 'can', 'forget', 'the', 'ridiculous', 'RED', 'DAWN', '', '?', '', ')', 'made', 'money', 'at', 'the', 'box', 'office', '', ',', 'they`re', 'turgid', 'action', 'crap', 'fests', 'with', 'a', 'rather', 'off', 'putting', 'right', 'wing', 'agenda', 'and', 'they', 'have', 'dated', 'very', 'badly', '', '.', 'TROMA`S', 'WAR', 'is', 'a', 'tongue', 'in', 'cheek', 'take', 'on', 'these', 'type', 'of', 'movies', 'but', 'you`ve', 'got', 'to', 'ask', 'yourself', 'did', 'they', 'need', 'spoofing', 'in', 'the', 'first', 'place', '', '?', 'Of', 'course', 'not', '', '.', 'TROMA`S', 'WAR', 'lacks', 'any', 'sort', 'of', 'sophistication', '-', 'though', 'it', 'does', 'make', 'the', 'point', 'that', 'there`s', 'no', 'real', 'difference', 'between', 'right', 'wing', 'tyrants', 'and', 'left', 'wing', 'ones', '-', 'and', 'sometimes', 'feels', 'more', 'like', 'a', 'grade', 'z', 'movie', 'than', 'a', 'send', 'up', '', '.', 'Maybe', 'it', 'is', '', '?']\n",
      "Sample label: neg \n",
      "\n",
      "Sample text: ['I', 'bought', 'this', 'DVD', 'without', 'any', 'previous', 'reference', 'but', 'the', 'names', 'of', 'John', 'Huston', ',', 'Raquel', 'Welch', ',', 'Mae', 'West', 'and', 'Farrah', 'Fawcett', 'on', 'its', 'cover', '.', 'I', 'found', 'the', 'Brazilian', 'title', 'very', 'weird', ',', 'but', 'I', 'decided', 'to', 'watch', 'expecting', 'to', 'see', 'a', 'funny', 'comedy', 'maybe', 'like', '\"', 'Switch\"', '.', 'However', 'the', 'non-sense', 'story', 'is', 'awful', 'and', 'hard', 'to', 'be', 'described', '.', 'Myron', 'Breckinridge', '(', 'Rex', 'Reed', ')', 'is', 'submitted', 'to', 'a', 'surgery', 'to', 'change', 'his', 'sex', 'in', 'Copenhagen', 'and', 'he', 'returns', 'to', 'Hollywood', 'telling', 'that', 'she', 'is', 'to', 'be', 'Myra', 'Breckinridge', '(', 'Raquel', 'Welch', ')', 'and', 'claiming', 'half', 'the', 'property', 'of', 'his', 'uncle', 'Buck', 'Loner', '(', 'John', 'Huston)', '.', 'Along', 'the', 'days', ',', 'Myra', 'and', 'her', 'alter-ego', 'Myron', 'corrupt', 'a', 'young', 'couple', 'in', 'her', \"uncle's\", 'academy', 'with', 'kinky', 'sex', '.', 'In', 'a', 'certain', 'moment', ',', 'the', 'messy', 'screenplay', 'is', 'so', 'confused', 'that', 'I', 'believe', 'the', 'whole', 'story', 'was', 'only', 'a', 'mind', 'trip', 'of', 'Myron', 'induced', 'by', 'the', 'accident', '.', 'Unfortunately', 'the', 'beauties', 'of', 'Raquel', 'Welch', 'and', 'Farrah', 'Fawcett', 'are', 'not', 'enough', 'to', 'hold', 'this', 'flick', '.', 'My', 'vote', 'is', 'three.<br', '/><br', '/>Title', '(', 'Brazil)', ':', '\"', 'Homem', '&', 'Mulher', 'Até', 'Certo', 'Ponto', '\"', '(', '\"Man', '&', 'Woman', 'Up', 'to', 'a', 'Point\"', ')']\n",
      "Sample label: neg \n",
      "\n",
      "Sample text: ['Pinjar', 'is', 'a', 'genuinely', 'good', 'film', ',', 'with', 'great', 'acting', ',', 'good', 'narrative', ',', 'good', 'presentation', ',', 'touching', 'emotions', ',', 'etc.<br', '/><br', '/>It', 'seems', 'to', 'me', 'that', 'the', 'quality', 'of', 'films', 'that', 'Bollywood', 'is', 'producing', 'is', 'quite', 'improving', 'these', 'days', ',', 'and', 'this', 'film', 'is', 'one', 'evidence.<br', '/><br', '/>No', 'Bollywood', 'movie', 'that', 'I', 'can', 'remember', 'of', 'made', 'such', 'an', 'impact', 'on', 'me', '-', 'I', 'was', 'literally', 'thinking', 'about', 'the', 'movie', 'for', 'hours', '-', 'marvelling', 'at', 'the', 'various', 'emotional', 'situations', 'that', 'test', 'the', 'human', 'in', 'a', 'human.<br', '/><br', '/>The', 'film', 'rests', 'on', 'the', 'great', 'acting', 'of', 'Urmilla', 'Matondkar', ',', 'and', 'also', 'some', 'from', 'Manoj', 'Bajpai', '.', 'Urmilla', 'plays', 'a', 'girl', 'in', 'North', 'India', 'in', 'the', 'background', 'of', 'the', 'partition', ',', 'and', 'all', 'troubles', 'seem', 'sweet', 'if', 'compared', 'with', 'the', 'problems', 'she', 'happens', 'to', 'face', '.', '<br', '/><br', '/>A', 'must-see', 'film', '.', 'A', 'technically', 'superior', 'Bollywood', 'product', ',', 'which', 'I', 'feel', 'is', 'comparable', 'to', 'the', 'best', 'movies', 'coming', 'out', 'of', 'other', 'countries', 'in', 'the', 'world', '.']\n",
      "Sample label: pos \n",
      "\n",
      "Sample text: ['My', 'husband', 'and', 'I', 'were', 'intrigued', 'by', 'the', 'spectacle', '-', 'a', 'strong', 'willed', 'Southern', 'lady', 'with', 'a', 'messy', 'personal', 'life', 'solves', 'crimes', 'for', 'the', 'LAPD', '.', 'The', 'first', 'season', 'was', 'must-see', 'TV', 'for', 'us', '.', 'Unfortunately', ',', 'the', 'stories', 'of', 'her', 'personal', 'life', 'in', 'the', 'second', 'season', 'became', 'so', 'tedious', 'and', 'unworthy', 'of', 'the', 'strong', 'character', 'that', 'we', 'stopped', 'watching.<br', '/><br', '/>My', 'husband', 'and', 'I', 'were', 'troubled', 'by', 'the', 'episode', 'where', 'she', 'tries', 'to', 'hide', 'from', 'her', 'mother', 'the', 'fact', 'that', 'she', 'is', 'shacked', 'up', '.', 'But', 'the', 'deal', 'breaker', 'was', 'the', 'episode', 'where', 'she', 'hides', 'her', 'possible', 'pregnancy', 'from', 'her', 'boyfriend', 'but', 'tells', 'her', 'boss', '.', 'Why', 'would', 'a', 'strong', ',', 'middle', 'aged', 'woman', 'do', 'those', 'things', '?', 'The', 'answer', 'is', 'she', \"wouldn't\", '.', 'Additionally', ',', 'my', 'husband', 'and', 'I', 'pick', 'out', 'the', 'bad', 'guy', 'with', 'almost', 'perfect', 'accuracy', '.', 'It', 'is', 'almost', 'always', 'a', 'white', 'male', 'or', 'female', 'introduced', 'in', 'cameo', 'at', 'the', 'murder', 'scene', 'or', 'in', 'an', 'idealized', 'family', '.', \"Can't\", 'the', 'script', 'writers', 'do', 'something', 'original', 'from', 'time', 'to', 'time', '?', 'As', 'I', 'mentioned', ',', 'we', 'are', 'no', 'longer', 'viewers', '.', 'We', 'prefer', 'shows', 'that', \"don't\", 'betray', 'the', 'characters', 'and', 'insult', 'our', 'intelligence', '.']\n",
      "Sample label: neg \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "import torchtext\n",
    "import random\n",
    "\n",
    "def preprocess(review):\n",
    "    '''\n",
    "    Simple preprocessing function.\n",
    "    '''\n",
    "    res = []\n",
    "    for x in review.split(' '):\n",
    "        remove_beg=True if x[0] in {'(', '\"', \"'\"} else False\n",
    "        remove_end=True if x[-1] in {'.', ',', ';', ':', '?', '!', '\"', \"'\", ')'} else False\n",
    "        if remove_beg and remove_end: res += [x[0], x[1:-1], x[-1]]\n",
    "        elif remove_beg: res += [x[0], x[1:]]\n",
    "        elif remove_end: res += [x[:-1], x[-1]]\n",
    "        else: res += [x]\n",
    "    return res\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_data = torchtext.datasets.IMDB(root='.data', split='train')\n",
    "    train_data = list(train_data)\n",
    "    train_data = [(x[0], preprocess(x[1])) for x in train_data]\n",
    "    train_data, test_data = train_data[0:10000] + train_data[12500:12500+10000], train_data[10000:12500] + train_data[12500+10000:], \n",
    "\n",
    "    print('Num. Train Examples:', len(train_data))\n",
    "    print('Num. Test Examples:', len(test_data))\n",
    "\n",
    "\n",
    "    # for i in range(len(train_data)):\n",
    "    for i in range(0,10,1):\n",
    "        print(f\"the label for the *i*th example: {train_data[i][0]} \")\n",
    "        print(f\"list of textual tokens for the *i*th example: {train_data[i][1]} \")\n",
    "\n",
    "\n",
    "    # *   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n",
    "    # *   To access the label for the *i*th example, use `train_data[i][0]`\n",
    "\n",
    "\n",
    "    print(\"\\nSAMPLE DATA:\")\n",
    "    for x in random.sample(train_data, 5):\n",
    "        print('Sample text:', x[1])\n",
    "        print('Sample label:', x[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kfg8RcyskyU"
   },
   "source": [
    "# Step 2: Create Dataloader [20 points]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TODO:</font> Define the Dataset Class [20 Points]\n",
    "\n",
    "In the following cell, we will define the <b>dataset</b> class. The dataset contains the tokenized data for your model. You need to implement the following functions: \n",
    "\n",
    "*   <b>` build_dictionary(self)`:</b>  <b>[10 points]</b> Creates the dictionaries `idx2word` and `word2idx`. You will represent each word in the dataset with a unique index, and keep track of this in these dictionaries. Use the hyperparameter `threshold` to control which words appear in the dictionary: a training word’s frequency should be `>= threshold` to be included in the dictionary.\n",
    "\n",
    "* <b>`convert_text(self)`:</b> Converts each review in the dataset to a list of indices, given by your `word2idx` dictionary. You should store this in the `textual_ids` variable, and the function does not return anything. If a word is not present in the  `word2idx` dictionary, you should use the `<UNK>` token for that word. Be sure to append the `<END>` token to the end of each review.\n",
    "\n",
    "*   <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
    "\n",
    "*   <b>`get_label(self, idx) `</b>: Return the value `1` if the label for `idx` in the dataset is `positive`, and should return `0` if it is `negative`. The return type should be `torch.LongTensor`.\n",
    "\n",
    "*  <b> ` __len__(self) `:</b> Return the total number of reviews in the dataset as an `int`.\n",
    "\n",
    "*   <b>` __getitem__(self, idx)`:</b> <b>[10 points]</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here.\n",
    "\n",
    "\n",
    "<b>Note:</b> You should convert all words to lower case in your functions.\n",
    "\n",
    "<font color='green'><b>Hint:</b> Make sure that you use instance variables such as `self.threshold` throughout your code, rather than the global variable `THRESHOLD` (defined later on). The variable `THRESHOLD` will not be known to the autograder, and the use of it within the class will cause an autograder error.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1irMn3LX2YDB"
   },
   "outputs": [],
   "source": [
    "PAD = '<PAD>'\n",
    "END = '<END>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "from torch.utils import data\n",
    "from collections import defaultdict\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "    def __init__(self, examples, split, threshold, max_len, idx2word=None, word2idx=None):\n",
    "        ### DO NOT EDIT ###\n",
    "        \n",
    "        self.examples = examples\n",
    "        assert split in {'train', 'val', 'test'}\n",
    "        self.split = split\n",
    "        self.threshold = threshold\n",
    "        self.max_len = max_len\n",
    "\n",
    "        #custom\n",
    "        self.map_token_to_unigram_frequency = {}\n",
    "\n",
    "        # Dictionaries\n",
    "        self.idx2word = idx2word\n",
    "        self.word2idx = word2idx\n",
    "        if split == 'train':\n",
    "            self.build_dictionary()\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "        self.vocabulary = []\n",
    "        \n",
    "        # Convert text to indices\n",
    "        self.textual_ids = []\n",
    "        self.convert_text()\n",
    "\n",
    "    # def default_function_for_default_dict(self):\n",
    "    #     return\n",
    "    def build_dictionary(self): \n",
    "        '''\n",
    "        Build the dictionaries idx2word and word2idx. This is only called when split='train', as these\n",
    "        dictionaries are passed in to the __init__(...) function otherwise. Be sure to use self.threshold\n",
    "        to control which words are assigned indices in the dictionaries.\n",
    "        Returns nothing.\n",
    "        '''\n",
    "        assert self.split == 'train'\n",
    "        \n",
    "        # Don't change this\n",
    "        self.idx2word = {0:PAD, 1:END, 2: UNK}\n",
    "        self.word2idx = {PAD:0, END:1, UNK: 2}\n",
    "\n",
    "        ##### TODO #####\n",
    "        # Count the frequencies of all words in the training data (self.examples)\n",
    "        # Assign idx (starting from 3) to all words having word_freq >= self.threshold\n",
    "        # Make sure you call word.lower() on each word to convert it to lowercase\n",
    "        # print(\" BUILDING DICT\")\n",
    "        # print(f\"training dataset is: {self.examples[0]}\")\n",
    "\n",
    "        # ('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
    "\n",
    "        # map_token_to_unigram_frequency = defaultdict(lambda: \" not\")\n",
    "\n",
    "        for build_dict_data in self.examples:           #iterate through preprocessed sentences\n",
    "            # print(f\"data: {data}\")\n",
    "            testset_label, preprocessed_sentence = build_dict_data[0], build_dict_data[1]\n",
    "            # print(f\"testset_label: {testset_label}, preprocessed_sentence:{preprocessed_sentence}\")\n",
    "            for token in preprocessed_sentence:             #iterate through each token\n",
    "                # print(f\"lowercase token is: {token}\")\n",
    "                token = token.lower()\n",
    "\n",
    "                if token not in self.map_token_to_unigram_frequency.keys():\n",
    "                    self.map_token_to_unigram_frequency[token] = 0          # add token as key if not present as a key in map_token_to_unigram_frequency\n",
    "                if token in self.map_token_to_unigram_frequency.keys():\n",
    "                    self.map_token_to_unigram_frequency[token] += 1          # add token as key if not present as a key in map_token_to_unigram_frequency\n",
    "\n",
    "\n",
    "        print(f\"self.map_token_to_unigram_frequency: {self.map_token_to_unigram_frequency}\")\n",
    "\n",
    "        # Also make sure your vocabulary is deterministic - if you make it multiple times,\n",
    "        # you should always get the same word to index mapping.\n",
    "        # Otherwise, you could get an issue where at test time you are basically mapping words to\n",
    "        # different indexes than it was trained under, causing basically random embeddings\n",
    "        # and thus 50% accuracy.\n",
    "\n",
    "        # if has_passed and sorted(list(dataset.idx2word.keys())) != list(range(0, dataset.vocab_size)):\n",
    "        #     has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(dataset.idx2word.keys())))\n",
    "\n",
    "        items = self.map_token_to_unigram_frequency.items()\n",
    "        # print(f\"items is: {items}\")\n",
    "\n",
    "        # sort in lexicographical order\n",
    "        sorted_items = (sorted(self.map_token_to_unigram_frequency.items()))\n",
    "        print(sorted_items)\n",
    "\n",
    "\n",
    "        # Made the dictionaries such that each word was always mapped to a particular index.\n",
    "        # Then removed all indexes and renamed them to (0,len(vocab)-1).\n",
    "        token_indice = 3\n",
    "        for token, freq in sorted(self.map_token_to_unigram_frequency.items()):\n",
    "            # print(f\"token: {token}, freq: {freq}\")\n",
    "            # self.idx2word[index] = token\n",
    "            if freq >= self.threshold:\n",
    "                # self.idx2word[token_indice] = token\n",
    "                self.word2idx[token] = token_indice\n",
    "            token_indice += 1\n",
    "\n",
    "        for index, (token, token_indice) in enumerate(self.word2idx.items()):\n",
    "            self.idx2word[index] = token\n",
    "            self.word2idx[token] = index\n",
    "            print(f\"index: {index}, token: {token}, token_indice{token_indice}\")\n",
    "\n",
    "        # for token, token_indice in temp_dict.keys():\n",
    "        #     if freq >= self.threshold:\n",
    "\n",
    "\n",
    "        # vocab_size = len(self.word2idx)\n",
    "        # self.vocabulary = [self.idx2word[i] for i in range(vocab_size)]\n",
    "\n",
    "\n",
    "        # --- TEST: idx2word and word2idx dictionaries ---\n",
    "        #     items is: dict_items([('your', 2), ('life', 3), ('is', 3), ('good', 2), ('when', 3), ('you', 3), ('have', 2), ('money', 2), (',', 2), ('success', 2), ('and', 2), ('health', 2), ('bad', 2), ('got', 2), ('not', 2), ('a', 2), ('lot', 2)])\n",
    "\n",
    "\n",
    "        print(f\"self.idx2word: {self.idx2word}\")\n",
    "        print(f\"self.word2idx: {self.word2idx}\")\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def convert_text(self):\n",
    "        '''\n",
    "        Convert each review in the dataset (self.examples) to a list of indices, given by self.word2idx.\n",
    "        Store this in self.textual_ids; returns nothing.\n",
    "        '''\n",
    "\n",
    "        ##### TODO #####\n",
    "        # Remember to replace a word with the <UNK> token if it does not exist in the word2idx dictionary.\n",
    "        # Remember to append the <END> token to the end of each review.\n",
    "        for convert_text_example in self.examples:           #iterate through preprocessed sentences\n",
    "            # print(f\"convert_text_example: {convert_text_example}\")\n",
    "            testset_label, preprocessed_sentence = convert_text_example[0], convert_text_example[1]\n",
    "            converted_preprocessed_sentence = []\n",
    "            # print(f\"testset_label: {testset_label}, preprocessed_sentence:{preprocessed_sentence}\")\n",
    "            for token_index in range(len(preprocessed_sentence)):             #iterate through each token\n",
    "                token = preprocessed_sentence[token_index]\n",
    "                # print(f\"IN CONVERT TEXT: token: {token}\")\n",
    "                token = token.lower()\n",
    "                # print(f\"lowercase token is: {token}\")\n",
    "                if token not in self.word2idx.keys():\n",
    "                    # preprocessed_sentence[token_index] = self.word2idx[UNK]\n",
    "                    converted_preprocessed_sentence.append(self.word2idx[UNK])\n",
    "                if token in self.word2idx.keys():\n",
    "                    # preprocessed_sentence[token_index] = self.word2idx[token]\n",
    "                    converted_preprocessed_sentence.append(self.word2idx[token])\n",
    "\n",
    "            converted_preprocessed_sentence.append(self.word2idx[END])\n",
    "\n",
    "            # print(f\"testset_label: {testset_label}, converted preprocessed_sentence:{converted_preprocessed_sentence}\")\n",
    "            # self.textual_ids.append([testset_label,converted_preprocessed_sentence])\n",
    "            self.textual_ids.append(converted_preprocessed_sentence)\n",
    "            # print(f\"self.textual_ids is: {self.textual_ids}\")\n",
    "\n",
    "        pass\n",
    "\n",
    "    def get_text(self, idx):\n",
    "        '''\n",
    "        Return the review at idx as a long tensor (torch.LongTensor) of integers corresponding to the words in the review.\n",
    "        You may need to pad as necessary (see above).\n",
    "\n",
    "        <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
    "        '''\n",
    "\n",
    "        ##### TODO #####\n",
    "        review = self.examples[idx]\n",
    "        indice_review = self.textual_ids[idx]\n",
    "        # print(f\"indice review is: {indice_review}\")\n",
    "\n",
    "        if len(indice_review) >= self.max_len:\n",
    "            indice_review_long_tensor = torch.LongTensor(indice_review[0:self.max_len])\n",
    "\n",
    "        elif len(indice_review) < self.max_len:\n",
    "            padding = [self.word2idx[PAD]] * (self.max_len - len(indice_review))\n",
    "            padded_version = indice_review + padding\n",
    "            # print(f\"padding list is: {padding} and padded version: {padded_version}\")\n",
    "            # indice_review_long_tensor = padded_version.type(torch.int64)\n",
    "            indice_review_long_tensor = torch.LongTensor(padded_version)\n",
    "\n",
    "\n",
    "        # print('Content of indice_review_long_tensor:', indice_review_long_tensor)\n",
    "        # print('Shape of indice_review_long_tensor:', indice_review_long_tensor.shape, '\\n')\n",
    "        # print('Type of indice_review_long_tensor:', indice_review_long_tensor.dtype, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "        return (indice_review_long_tensor)\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        '''\n",
    "        This function should return the value 1 if the label for idx in the dataset is 'positive', \n",
    "        and 0 if it is 'negative'. The return type should be torch.LongTensor.\n",
    "        '''\n",
    "        ##### TODO #####\n",
    "        review_label = self.examples[idx][0]\n",
    "        # print(f\"review label: {review_label}\")\n",
    "\n",
    "        if review_label == 'pos':\n",
    "            return torch.squeeze(torch.LongTensor([1]))\n",
    "            # print('Shape of torch.squeeze(torch.Tensor(1)):', torch.squeeze(torch.Tensor(1)).shape, '\\n')\n",
    "            # return torch.squeeze(torch.Tensor([1]))\n",
    "\n",
    "        elif review_label == 'neg':\n",
    "            return torch.squeeze(torch.LongTensor([0]))\n",
    "            # print('Shape of torch.squeeze(torch.Tensor(0)):', torch.squeeze(torch.Tensor(0)).shape, '\\n')\n",
    "            # return torch.squeeze(torch.Tensor([0]))\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return the number of reviews (int value) in the dataset\n",
    "        '''\n",
    "        ##### TODO #####\n",
    "        return int(len(self.examples))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Return the review, and label of the review specified by idx.\n",
    "\n",
    "        *   <b>` __getitem__(self, idx)`:</b> <b>[10 points]</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here.\n",
    "        '''\n",
    "        ##### TODO #####\n",
    "        # return self.examples[idx][1], self.examples[idx][0]\n",
    "        return self.get_text(idx), self.get_label(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxVxiGGbFJAj"
   },
   "source": [
    "##Sanity Check: Dataset Class\n",
    "\n",
    "The code below runs a sanity check for your `Dataset` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bvHIZt8Z-RzK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset:\n",
      "('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
      "('neg', ['Life', 'is', 'bad', 'when', 'you', 'got', 'not', 'a', 'lot'])\n",
      "\n",
      "--- TEST: idx2word and word2idx dictionaries ---\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: ,, token_indice3\n",
      "index: 4, token: a, token_indice4\n",
      "index: 5, token: and, token_indice5\n",
      "index: 6, token: bad, token_indice6\n",
      "index: 7, token: good, token_indice7\n",
      "index: 8, token: got, token_indice8\n",
      "index: 9, token: have, token_indice9\n",
      "index: 10, token: health, token_indice10\n",
      "index: 11, token: is, token_indice11\n",
      "index: 12, token: life, token_indice12\n",
      "index: 13, token: lot, token_indice13\n",
      "index: 14, token: money, token_indice14\n",
      "index: 15, token: not, token_indice15\n",
      "index: 16, token: success, token_indice16\n",
      "index: 17, token: when, token_indice17\n",
      "index: 18, token: you, token_indice18\n",
      "index: 19, token: your, token_indice19\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: ',', 4: 'a', 5: 'and', 6: 'bad', 7: 'good', 8: 'got', 9: 'have', 10: 'health', 11: 'is', 12: 'life', 13: 'lot', 14: 'money', 15: 'not', 16: 'success', 17: 'when', 18: 'you', 19: 'your'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, ',': 3, 'a': 4, 'and': 5, 'bad': 6, 'good': 7, 'got': 8, 'have': 9, 'health': 10, 'is': 11, 'life': 12, 'lot': 13, 'money': 14, 'not': 15, 'success': 16, 'when': 17, 'you': 18, 'your': 19}\n",
      "\tthreshold: 1 \tmax_len: 3 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: is, token_indice11\n",
      "index: 4, token: life, token_indice12\n",
      "index: 5, token: when, token_indice17\n",
      "index: 6, token: you, token_indice18\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: 'is', 4: 'life', 5: 'when', 6: 'you'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, 'is': 3, 'life': 4, 'when': 5, 'you': 6}\n",
      "\tthreshold: 2 \tmax_len: 3 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2}\n",
      "\tthreshold: 3 \tmax_len: 3 \tPASSED \t\n",
      "\n",
      "--- TEST: len(dataset) ---\n",
      "\tPASSED\n",
      "\n",
      "--- TEST: __getitem__(self, idx) ---\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: ,, token_indice3\n",
      "index: 4, token: a, token_indice4\n",
      "index: 5, token: and, token_indice5\n",
      "index: 6, token: bad, token_indice6\n",
      "index: 7, token: good, token_indice7\n",
      "index: 8, token: got, token_indice8\n",
      "index: 9, token: have, token_indice9\n",
      "index: 10, token: health, token_indice10\n",
      "index: 11, token: is, token_indice11\n",
      "index: 12, token: life, token_indice12\n",
      "index: 13, token: lot, token_indice13\n",
      "index: 14, token: money, token_indice14\n",
      "index: 15, token: not, token_indice15\n",
      "index: 16, token: success, token_indice16\n",
      "index: 17, token: when, token_indice17\n",
      "index: 18, token: you, token_indice18\n",
      "index: 19, token: your, token_indice19\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: ',', 4: 'a', 5: 'and', 6: 'bad', 7: 'good', 8: 'got', 9: 'have', 10: 'health', 11: 'is', 12: 'life', 13: 'lot', 14: 'money', 15: 'not', 16: 'success', 17: 'when', 18: 'you', 19: 'your'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, ',': 3, 'a': 4, 'and': 5, 'bad': 6, 'good': 7, 'got': 8, 'have': 9, 'health': 10, 'is': 11, 'life': 12, 'lot': 13, 'money': 14, 'not': 15, 'success': 16, 'when': 17, 'you': 18, 'your': 19}\n",
      "\tthreshold: 1 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: ,, token_indice3\n",
      "index: 4, token: a, token_indice4\n",
      "index: 5, token: and, token_indice5\n",
      "index: 6, token: bad, token_indice6\n",
      "index: 7, token: good, token_indice7\n",
      "index: 8, token: got, token_indice8\n",
      "index: 9, token: have, token_indice9\n",
      "index: 10, token: health, token_indice10\n",
      "index: 11, token: is, token_indice11\n",
      "index: 12, token: life, token_indice12\n",
      "index: 13, token: lot, token_indice13\n",
      "index: 14, token: money, token_indice14\n",
      "index: 15, token: not, token_indice15\n",
      "index: 16, token: success, token_indice16\n",
      "index: 17, token: when, token_indice17\n",
      "index: 18, token: you, token_indice18\n",
      "index: 19, token: your, token_indice19\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: ',', 4: 'a', 5: 'and', 6: 'bad', 7: 'good', 8: 'got', 9: 'have', 10: 'health', 11: 'is', 12: 'life', 13: 'lot', 14: 'money', 15: 'not', 16: 'success', 17: 'when', 18: 'you', 19: 'your'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, ',': 3, 'a': 4, 'and': 5, 'bad': 6, 'good': 7, 'got': 8, 'have': 9, 'health': 10, 'is': 11, 'life': 12, 'lot': 13, 'money': 14, 'not': 15, 'success': 16, 'when': 17, 'you': 18, 'your': 19}\n",
      "\tthreshold: 1 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: ,, token_indice3\n",
      "index: 4, token: a, token_indice4\n",
      "index: 5, token: and, token_indice5\n",
      "index: 6, token: bad, token_indice6\n",
      "index: 7, token: good, token_indice7\n",
      "index: 8, token: got, token_indice8\n",
      "index: 9, token: have, token_indice9\n",
      "index: 10, token: health, token_indice10\n",
      "index: 11, token: is, token_indice11\n",
      "index: 12, token: life, token_indice12\n",
      "index: 13, token: lot, token_indice13\n",
      "index: 14, token: money, token_indice14\n",
      "index: 15, token: not, token_indice15\n",
      "index: 16, token: success, token_indice16\n",
      "index: 17, token: when, token_indice17\n",
      "index: 18, token: you, token_indice18\n",
      "index: 19, token: your, token_indice19\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: ',', 4: 'a', 5: 'and', 6: 'bad', 7: 'good', 8: 'got', 9: 'have', 10: 'health', 11: 'is', 12: 'life', 13: 'lot', 14: 'money', 15: 'not', 16: 'success', 17: 'when', 18: 'you', 19: 'your'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, ',': 3, 'a': 4, 'and': 5, 'bad': 6, 'good': 7, 'got': 8, 'have': 9, 'health': 10, 'is': 11, 'life': 12, 'lot': 13, 'money': 14, 'not': 15, 'success': 16, 'when': 17, 'you': 18, 'your': 19}\n",
      "\tthreshold: 1 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: ,, token_indice3\n",
      "index: 4, token: a, token_indice4\n",
      "index: 5, token: and, token_indice5\n",
      "index: 6, token: bad, token_indice6\n",
      "index: 7, token: good, token_indice7\n",
      "index: 8, token: got, token_indice8\n",
      "index: 9, token: have, token_indice9\n",
      "index: 10, token: health, token_indice10\n",
      "index: 11, token: is, token_indice11\n",
      "index: 12, token: life, token_indice12\n",
      "index: 13, token: lot, token_indice13\n",
      "index: 14, token: money, token_indice14\n",
      "index: 15, token: not, token_indice15\n",
      "index: 16, token: success, token_indice16\n",
      "index: 17, token: when, token_indice17\n",
      "index: 18, token: you, token_indice18\n",
      "index: 19, token: your, token_indice19\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: ',', 4: 'a', 5: 'and', 6: 'bad', 7: 'good', 8: 'got', 9: 'have', 10: 'health', 11: 'is', 12: 'life', 13: 'lot', 14: 'money', 15: 'not', 16: 'success', 17: 'when', 18: 'you', 19: 'your'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, ',': 3, 'a': 4, 'and': 5, 'bad': 6, 'good': 7, 'got': 8, 'have': 9, 'health': 10, 'is': 11, 'life': 12, 'lot': 13, 'money': 14, 'not': 15, 'success': 16, 'when': 17, 'you': 18, 'your': 19}\n",
      "\tthreshold: 1 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: ,, token_indice3\n",
      "index: 4, token: a, token_indice4\n",
      "index: 5, token: and, token_indice5\n",
      "index: 6, token: bad, token_indice6\n",
      "index: 7, token: good, token_indice7\n",
      "index: 8, token: got, token_indice8\n",
      "index: 9, token: have, token_indice9\n",
      "index: 10, token: health, token_indice10\n",
      "index: 11, token: is, token_indice11\n",
      "index: 12, token: life, token_indice12\n",
      "index: 13, token: lot, token_indice13\n",
      "index: 14, token: money, token_indice14\n",
      "index: 15, token: not, token_indice15\n",
      "index: 16, token: success, token_indice16\n",
      "index: 17, token: when, token_indice17\n",
      "index: 18, token: you, token_indice18\n",
      "index: 19, token: your, token_indice19\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: ',', 4: 'a', 5: 'and', 6: 'bad', 7: 'good', 8: 'got', 9: 'have', 10: 'health', 11: 'is', 12: 'life', 13: 'lot', 14: 'money', 15: 'not', 16: 'success', 17: 'when', 18: 'you', 19: 'your'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, ',': 3, 'a': 4, 'and': 5, 'bad': 6, 'good': 7, 'got': 8, 'have': 9, 'health': 10, 'is': 11, 'life': 12, 'lot': 13, 'money': 14, 'not': 15, 'success': 16, 'when': 17, 'you': 18, 'your': 19}\n",
      "\tthreshold: 1 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: ,, token_indice3\n",
      "index: 4, token: a, token_indice4\n",
      "index: 5, token: and, token_indice5\n",
      "index: 6, token: bad, token_indice6\n",
      "index: 7, token: good, token_indice7\n",
      "index: 8, token: got, token_indice8\n",
      "index: 9, token: have, token_indice9\n",
      "index: 10, token: health, token_indice10\n",
      "index: 11, token: is, token_indice11\n",
      "index: 12, token: life, token_indice12\n",
      "index: 13, token: lot, token_indice13\n",
      "index: 14, token: money, token_indice14\n",
      "index: 15, token: not, token_indice15\n",
      "index: 16, token: success, token_indice16\n",
      "index: 17, token: when, token_indice17\n",
      "index: 18, token: you, token_indice18\n",
      "index: 19, token: your, token_indice19\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: ',', 4: 'a', 5: 'and', 6: 'bad', 7: 'good', 8: 'got', 9: 'have', 10: 'health', 11: 'is', 12: 'life', 13: 'lot', 14: 'money', 15: 'not', 16: 'success', 17: 'when', 18: 'you', 19: 'your'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, ',': 3, 'a': 4, 'and': 5, 'bad': 6, 'good': 7, 'got': 8, 'have': 9, 'health': 10, 'is': 11, 'life': 12, 'lot': 13, 'money': 14, 'not': 15, 'success': 16, 'when': 17, 'you': 18, 'your': 19}\n",
      "\tthreshold: 1 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: is, token_indice11\n",
      "index: 4, token: life, token_indice12\n",
      "index: 5, token: when, token_indice17\n",
      "index: 6, token: you, token_indice18\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: 'is', 4: 'life', 5: 'when', 6: 'you'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, 'is': 3, 'life': 4, 'when': 5, 'you': 6}\n",
      "\tthreshold: 2 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: is, token_indice11\n",
      "index: 4, token: life, token_indice12\n",
      "index: 5, token: when, token_indice17\n",
      "index: 6, token: you, token_indice18\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: 'is', 4: 'life', 5: 'when', 6: 'you'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, 'is': 3, 'life': 4, 'when': 5, 'you': 6}\n",
      "\tthreshold: 2 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: is, token_indice11\n",
      "index: 4, token: life, token_indice12\n",
      "index: 5, token: when, token_indice17\n",
      "index: 6, token: you, token_indice18\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: 'is', 4: 'life', 5: 'when', 6: 'you'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, 'is': 3, 'life': 4, 'when': 5, 'you': 6}\n",
      "\tthreshold: 2 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: is, token_indice11\n",
      "index: 4, token: life, token_indice12\n",
      "index: 5, token: when, token_indice17\n",
      "index: 6, token: you, token_indice18\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: 'is', 4: 'life', 5: 'when', 6: 'you'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, 'is': 3, 'life': 4, 'when': 5, 'you': 6}\n",
      "\tthreshold: 2 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: is, token_indice11\n",
      "index: 4, token: life, token_indice12\n",
      "index: 5, token: when, token_indice17\n",
      "index: 6, token: you, token_indice18\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: 'is', 4: 'life', 5: 'when', 6: 'you'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, 'is': 3, 'life': 4, 'when': 5, 'you': 6}\n",
      "\tthreshold: 2 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "index: 3, token: is, token_indice11\n",
      "index: 4, token: life, token_indice12\n",
      "index: 5, token: when, token_indice17\n",
      "index: 6, token: you, token_indice18\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>', 3: 'is', 4: 'life', 5: 'when', 6: 'you'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2, 'is': 3, 'life': 4, 'when': 5, 'you': 6}\n",
      "\tthreshold: 2 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2}\n",
      "\tthreshold: 3 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2}\n",
      "\tthreshold: 3 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2}\n",
      "\tthreshold: 3 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2}\n",
      "\tthreshold: 3 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2}\n",
      "\tthreshold: 3 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "self.map_token_to_unigram_frequency: {'your': 1, 'life': 2, 'is': 2, 'good': 1, 'when': 2, 'you': 2, 'have': 1, 'money': 1, ',': 1, 'success': 1, 'and': 1, 'health': 1, 'bad': 1, 'got': 1, 'not': 1, 'a': 1, 'lot': 1}\n",
      "[(',', 1), ('a', 1), ('and', 1), ('bad', 1), ('good', 1), ('got', 1), ('have', 1), ('health', 1), ('is', 2), ('life', 2), ('lot', 1), ('money', 1), ('not', 1), ('success', 1), ('when', 2), ('you', 2), ('your', 1)]\n",
      "index: 0, token: <PAD>, token_indice0\n",
      "index: 1, token: <END>, token_indice1\n",
      "index: 2, token: <UNK>, token_indice2\n",
      "self.idx2word: {0: '<PAD>', 1: '<END>', 2: '<UNK>'}\n",
      "self.word2idx: {'<PAD>': 0, '<END>': 1, '<UNK>': 2}\n",
      "\tthreshold: 3 \tmax_len: 15 \tidx: 1 \tPASSED \t\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "def sanityCheckDataSet():\n",
    "    #\tRead in the sample corpus\n",
    "    reviews = [('pos', 'Your life is good when you have money, success and health'),\n",
    "               ('neg', 'Life is bad when you got not a lot')]\n",
    "    data = [(x[0], preprocess(x[1])) for x in reviews]\n",
    "    print(\"Sample dataset:\")\n",
    "    for x in data: print(x)\n",
    "\n",
    "    thresholds = [1,2,3]\n",
    "    print('\\n--- TEST: idx2word and word2idx dictionaries ---') # max_len does not matter for this test\n",
    "    correct = [[',', '<END>', '<PAD>', '<UNK>', 'a', 'and', 'bad', 'good', 'got', 'have', 'health', 'is', 'life', 'lot', 'money', 'not', 'success', 'when', 'you', 'your'], ['<END>', '<PAD>', '<UNK>', 'is', 'life', 'when', 'you'], ['<END>', '<PAD>', '<UNK>']]\n",
    "    for i in range(len(thresholds)):\n",
    "        dataset = TextDataset(data, 'train', threshold=thresholds[i], max_len=3)\n",
    "\n",
    "        has_passed, message = True, ''\n",
    "        if has_passed and (dataset.vocab_size != len(dataset.word2idx) or dataset.vocab_size != len(dataset.idx2word)):\n",
    "            has_passed, message = False, 'dataset.vocab_size (' + str(dataset.vocab_size) + ') must be the same length as dataset.word2idx (' + str(len(dataset.word2idx)) + ') and dataset.idx2word ('+str(len(dataset.idx2word)) +').'\n",
    "        if has_passed and (dataset.vocab_size != len(correct[i])):\n",
    "            has_passed, message = False, 'Your vocab size is incorrect. Expected: ' + str(len(correct[i])) + '\\tGot: ' + str(dataset.vocab_size)\n",
    "        if has_passed and sorted(list(dataset.idx2word.keys())) != list(range(0, dataset.vocab_size)):\n",
    "            has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(dataset.idx2word.keys())))\n",
    "        if has_passed and sorted(list(dataset.word2idx.keys())) != correct[i]:\n",
    "            has_passed, message = False, 'Your dataset.word2idx has incorrect keys. Expected: ' + str(correct[i]) + '\\tGot: ' + str(sorted(list(dataset.word2idx.keys())))\n",
    "        if has_passed: # Check that word2idx and idx2word are consistent\n",
    "            widx = sorted(list(dataset.word2idx.items())) \n",
    "            idxw = sorted(list([(v,k) for k,v in dataset.idx2word.items()]))\n",
    "            if not (len(widx) == len(idxw) and all([widx[q] == idxw[q] for q in range(len(widx))])):\n",
    "                has_passed, message = False, 'Your dataset.word2idx and dataset.idx2word are not consistent. dataset.idx2word: ' + str(dataset.idx2word) + '\\tdataset.word2idx: ' + str(dataset.word2idx)\n",
    "\n",
    "        status = 'PASSED' if has_passed else 'FAILED'\n",
    "        print('\\tthreshold:', thresholds[i], '\\tmax_len:', 3, '\\t'+status, '\\t'+message)\n",
    "    \n",
    "    print('\\n--- TEST: len(dataset) ---')\n",
    "    has_passed = len(dataset) == 2\n",
    "    if has_passed: print('\\tPASSED')\n",
    "    else: print('\\tlen(dataset) is incorrect. Expected: 2\\tGot: ' + str(len(dataset)))\n",
    "\n",
    "    print('\\n--- TEST: __getitem__(self, idx) ---')\n",
    "    max_lens = [3,8,15]\n",
    "    idxes = [0,1]\n",
    "    combos = [{'threshold': t, 'max_len': m, 'idx': idx} for t in thresholds for m in max_lens for idx in idxes]\n",
    "    correct = [(torch.tensor([3, 4, 5]), torch.tensor(1)), (torch.tensor([ 4,  5, 15]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  1,  0,  0]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18, 19,  1,  0,  0,  0,  0,  0]), torch.tensor(0)), (torch.tensor([2, 3, 4]), torch.tensor(1)), (torch.tensor([3, 4, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0)), (torch.tensor([2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0))]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(combos)):\n",
    "        combo = combos[i]\n",
    "        dataset = TextDataset(data, 'train', threshold=combo['threshold'], max_len=combo['max_len'])\n",
    "        returned = dataset.__getitem__(combo['idx'])\n",
    "\n",
    "        has_passed, message = True, ''\n",
    "        if has_passed and len(returned) != 2:\n",
    "            has_passed, message = False, 'dataset.__getitem__(idx) must return 2 things. Got ' + str(len(returned)) +' things instead.'\n",
    "        if has_passed and (type(returned[0]) != torch.Tensor or type(returned[1]) != torch.Tensor):\n",
    "            has_passed, message = False, 'Both returns must be of type torch.Tensor. Got: (' + str(type(returned[0])) + ', ' + str(type(returned[1])) + ')'\n",
    "        if has_passed and (returned[0].shape != correct[i][0].shape):\n",
    "            has_passed, message = False, 'Shape of first return is incorrect. Expected: ' + str(correct[i][0].shape) + '.\\tGot: ' + str(returned[0].shape)\n",
    "        if has_passed and (returned[1].shape != correct[i][1].shape):\n",
    "            has_passed, message = False, 'Shape of second return is incorrect. Expected: ' + str(correct[i][1].shape) + '.\\tGot: ' + str(returned[1].shape) + '\\n\\t\\tHint: torch.Size([]) means that the tensor should be dimensionless (just a number). Try squeezing your result.'\n",
    "        if has_passed and (returned[1] != correct[i][1]):\n",
    "            has_passed, message = False, 'Label (second return) is incorrect. Expected: ' + str(correct[i][1]) + '.\\tGot: ' + str(returned[1])\n",
    "        if has_passed:\n",
    "            correct_padding_idxes, your_padding_idxes = torch.where(correct[i][0] == 0)[0], torch.where(returned[0] == dataset.word2idx[PAD])[0]\n",
    "            if not (correct_padding_idxes.shape == your_padding_idxes.shape and torch.all(correct_padding_idxes == your_padding_idxes)):\n",
    "                has_passed, message = False, 'Padding is not correct. Expected padding indxes: ' + str(correct_padding_idxes) + '.\\tYour padding indexes: ' + str(your_padding_idxes)\n",
    "\n",
    "        status = 'PASSED' if has_passed else 'FAILED'\n",
    "        print('\\tthreshold:', combo['threshold'], '\\tmax_len:', combo['max_len'] , '\\tidx:', combo['idx'], '\\t'+status, '\\t'+message)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sanityCheckDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR4VQbQCNZH6"
   },
   "source": [
    "The following cell builds the dataset on the IMDb movie reviews and prints an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HSxpGXj6ml9N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 19002 \n",
      "\n",
      "Example text:\n",
      "['**', 'Warning', '-', 'this', 'post', 'may', 'contain', 'spoilers', '**<br', '/><br', '/>I', 'only', 'got', 'a', 'Gamecube', 'in', 'September', '2005', ',', 'and', 'the', 'first', 'two', 'games', 'I', 'bought', 'were', 'James', 'Bond', 'games', ',', 'the', 'decent', 'Agent', 'Under', 'Fire', 'and', 'the', 'dull', 'Goldeneye', 'Rogue', 'Agent', '.', 'The', 'next', 'game', 'I', 'planned', 'to', 'get', 'was', 'Everything', 'or', 'Nothing', ',', 'because', 'my', 'friend', 'told', 'me', 'that', 'it', 'was', 'better', 'than', 'the', 'two', 'games', 'I', 'already', 'had', '.', 'I', 'have', 'to', 'say', ',', 'he', 'was', 'right', '.', '<br', '/><br', '/>I', 'bought', 'this', 'for', 'a', 'tenner', 'in', 'HMV', ',', 'and', 'when', 'I', 'got', 'home', ',', 'I', 'slammed', 'it', 'in', 'to', 'my', 'Cube', 'and', 'played', 'it', 'for', 'hours', 'on', 'end', '.', 'It', 'was', 'much', 'better', 'than', 'my', 'other', 'two', 'games', ',', 'and', 'there', 'was', 'a', 'much', 'better', 'and', 'more', 'interesting', 'storyline', '.', 'Graphics', 'were', 'some', 'of', 'the', 'best', 'I', 'have', 'seen', '(', 'but', 'now', 'that', 'the', 'XBOX', '360', 'has', 'come', 'out', ',', 'Farcry', 'Instincts', 'Predator', 'has', 'some', 'of', 'the', 'best', 'graphics', 'known', 'to', 'man)', '.', 'The', 'storyline', 'was', 'clever', ';', 'mad', 'man', '(', 'Willem', 'Dafoe', ',', 'named', 'as', 'Nikolai', 'Diavolo', ')', 'and', 'beautiful', 'henchwoman', '(', 'Heidi', 'Klum', ',', 'named', 'as', 'Katya', 'Nadanova)', ',', 'try', 'to', 'destroy', 'the', 'world', 'with', 'tiny', 'nanobots', ',', 'which', 'at', 'the', 'start', 'of', 'the', 'game', ',', 'you', ',', 'James', 'Bond', ',', 'have', 'to', 'destroy', 'on', 'a', 'train', '.', 'The', 'bad', 'thing', 'is', 'that', 'one', 'of', 'them', 'is', 'hidden', 'in', \"Katya's\", 'boobs', '.', 'You', 'then', 'have', 'to', 'thwart', 'their', 'plans', 'and', 'save', 'the', 'world.<br', '/><br', '/>The', 'great', 'thing', 'about', 'this', 'game', 'is', 'that', 'it', 'actually', 'has', 'actors', 'voicing', 'the', 'characters', ',', 'such', 'as', 'Cleese', 'voicing', 'Q', '.', 'There', 'are', '27', 'levels', ',', 'some', 'of', 'them', 'short', 'and', 'some', 'of', 'them', 'pretty', 'long', 'and', 'tricky.<br', '/><br', '/>Gameplay', '-', '10/10', 'Graphics', '-', '9/10', 'Sound', '-', '9/10', 'Replay', 'value', '-', '7/10', 'Multiplayer', '-', '8/10<br', '/><br', '/>I', 'give', 'this', 'game', 'a', 'grand', 'total', 'of', '90%']\n",
      "tensor([   27, 18362,    42, 17089, 13012, 10745,  4052, 15983,     2,    89,\n",
      "          208, 12006,  7606,   701,     2,  8800, 15065,   556,    39,  1274,\n",
      "        17004,  6782, 17637,  7271,  8616,  2535, 18513,  9326,  2460,  7271,\n",
      "           39, 17004,  4723,  1024, 17726,  6773,  1274, 17004,  5590,  7556,\n",
      "        14448,  1024,    47, 17004, 11629,  7266,  8616, 12809, 17247,  7404,\n",
      "        18377,  6189, 12058, 11761,    39,  2074, 11421,  7132, 17272, 10782,\n",
      "        16992,  9260, 18377,  2220, 16984, 17004, 17637,  7271,  8616,  1175,\n",
      "         7882,    47,  8616,  8073, 17247, 14764,    39,  8097, 18377, 14339,\n",
      "           47,   694,    89,   208,  2535, 17089,  6960,   701,     2,  8800,\n",
      "            2,    39,  1274, 18541,  8616,  7606,  8401,    39,  8616, 15549,\n",
      "         9260,  8800, 17247, 11421,  4455,  1274, 12830,  9260,  6960,  8507,\n",
      "        11979,  5932,    47,  9260, 18377, 11346,  2220, 16984, 11421, 12120,\n",
      "        17637,  7271,    39,  1274, 17043, 18377,   701, 11346,  2220,  1274,\n",
      "        11236,  9092, 16284,    47,  7668, 18513, 15780, 11907, 17004,  2203,\n",
      "         8616,  8073, 14980,    24,  2841, 11788, 16992, 17004,     2,   594])\n",
      "\n",
      "Example label:\n",
      "pos\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_dataset = TextDataset(train_data, 'train', threshold=10, max_len=150)\n",
    "    print('Vocab size:', train_dataset.vocab_size, '\\n')\n",
    "\n",
    "    randidx = random.randint(0, len(train_dataset)-1)\n",
    "    text, label = train_dataset[randidx]\n",
    "    print('Example text:')\n",
    "    print(train_data[randidx][1])\n",
    "    print(text)\n",
    "    print('\\nExample label:')\n",
    "    print(train_data[randidx][0])\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_4FFhulaAod"
   },
   "source": [
    "# Step 3: Train a Convolutional Neural Network (CNN) [40 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcSKydlClwOC"
   },
   "source": [
    "## <font color='red'>TODO:</font> Define the CNN Model [20 points]\n",
    "Here you will define your convolutional neural network for text classification. We provide you with the CNN class, you need to fill in parts of the `__init__(...)` and `forward(...)` functions. Each of these functions is worth 10 points.\n",
    "\n",
    "We have provided you with instructions and hints in the comments. In particular, pay attention to the desired shapes; you may find it helpful to print the shape of the tensors as you code. It may also help to keep PyTorch documentation open for the modules & functions you are using, since they describe input and output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0ztuy2hUaAof"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, out_channels, filter_heights, stride, dropout, num_classes, pad_idx):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        ##### TODO #####\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
    "        # print(f\" vocab size is: {vocab_size}, embed size is: {embed_size}, filter heights: {filter_heights}\")\n",
    "        # number of embeddings = vocab size??\n",
    "        # embedding size = embed size? = max len??\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=pad_idx)\n",
    "        # self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        #self.embedding is learnable\n",
    "\n",
    "        # print(f\"weights of embedding: {self.embedding.weight}\")\n",
    "\n",
    "\n",
    "        # Define multiple Convolution layers (nn.Conv2d) with filter (kernel) size [filter_height, embed_size] based on your \n",
    "        #   different filter_heights.\n",
    "        # Input channels will be 1 and output channels will be out_channels (these many different filters will be trained\n",
    "        #   for each convolution layer)\n",
    "\n",
    "\n",
    "        # If you want, you can store a list of modules inside nn.ModuleList.\n",
    "        self.conv_module_list = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(filter_height, embed_size), stride=stride) for filter_height in filter_heights])\n",
    "        # print(f\"conv module list is: {self.conv_module_list}\")\n",
    "\n",
    "        self.conv_model_outputs = {}\n",
    "\n",
    "        # conv module list is: ModuleList(\n",
    "        #                                   (0): Conv2d(1, 32, kernel_size=(3, 32), stride=(1, 1))\n",
    "        #                                   (1): Conv2d(1, 32, kernel_size=(4, 32), stride=(1, 1))\n",
    "        #                                   (2): Conv2d(1, 32, kernel_size=(5, 32), stride=(1, 1))\n",
    "        #                                 )\n",
    "\n",
    "        # self.maxpool = nn.MaxPool1d(2)\n",
    "\n",
    "        # Note: even though your conv layers are nn.Conv2d, we are doing a 1d convolution since we are only moving the filter \n",
    "        #   in one direction\n",
    "\n",
    "        # Create a dropout layer (nn.Dropout) using dropout\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "        # Define a linear layer (nn.Linear) that consists of num_classes units\n",
    "        #   and takes as input the $concatenated output$ for all cnn layers (out_channels * num_of_cnn_layers units) ???\n",
    "        # print(f\"out_channels * len(filter_heights), :{out_channels * len(filter_heights)}\")\n",
    "        self.dense_layer = nn.Linear(out_channels * len(filter_heights), num_classes)\n",
    "        # another dense layer\n",
    "        # self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, texts):\n",
    "        \"\"\"\n",
    "        texts: LongTensor [batch_size, max_len]\n",
    "        \n",
    "        Returns output: Tensor [batch_size, num_classes]\n",
    "\n",
    "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
    "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
    "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
    "        #   Apply non-linearity on it (F.relu() is a commonly used one. Feel free to try others)\n",
    "        #   Take the max value across last dimension to have shape [batch_size, out_channels]\n",
    "        # Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
    "        #\n",
    "        \"\"\"\n",
    "        ##### TODO #####\n",
    "        # print('Content of texts:', texts)\n",
    "        # print('Shape of texts:', texts.shape, '\\n')\n",
    "        # print('Type of texts:', texts.dtype, '\\n')\n",
    "\n",
    "        texts = texts.type(torch.int64)\n",
    "        final_embedding = self.embedding(texts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print('Content of embedding:', final_embedding)\n",
    "        # print('Shape of embedding:', final_embedding.shape, '\\n')\n",
    "        # print('Type of embedding:', final_embedding.dtype, '\\n')\n",
    "        # Resulting: shape: [batch_size, max_len, embed_size]\n",
    "        # Shape of embedding: torch.Size([1, 150, 16])\n",
    "\n",
    "\n",
    "        # Input to conv should have 1 channel. Take a look at torch's unsqueeze() function\n",
    "        #   Resulting shape: [batch_size, 1, MAX_LEN, embed_size]\n",
    "        y = torch.unsqueeze(final_embedding, 1)\n",
    "        # print('Shape of unsqueeze:', y.shape, '\\n')  #CORRECT\n",
    "\n",
    "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
    "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
    "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
    "        #   Apply non-linearity on it (F.relu() is a commonly used\n",
    "        #   one. Feel free to try others)\n",
    "\n",
    "        list_to_be_concatenated = []\n",
    "\n",
    "        for i, conv_model in enumerate(self.conv_module_list):\n",
    "\n",
    "            # Shape of x: torch.Size([1, 32, 148, 1])   #148 = * = depends on filter_height and stride\n",
    "            # Shape of x1_squeezed: torch.Size([1, 32, 148])\n",
    "            # Shape of x1_squeezed_relu: torch.Size([1, 32, 148])\n",
    "\n",
    "            # print(f\"i: {i}, conv_model: {conv_model}\")\n",
    "            x = conv_model(y)\n",
    "            # print('Shape of x:', x.shape, '\\n')  #\n",
    "\n",
    "            x1_squeezed = torch.squeeze(x, dim=3)\n",
    "            # print('Shape of x1_squeezed:', x1_squeezed.shape, '\\n')\n",
    "\n",
    "            x1_squeezed_relu = F.relu(x1_squeezed) #??? #TODO: apply non linearity here??\n",
    "            # print('Shape of x1_squeezed_relu:', x1_squeezed_relu.shape, '\\n')\n",
    "\n",
    "            #   Take the max value across last dimension to have shape [batch_size, out_channels] ??? #TODO: how and why?\n",
    "            # torch.nn.functional.max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)\n",
    "            maxpool_values, maxpool_indices = F.max_pool1d(x1_squeezed_relu, x1_squeezed_relu.shape[2], return_indices=True)\n",
    "            # print(f\"maxpool_values is: {maxpool_values}\")\n",
    "            # print(f\"maxpool_values.shape: {maxpool_values.shape}\")\n",
    "\n",
    "            # print(f\"maxpool_indices is: {maxpool_indices}, maxpool_indices.shape: {maxpool_indices.shape}\")\n",
    "\n",
    "            maxpool_values_squeezed = torch.squeeze(maxpool_values, dim=2)\n",
    "            # print(f\" maxpool_values_squeezed is: {maxpool_values_squeezed}, maxpool_values_squeezed.shape: {maxpool_values_squeezed.shape}\")\n",
    "            list_to_be_concatenated.append(maxpool_values_squeezed)\n",
    "\n",
    "        ##########\n",
    "        # i: 0, conv_model: Conv2d(1, 32, kernel_size=(3, 16), stride=(1, 1))\n",
    "        # i: 1, conv_model: Conv2d(1, 32, kernel_size=(4, 16), stride=(1, 1))\n",
    "        # i: 2, conv_model: Conv2d(1, 32, kernel_size=(5, 16), stride=(1, 1))\n",
    "        # shape of tensor: torch.Size([1, 32, 148])\n",
    "        # shape of tensor: torch.Size([1, 32, 147])\n",
    "        # shape of tensor: torch.Size([1, 32, 146])\n",
    "        ##########\n",
    "        #  Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
    "        list_to_be_concatenated_tensor = torch.cat([i for i in list_to_be_concatenated], dim=1)\n",
    "\n",
    "        # print(f\"list_to_be_concatenated_tensor is: {list_to_be_concatenated_tensor}, shape: {list_to_be_concatenated_tensor.shape}\")\n",
    "        # print(f\"list_to_be_concatenated_tensor: {list_to_be_concatenated_tensor.shape}\")\n",
    "\n",
    "        #  #print shapes\n",
    "        # for tensor in list_to_be_concatenated:\n",
    "        #     print(f\"shape of tensor: {tensor.shape}\")\n",
    "\n",
    "        #[batch_size, (out_channels*num_of_cnn_layers)]\n",
    "        # shape of tensor: torch.Size([20, 32])\n",
    "        # shape of tensor: torch.Size([20, 32])\n",
    "        # shape of tensor: torch.Size([20, 32])\n",
    "        # list_to_be_concatenated_tensor: torch.Size([20, 96])\n",
    "\n",
    "\n",
    "        # Let's understand what you just did:\n",
    "        #   Since each cnn is of different filter_height, it will look at different number of words at a time\n",
    "        #     So, a filter_height of 3 means your cnn looks at 3 words (3-grams) at a time and tries to extract some information from it\n",
    "        #   Each cnn will learn out_channels number of features from the words it sees at a time\n",
    "        #   Then you applied a non-linearity and took the max value for all channels\n",
    "        #     You are essentially trying to find important n-grams from the entire text\n",
    "        # Everything happens on a batch simultaneously hence you have that additional batch_size as the first dimension\n",
    "\n",
    "\n",
    "        # flattened_tensor = torch.flatten(list_to_be_concatenated_tensor)\n",
    "        # print(f\"flattened_tensor is: {flattened_tensor}, shape: {flattened_tensor.shape}\")\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = self.dropout_layer(list_to_be_concatenated_tensor)\n",
    "        # print(f\"dropout is: {dropout}, shape: {dropout.shape}\")\n",
    "\n",
    "        # Pass your output through the linear layer and return its output \n",
    "        #   Resulting shape: [batch_size, num_classes]\n",
    "        # x = self.dense_layer(self.relu(x))\n",
    "\n",
    "        linear = (self.dense_layer(dropout))\n",
    "        # print(f\"linear is: {linear}, shape: {linear.shape}, linear dtype: {linear.dtype}\")\n",
    "\n",
    "\n",
    "        # linear = linear.type(torch.int32)\n",
    "\n",
    "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
    "\n",
    "\n",
    "        return linear\n",
    "        # return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mVE_ujfnh0w"
   },
   "source": [
    "##Sanity Check: CNN Model\n",
    "\n",
    "The code below runs a sanity check for your `CNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yy9oF6qUUHvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "count_parameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def sanityCheckModel(all_test_params, NN, expected_outputs, init_or_forward, data_loader):\n",
    "    # print('--- TEST: ' + ('Number of Model Parameters (tests __init__(...))' if init_or_forward=='init' else 'Output shape of forward(...)') + ' ---')\n",
    "    \n",
    "    if init_or_forward == \"forward\":\n",
    "        # Reading the first batch of data for testing\n",
    "        for texts_, labels_ in data_loader:\n",
    "            texts_batch, labels_batch = texts_, labels_\n",
    "            break\n",
    "\n",
    "    for tp_idx, (test_params, expected_output) in enumerate(zip(all_test_params, expected_outputs)):       \n",
    "        if init_or_forward == \"forward\":\n",
    "            batch_size = test_params['batch_size']\n",
    "            texts = texts_batch[:batch_size]\n",
    "\n",
    "        # Construct the student model\n",
    "        tps = {k:v for k, v in test_params.items() if k != 'batch_size'}\n",
    "        stu_nn = NN(**tps)\n",
    "\n",
    "        if init_or_forward == \"forward\":\n",
    "            with torch.no_grad(): \n",
    "                stu_out = stu_nn(texts)\n",
    "            ref_out_shape = expected_output\n",
    "\n",
    "            has_passed = torch.is_tensor(stu_out)\n",
    "            if not has_passed: msg = 'Output must be a torch.Tensor; received ' + str(type(stu_out))\n",
    "            else: \n",
    "                has_passed = stu_out.shape == ref_out_shape\n",
    "                msg = 'Your Output Shape: ' + str(stu_out.shape)\n",
    "            \n",
    "\n",
    "            status = 'PASSED' if has_passed else 'FAILED'\n",
    "            message = '\\t' + status + \"\\t Init Input: \" + str({k:v for k,v in tps.items()}) + '\\tForward Input Shape: ' + str(texts.shape) + '\\tExpected Output Shape: ' + str(ref_out_shape) + '\\t' + msg\n",
    "            print(message)\n",
    "        else:\n",
    "            stu_num_params = count_parameters(stu_nn)\n",
    "            ref_num_params = expected_output\n",
    "            comparison_result = (stu_num_params == ref_num_params)\n",
    "\n",
    "            status = 'PASSED' if comparison_result else 'FAILED'\n",
    "            message = '\\t' + status + \"\\tInput: \" + str({k:v for k,v in test_params.items()}) + ('\\tExpected Num. Params: ' + str(ref_num_params) + '\\tYour Num. Params: '+ str(stu_num_params))\n",
    "            print(message)\n",
    "\n",
    "        del stu_nn\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test init\n",
    "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}]\n",
    "    expected_outputs = [22434, 22531, 22434, 22531, 23874, 23939, 23874, 23939, 41730, 42115, 41730, 42115, 47490, 47747, 47490, 47747, 44578, 44675, 44578, 44675, 47554, 47619, 47554, 47619, 82306, 82691, 82306, 82691, 94210, 94467, 94210, 94467]\n",
    "\n",
    "    sanityCheckModel(inputs, CNN, expected_outputs, \"init\", None)\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}]\n",
    "    expected_outputs = [torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2])]\n",
    "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
    "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    sanityCheckModel(inputs, CNN, expected_outputs, \"forward\", sanity_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyModule(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MyModule, self).__init__()\n",
    "#         self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         # ModuleList can act as an iterable, or be indexed using ints\n",
    "#         for i, l in enumerate(self.linears):\n",
    "#             print(f\"i: {i}, l: {l}\")\n",
    "#\n",
    "#             first_part = self.linears[i // 2](x)\n",
    "#             second_part =  l(x)\n",
    "#             x = first_part + second_part\n",
    "#\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_object = MyModule()\n",
    "# test_object.forward(torch.ones(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FupiBIfasCu_"
   },
   "source": [
    "## Train CNN Model\n",
    "\n",
    "First, we initialize the train and test <b>dataloaders</b>. A dataloader is responsible for providing batches of data to your model. Notice how we first instantiate datasets for the train and test data, and that we use the training vocabulary for both.\n",
    "\n",
    "You do not need to edit this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J2QYl334n9ON"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    THRESHOLD = 5 # Don't change this\n",
    "    MAX_LEN = 200 # Don't change this\n",
    "    BATCH_SIZE = 128 # Feel free to try other batch sizes\n",
    "\n",
    "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvsctopWmeoY"
   },
   "source": [
    "Now we provide you with a function that takes your model and trains it on the data.\n",
    "\n",
    "You do not need to edit this cell. However, you may want to write code to save your model periodically, as Colab connections are not permanent. See the tutorial here if you wish to do this: https://pytorch.org/tutorials/beginner/saving_loading_models.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LD-Jj2rUFOzr"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(model, num_epochs, data_loader, optimizer, criterion):\n",
    "    print('Training Model...')\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for texts, labels in data_loader:\n",
    "            texts = texts.to(DEVICE) # shape: [batch_size, MAX_LEN]\n",
    "            labels = labels.to(DEVICE) # shape: [batch_size]\n",
    "            # print(f\"labels is: {labels}, labels shape: {labels.shape}, labels dtype: {labels.dtype}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(texts)\n",
    "            # print(f\"output is: {output}, output shape: {output.shape}, output dtype: {output.dtype}\")\n",
    "\n",
    "            acc = accuracy(output, labels)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}\\t Train Accuracy: {:.2f}%'.format(epoch+1, epoch_loss/len(data_loader), 100*epoch_acc/len(data_loader)))\n",
    "    print('Model Trained!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyIZS0WUhFA6"
   },
   "source": [
    "Here are some other helper functions we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zVP2scuyhG5f"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    output: Tensor [batch_size, n_classes]\n",
    "    labels: LongTensor [batch_size]\n",
    "    \"\"\"\n",
    "    preds = output.argmax(dim=1) # find predicted class\n",
    "    correct = (preds == labels).sum().float() # convert into float for division \n",
    "    acc = correct / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjvX5c6Isw9e"
   },
   "source": [
    "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M5UtdjGDuBty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,879,746 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    cnn_model = CNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
    "                embed_size = 128, \n",
    "                out_channels = 64, \n",
    "                filter_heights = [2, 3, 4], \n",
    "                stride = 1, \n",
    "                dropout = 0.5, \n",
    "                num_classes = 2, # Don't change this\n",
    "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
    "\n",
    "    # Put your model on the device (cuda or cpu)\n",
    "    cnn_model = cnn_model.to(DEVICE)\n",
    "    \n",
    "    print('The model has {:,d} trainable parameters'.format(count_parameters(cnn_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeHpqw6zvkhI"
   },
   "source": [
    "Next, we create the **criterion**, which is our loss function: it is a measure of how well the model matches the empirical distribution of the data. We use cross-entropy loss (https://en.wikipedia.org/wiki/Cross_entropy).\n",
    "\n",
    "We also define the **optimizer**, which performs gradient descent. We use the Adam optimizer (https://arxiv.org/pdf/1412.6980.pdf), which has been shown to work well on these types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FoeyQL4PoNoH"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':    \n",
    "    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RopLfAJ9wOHN"
   },
   "source": [
    "Finally, we can train the model. If the model is implemented correctly and you're using the GPU, this cell should take around <b>4 minutes</b> (or less). Feel free to change the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6045d41ccae4e19bfbb7cfa8affbbd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]\t Epoch:  1\t Loss: 0.7348\t Train Accuracy: 55.35%\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.6034\t Train Accuracy: 67.20%\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.5507\t Train Accuracy: 71.39%\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.5116\t Train Accuracy: 74.51%\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.4816\t Train Accuracy: 76.35%\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.4566\t Train Accuracy: 78.43%\n",
      "[TRAIN]\t Epoch:  7\t Loss: 0.4284\t Train Accuracy: 80.07%\n",
      "[TRAIN]\t Epoch:  8\t Loss: 0.4076\t Train Accuracy: 81.40%\n",
      "[TRAIN]\t Epoch:  9\t Loss: 0.3856\t Train Accuracy: 82.54%\n",
      "[TRAIN]\t Epoch: 10\t Loss: 0.3655\t Train Accuracy: 83.40%\n",
      "[TRAIN]\t Epoch: 11\t Loss: 0.3465\t Train Accuracy: 84.73%\n",
      "[TRAIN]\t Epoch: 12\t Loss: 0.3193\t Train Accuracy: 86.20%\n",
      "[TRAIN]\t Epoch: 13\t Loss: 0.3095\t Train Accuracy: 86.89%\n",
      "[TRAIN]\t Epoch: 14\t Loss: 0.2861\t Train Accuracy: 88.23%\n",
      "[TRAIN]\t Epoch: 15\t Loss: 0.2614\t Train Accuracy: 89.23%\n",
      "Model Trained!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    N_EPOCHS = 15 # Feel free to change this == 20 == best\n",
    "\n",
    "    # train model for N_EPOCHS epochs\n",
    "    train_model(cnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-OJbZ72t6Yq"
   },
   "source": [
    "## Evaluate CNN Model [20 points]\n",
    "\n",
    "Now that we have trained a model for text classification, it is time to evaluate it. We have provided you with a function to do this; you do not need to modify anything.\n",
    "\n",
    "To pass the autograder for the CNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vTiiYDZIF--7"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "import random\n",
    "\n",
    "def evaluate(model, data_loader, criterion, use_tqdm=False):\n",
    "    print('Evaluating performance on the test dataset...')\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    all_predictions = []\n",
    "    print(\"\\nSOME PREDICTIONS FROM THE MODEL:\")\n",
    "    iterator = tqdm(data_loader) if use_tqdm else data_loader\n",
    "    total = 0\n",
    "    for texts, labels in iterator:\n",
    "        bs = texts.shape[0]\n",
    "        total += bs\n",
    "        texts = texts.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        output = model(texts)\n",
    "        acc = accuracy(output, labels) * len(labels)\n",
    "        pred = output.argmax(dim=1)\n",
    "        all_predictions.append(pred)\n",
    "        \n",
    "        loss = criterion(output, labels) * len(labels)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        if random.random() < 0.0015 and bs == 1:\n",
    "            print(\"Input: \"+' '.join([data_loader.dataset.idx2word[idx] for idx in texts[0].tolist() if idx not in {data_loader.dataset.word2idx[PAD], data_loader.dataset.word2idx[END]}]))\n",
    "            print(\"Prediction:\", pred.item(), '\\tCorrect Output:', labels.item(), '\\n')\n",
    "\n",
    "    full_acc = 100*epoch_acc/total\n",
    "    full_loss = epoch_loss/total\n",
    "    print('[TEST]\\t Loss: {:.4f}\\t Accuracy: {:.2f}%'.format(full_loss, full_acc))\n",
    "    predictions = torch.cat(all_predictions)\n",
    "    return predictions, full_acc, full_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Z718w8e0oNoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance on the test dataset...\n",
      "\n",
      "SOME PREDICTIONS FROM THE MODEL:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "870fe2078bde4e0ab2b32e5eac9a4435"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good movie , good music , good background and an acceptable plot . but the main point again as his movies tend to be , the man is the best actor in <UNK> and can turn dust into gold . nana <UNK> . this may be his second best performance after <UNK> others may <UNK> . although other movies are not far behind . one man that will never ever disappoint you.<br /><br />good movie although i think shahrukh was a luxury this movie could have done without . you can see in his movies , others try very hard to reach his heights and act out of their <UNK> . but this man is really something <UNK> /><br />the movie is cool , the music and direction is excellent plot a bit thin but the screen play and dialog again very good . a must watch .\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: i first heard of this movie after purchasing the 1976 flick \" <UNK> . i was told that devil's experiment was much better so naturally i went ahead and ordered the guinea pig box set . i was really interested to hear that charlie sheen had come out trying to ban either this movie or the second one , so my interest was <UNK> /><br <UNK> experiment is a short film with no story , no character development . just 3 men torturing a woman for about 45 minutes . they torture her in various ways like beating her , spinning her in circles over and over again then forcing her to drink alcohol , forcing her to listen to <UNK> noise for 24 hours , smash her hand with a mallet , burning and putting maggots on the burns , throwing guts at her , and ultimately shoving a sharp needle through her eye.<br /><br />i must say that a lot of this movie was fake , like the beating scenes . but then , some of it was actually well done as far as grossing you out . the scenes in which the woman is being spun around\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: sweet and charming , funny and poignant , plot less but meaningful , \" before sunrise \" ( 1995) , the third movie of richard <UNK> , is dedicated to everyone who ever been in love , is in love , or never been in love but still dreams of it and hopes to find it . it is one of the very rare movies that <UNK> be equally interesting to teenagers , their parents and even grandparents . it seems a very simple little movie with no spectacular visual effects , car chases , or long and steamy sex scenes . two young people in their early 20s , two college students ( american tourist ethan hawke who is returning home after the summer in europe and the french student julie <UNK> who goes to paris to attend the classes in sorbonne ) meet on a train . they are attracted to each other instantly even before they start talking , they hop off the train in vienna where they walk around exploring the city all night . they talk and fall in love . that's it , that's the movie . it could've been boring and silly but\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: sitting , <UNK> nothing is the latest \" what <UNK> \" fest offered by <UNK> natali , and starring david <UNK> and andrew miller as two losers . one is having relationship problems , got canned from his job ( because of relationship problems ) and the police are out to get him ( because of his job and his relationship <UNK> . the other guy is a <UNK> who refuses to go outside his home , is met by a bothersome girl guide who calls on her mom to claim she was molested when he doesn't buy <UNK> from him . oh yeah , the police are after him too , after the mom of the girl scout call them in to arrest him.<br /><br />man , what a day.<br /><br />what if you could make all of this disappear ? that is the whole premise behind ' <UNK> . the two fools realize , the cops , the girl scout , the cars , the lawn , the road , <UNK> disappear . there's nothing but white space ! this is an interesting concept i thought . i also looked at the time of this , 30 minutes\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: good , funny , straightforward story , excellent nicole kidman ( i almost always like the movies she's in) . this was a good \" vehicle \" for someone adept at comedy and drama since there are elements of both . a romantic comedy wrapped around two crime stories , great closing lines . chaplin , very good here , was also good in another good , but unpopular romantic comedy ( <UNK> about cats & <UNK> . maybe they're too implausible . ebert didn't even post a review for this . the great \" screwball \" comedies obviously were totally implausible ( <UNK> up baby\" , etc.) . if you've seen one implausible comedy , you've seen them all ? or maybe people are ready to move on from the 1930s . weird . birthday girl is a movie i've enjoyed several times . nicole kidman may be the \" killer <UNK> \" for home video .\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: clara <UNK> beauty and wonderful appeal are the chief reason to watch this film . \" <UNK> \" is not quite up to par with <UNK> best films but it is still enjoyable . she dances , she rides her horse , and pursues the man that she loves . this film is just over an hour in length and was directed by future oscar winner victor fleming ( gone with the <UNK> film moves quickly and clara bow has lots of screen time . if you like clara , i would reccomend \" <UNK> \"\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: there are way too many subjects avoided in cinema and eating disorders is one of them . this film shows it as it is . it is not <UNK> for the viewers to enjoy , it is shown with real truth which makes it all the more powerful . i've only seen it once and that was a few years ago but i can still remember everything about it and how it made me feel . it is a very powerful film and is good support for anyone suffering from a eating disorder to give them the willpower to stop . this is what films should be <UNK> they should be there to help people and not <UNK> things that are wrong .\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: this movie is so , so , so horrible , that it makes angels lose their wings . <UNK> had tried to make other crossover efforts , like his work in <UNK> for the <UNK> and his plethora of unbearable rap albums , and later , the epic serving of horrible film-making that is <UNK> /><br />there's not a single good thing to be said about this movie . i saw it a bunch of times when i was very young , but i must've been an idiot then , because this movie takes all that is enjoyable about films and tears it apart . it's fun to mock . i saw it on the disney channel a while back and spent a few minutes doing that . although , once the thrill of mocking it is done , you still become overwhelmed by its <UNK> /><br />if you see it on tv , try this : consider , as your watching the film , removing from it all the scenes in which <UNK> uses his magical genie powers . if you do that , it becomes like a film about a pedophile chasing a kid and <UNK> to seduce\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: you all know the story of \" <UNK> . i do . <br /><br /> well , the \" to be or not to be \" phrase ( not the speech itself ) has been beaten into the ground so many times that it's not very interesting ( in fact , it wasn't that great to begin with) . in fact , i find \" hamlet \" a good but vastly overrated play . it's not even shakespeare's best : \" julius caesar \" and \" romeo & juliet \" are ten times better , with \" a <UNK> night's dream \" and \" othello \" not too far behind . \" macbeth ( knock your table , off his <UNK> , <UNK> will make amends , <UNK> \" isn't that bad either . there are lots of others that are better than this by shakespeare.<br /><br /> i won't really comment too much on the movie , rather i will dissect the utterly horrible mst3k episode.<br /><br /> okay  .  .  . mike and the bots win a card game , get to pick the movie  .  .  . they ask for \"\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: this movie is a joke and must be one of the worst movies stallone ever made . this is a typical 80s movie where you have one man destroying the whole army by himself . \" first blood <UNK> . 2 \" is very similar to schwarzenegger's \" <UNK> , but there you have arnold killing the terrorist while here you have a specific nation showed as the bad guys . this movie is a typical american <UNK> propaganda . true , this was the peak of the cold war , but i'm sick of having communists or the nazis always being shown as the enemy . there are so many american movies that have this one thing in common . why can't there a movie that show americans as the enemy ? who's going to believe that one lone soldier will destroy the whole army ? do you really think that something like this would have really happened ? by the looks of it , an average , brain washed american viewer certainly would .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: seeing as i hate reading long <UNK> hoping to find a point and being disappointed , i will first tell everyone that this movie was terrible . downright terrible . and not , surprisingly for the reasons mentioned in the first review . i thought i might agree with him , seeing as he gave the movie the rank it deserved , but was <UNK> <UNK> upon reading what he said . i am quite ashamed to be taking the same side as someone who commented that the movie \" definitely lacks good-looking <UNK> \" let me be the first to say , \" wow ! that was definitely some serious in-depth reviewing there . my mind can hardly comprehend the philosophical musings about this movie. \" seriously though , a lack of \" good-looking females \" shouldn't be considered an essential to a movie . if you're desperate enough for \" good-looking females \" you should really watch other types of movies , not necessarily falling into the sci-fi category .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "[TEST]\t Loss: 0.3898\t Accuracy: 82.58%\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    evaluate(cnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRCFvjwDthiA"
   },
   "source": [
    "# Step 4: Train a Recurrent Neural Network (RNN) [40 points]\n",
    "You will now build a text clasification model that is based on **recurrences**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-t8tlZviV2x"
   },
   "source": [
    "## <font color='red'>TODO:</font> Define the RNN Model [20 points]\n",
    "\n",
    "First, you will define the RNN. As with the CNN, we provide you with the skeleton of the class, and you need to fill in parts of the `__init__(...)` and `forward(...)` methods. Each of these functions is worth 10 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2nc_HxbP6klI"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional, dropout, num_classes, pad_idx):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        ##### TODO #####\n",
    "\n",
    "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=pad_idx)\n",
    "        self.embed_size = embed_size\n",
    "        # Create a recurrent network (use nn.GRU, not nn.LSTM) with batch_first = True\n",
    "        # Make sure you use hidden_size, num_layers, dropout, and bidirectional here.\n",
    "        self.GRU = nn.GRU(input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout, bidirectional=bidirectional).to(DEVICE)\n",
    "\n",
    "\n",
    "        if bidirectional==True:\n",
    "            self.D =2\n",
    "        elif bidirectional==False:\n",
    "            self.D=1\n",
    "\n",
    "        # self.initial_state_h0 = 0\n",
    "\n",
    "\n",
    "        # Create a dropout layer (nn.Dropout) using dropout\n",
    "        self.dropout_layer = nn.Dropout(dropout).to(DEVICE)\n",
    "\n",
    "        # Define a linear layer (nn.Linear) that consists of num_classes units\n",
    "        #   and takes as input the output of the last timestep. In the bidirectional case, you should concatenate\n",
    "        #   the output of the last timestep of the forward direction with the output of the last timestep of the backward direction).\n",
    "\n",
    "        self.dense_layer = nn.Linear(hidden_size*self.D, num_classes).to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, texts):\n",
    "        \"\"\"\n",
    "        texts: LongTensor [batch_size, MAX_LEN]\n",
    "        \n",
    "        Returns output: Tensor [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        ##### TODO #####\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
    "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
    "        texts = texts.type(torch.int64)\n",
    "        # print('Content of embedding:', texts)\n",
    "        # print('Shape of embedding:', texts.shape, '\\n')\n",
    "        # print('Type of embedding:', texts.dtype, '\\n')\n",
    "\n",
    "        final_embedding = (self.embedding(texts))\n",
    "        final_embedding_gpu = final_embedding.to(device)\n",
    "        # print(f\"  final_embedding_gpu: {final_embedding_gpu.shape}, final_embedding_gpu dtype: {final_embedding_gpu.dtype}, final_embedding_gpu device: {final_embedding_gpu.get_device()}\")\n",
    "\n",
    "        # print('Content of embedding:', final_embedding)\n",
    "        # print('Shape of embedding:', final_embedding.shape, '\\n')\n",
    "        # print('Type of embedding:', final_embedding.dtype, '\\n')\n",
    "        batch_size, max_len = texts.shape\n",
    "        # print(f\"batch_size: {batch_size}, max_len: {max_len}\")\n",
    "        # print(f\"(batch_size, max_len, self.hidden_size): ({batch_size}, {max_len}, {self.hidden_size})\")\n",
    "\n",
    "        initial_state_h0 = torch.nn.parameter.Parameter(torch.randn(self.D*self.num_layers, batch_size, self.hidden_size)).to(device)\n",
    "        # print(f\"  initial_state_h0: {initial_state_h0.shape}, initial_state_h0 dtype: {initial_state_h0.dtype}, initial_state_h0 device: {initial_state_h0.get_device()}\")\n",
    "\n",
    "        # gru_input = torch.randn(batch_size, max_len, self.hidden_size).to(device)\n",
    "        # print(f\"  gru_input: {gru_input.shape}, gru_input dtype: {gru_input.dtype}, gru_input device: {gru_input.get_device()}\")\n",
    "        # # h_out = 32\n",
    "\n",
    "\n",
    "\n",
    "        # Pass the result through your recurrent network\n",
    "        #   See PyTorch documentation for resulting shape for nn.GRU\n",
    "        output, hn = self.GRU(final_embedding_gpu, initial_state_h0)\n",
    "        # print(f\"  output: {output.shape}, output dtype: {output.dtype}\")\n",
    "        # print(f\" hn: {hn.shape}, hn dtype: {hn.dtype}\")\n",
    "\n",
    "\n",
    "        # Concatenate the outputs of the last timestep for each direction (see torch.cat(...))\n",
    "        #   This depends on whether or not your model is bidirectional.\n",
    "        #   Resulting shape: [batch_size, num_dirs*hidden_size]\n",
    "        # concatenated_output = torch.cat([h for h in output], dim=0)\n",
    "        concatenated_output = output[:, -1, :]\n",
    "        # print(f\"concatenated_output: {concatenated_output.shape}, concatenated_output dtype: {concatenated_output.dtype}\")\n",
    "\n",
    "        # batch_size: 1, max_len: 150\n",
    "        # (batch_size, max_len, self.hidden_size): (1, 150, 32)\n",
    "        #   gru_input: torch.Size([1, 150, 16]), gru_input dtype: torch.float32\n",
    "        #   initial_state_h0: torch.Size([4, 1, 32]), initial_state_h0 dtype: torch.float32\n",
    "        #   output: torch.Size([1, 150, 64]), output dtype: torch.float32\n",
    "        #  hn: torch.Size([4, 1, 32]), hn dtype: torch.float32\n",
    "        #  concatenated_output: torch.Size([4, 32]), concatenated_output dtype: torch.float32\n",
    "        #  dropout: torch.Size([4, 32]), dropout dtype: torch.float32\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = self.dropout_layer(concatenated_output)\n",
    "        # print(f\" dropout: {dropout.shape}, dropout dtype: {dropout.dtype}\")\n",
    "\n",
    "        # Pass your output through the linear layer and return its output \n",
    "        #   Resulting shape: [batch_size, num_classes]\n",
    "        linear_output = self.dense_layer(dropout)\n",
    "        # print(f\" linear_output: {linear_output.shape}, linear_output dtype: {linear_output.dtype}\")\n",
    "\n",
    "\n",
    "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
    "\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDLTiJMyoLxJ"
   },
   "source": [
    "##Sanity Check: RNN Model\n",
    "\n",
    "The code below runs a sanity check for your `RNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Duq7X2ClwXga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44546\tYour Num. Params: 44546\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 44676\tYour Num. Params: 44676\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 27202\tYour Num. Params: 27202\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 27268\tYour Num. Params: 27268\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82178\tYour Num. Params: 82178\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 82308\tYour Num. Params: 82308\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 39874\tYour Num. Params: 39874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 39940\tYour Num. Params: 39940\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1620610\tYour Num. Params: 1620610\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1621636\tYour Num. Params: 1621636\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 621698\tYour Num. Params: 621698\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 622212\tYour Num. Params: 622212\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 3986050\tYour Num. Params: 3986050\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 3987076\tYour Num. Params: 3987076\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1411202\tYour Num. Params: 1411202\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1411716\tYour Num. Params: 1411716\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 101762\tYour Num. Params: 101762\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 101892\tYour Num. Params: 101892\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 79810\tYour Num. Params: 79810\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 79876\tYour Num. Params: 79876\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 139394\tYour Num. Params: 139394\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 139524\tYour Num. Params: 139524\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 92482\tYour Num. Params: 92482\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 92548\tYour Num. Params: 92548\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1742338\tYour Num. Params: 1742338\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1743364\tYour Num. Params: 1743364\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 706562\tYour Num. Params: 706562\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 707076\tYour Num. Params: 707076\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 4107778\tYour Num. Params: 4107778\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 4108804\tYour Num. Params: 4108804\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1496066\tYour Num. Params: 1496066\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1496580\tYour Num. Params: 1496580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test init\n",
    "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}]\n",
    "    expected_outputs = [44546, 44676, 27202, 27268, 82178, 82308, 39874, 39940, 1620610, 1621636, 621698, 622212, 3986050, 3987076, 1411202, 1411716, 101762, 101892, 79810, 79876, 139394, 139524, 92482, 92548, 1742338, 1743364, 706562, 707076, 4107778, 4108804, 1496066, 1496580]\n",
    "\n",
    "    sanityCheckModel(inputs, RNN, expected_outputs, \"init\", None)\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}]\n",
    "    expected_outputs = [torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4])]\n",
    "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
    "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    sanityCheckModel(inputs, RNN, expected_outputs, \"forward\", sanity_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baD8lYAytdTV"
   },
   "source": [
    "## Train RNN Model\n",
    "First, we initialize the train and test dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WCzNm8LDM5aT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    THRESHOLD = 5 # Don't change this\n",
    "    MAX_LEN = 200 # Don't change this\n",
    "    BATCH_SIZE = 64 # Feel free to try other batch sizes\n",
    "\n",
    "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lp5pAz8emxi2"
   },
   "source": [
    "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CA-UairGErap"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,300,546 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    rnn_model = RNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
    "                embed_size = 128, \n",
    "                hidden_size = 128, \n",
    "                num_layers = 2,\n",
    "                bidirectional = True,\n",
    "                dropout = 0.5,\n",
    "                num_classes = 2, # Don't change this\n",
    "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
    "\n",
    "    # Put your model on device\n",
    "    rnn_model = rnn_model.to(DEVICE)\n",
    "\n",
    "    print('The model has {:,d} trainable parameters'.format(count_parameters(rnn_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqngFY4MoLec"
   },
   "source": [
    "Here, we create the criterion and optimizer; as with the CNN, we use cross-entropy loss and Adam optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "em6Rs58OlJ3Z"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':    \n",
    "    LEARNING_RATE = 6e-4 # Feel free to try other learning rates\n",
    "\n",
    "    # Define your loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "    # Define your optimizer\n",
    "    optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEPsi3choUm5"
   },
   "source": [
    "Finally, we can train the model. We use the same `train_model(...)` function that we defined for the CNN. If the model is implemented correctly and you're using the GPU, this cell should take around <b>2 minutes</b> (or less). Feel free to change the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NR8Wckf0l2G7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "538ea72eae3d44768b104851ec927d4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]\t Epoch:  1\t Loss: 0.7064\t Train Accuracy: 50.78%\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.6900\t Train Accuracy: 54.33%\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.6922\t Train Accuracy: 52.60%\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.6305\t Train Accuracy: 62.04%\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.3878\t Train Accuracy: 82.97%\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.2751\t Train Accuracy: 88.84%\n",
      "[TRAIN]\t Epoch:  7\t Loss: 0.2018\t Train Accuracy: 92.42%\n",
      "Model Trained!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    N_EPOCHS = 7 # Feel free to change this\n",
    "    \n",
    "    # train model for N_EPOCHS epochs\n",
    "    train_model(rnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-SRIFfooYk6"
   },
   "source": [
    "## Evaluate RNN Model [20 points]\n",
    "\n",
    "Now we can evaluate the RNN. \n",
    "\n",
    "To pass the autograder for the RNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HYon4AbHl5_M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance on the test dataset...\n",
      "\n",
      "SOME PREDICTIONS FROM THE MODEL:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35e2a8eea9344ff48b4e5ebd7ac592b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: making a book into a movie by following the story <UNK> is never a good idea . when people read the book , they automatically start making their own \" mental movie \" of who the characters look like , the places they exist in , how the situations progress . and everybody's <UNK> opus is different , which is why when the ' real ' movie finally comes out , you're always going to have a <UNK> segment of the movie-going audience who are disappointed that it just doesn't measure up.<br /><br />all a screenwriter and a director can hope to accomplish is whatever their own vision of the movie is , and hope that it comes as close as possible to what their audience is expecting to see.<br /><br />there is no better case for this situation than the movies based on the novels of stephen king . when filmmakers capture at least the essence of his stories , the results can be breathtaking and truly terrifying ( carrie , ' <UNK> lot , the dead <UNK> , or they can be what fans consider to be a <UNK> mess ( kubrick's version of the shining ; the\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: i was bored one night and red eye was on and thought why not.<br /><br <UNK> eye is one of the best movies in a long time.<br /><br />i mean i just got into the movie cause it was just so brilliant.<br /><br />the story is new and different.<br /><br />the movie also has two great leads in the movie with rachel mcadams as lisa <UNK> and cillian murphy as jackson <UNK> /><br />the acting is just brilliant and you get the feel for the people in the movie.<br /><br />the music is just excellent , it give you chills and can also make you feel <UNK> /><br />i just love how the movie was just so well done and it never gets boring.<br /><br <UNK> eye is just phenomenal . nothing more and nothing less.<br /><br />it's a excellent thriller.<br /><br />overall , i enjoy red eye so much that i can watch it over and over again.<br /><br />if you like red eye , then i recommend <UNK> and cry <UNK> /><br />i give red eye 9 out of 10.<br /><br />great movie\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: there's more to offer in the opening of the odd couple than in the entirety of most films . felix unger ( the poor guy's monogram even curses him ) checks into a new york hotel . a cleaning lady says \" good <UNK> \" \" <UNK> \" he answers back . in his room he <UNK> his pockets , then struggles to take off his wedding ring only to put the objects neatly into an envelope , addressed to his wife and beloved children . when the viewer finally puts it together  aha , he's going to off himself  we watch him struggle to open the window  oh no , he's going to jump  the poor guy <UNK> his lower back . this is all you need to know about felix unger  his wife has left him , he's a compulsive cleaner and he's a <UNK> . and all in one scene . this is the particular genius of neil simon's comedy  it's about situation and character . there are few obvious physical jokes  no kicks to the groin , no cheap gags  just funny characters in uncomfortable situations . and\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: unlike many , i don't find the premise or theme of this show the least bit offensive . its execution , however , is another matter entirely . like so many <UNK> movies , all the decent gags appear to have been spliced into the trailers . for most of the <UNK> minutes we sit in waning anticipation any <UNK> of real humor . or at least something to keep one from <UNK> with the remote or counting carpet <UNK> . with a couple of exceptions the acting is awful ; the comical <UNK> and <UNK> of some cast members might be well suited to a late-night infomercial , but not a <UNK> sitcom ( even a canadian one. ) notwithstanding the admittedly original cultural angle , i cannot help but think this is mainly a <UNK> shot by the <UNK> to replicate the success of corner gas . unfortunately , they got the tone -- and the script -- completely wrong for the <UNK> . the final insult is that they apparently couldn't even afford to have the location work done in an actual small town ( why ? are they so hard to find in <UNK> ) did\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: this may have been made for the hell of it , but it was most probably the worst film i've seen in years , the best thing about the entire dvd would be the <UNK> ! i'm surprised that people took the time to make something so rubbish and yet spend money on it too , i'm glad i only rented . i suppose the real fans of this film would probably have to be sadistic and gothic to care about it without taking in any cgi or any other effects for that matter , i hope alex <UNK> learnt a lesson about lighting and sfx to make a better film in the future , that is , if he is still in work.<br /><br <UNK> to buyers this is extremely disappointing , don't buy <UNK> !\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: sheesh ! what a dreadful movie . dodgy camera work , a script with more corn than <UNK> , and acting so hammy you could open a pig farm with it . <br /><br />to cap it all , it doesn't know which audience to aim at - we have <UNK> wilde - or is that corny wilde ? - getting on his soap box about the <UNK> of smoking any time someone lights a cigarette , dear oh dear , and in another awkward scene we have the baddie , <UNK> , forcing his , ahem , if you will , ' male friend ' to do a striptease dressed in a bikini . try explaining that one to the <UNK> /><br />throw in an overly contrived treasure <UNK> type storyline , and the result is a film so unintentionally funny , it's enjoyable - i shouldn't expect a special edition dvd any time soon , though .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "[TEST]\t Loss: 0.4409\t Accuracy: 82.44%\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    evaluate(rnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WQAV6O2xHvS"
   },
   "source": [
    "# What to Submit\n",
    "\n",
    "To submit the assignment, download this notebook as a <TT>.py</TT> file. You can do this by going to <TT>File > Download > Download .py</TT>. Then (optionally) rename it to `hwk2.py`.\n",
    "\n",
    "You will also need to save the `cnn_model` and `rnn_model`. You can run the cell below to do this. After you save the files to your Google Drive, you need to manually download the files to your computer, and then submit them to the autograder.\n",
    "\n",
    "You will submit the following files to the autograder:\n",
    "1.   `hwk2.py`, the download of this notebook as a `.py` file (**not** a `.ipynb` file)\n",
    "1.   `cnn.pt`, the saved version of your `cnn_model`\n",
    "1.   `rnn.pt`, the saved version of your `rnn_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "abbbMNi8X_ai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving CNN model....\n",
      "Saving RNN model....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        cnn_model is None\n",
    "        cnn_exists = True\n",
    "    except:\n",
    "        cnn_exists = False\n",
    "\n",
    "    try:\n",
    "        rnn_model is None\n",
    "        rnn_exists = True\n",
    "    except:\n",
    "        rnn_exists = False\n",
    "\n",
    "    if cnn_exists:\n",
    "        print(\"Saving CNN model....\") \n",
    "        # torch.save(cnn_model, \"drive/My Drive/cnn.pt\")\n",
    "        torch.save(cnn_model, \"saved_models/cnn.pt\")\n",
    "    if rnn_exists:\n",
    "        print(\"Saving RNN model....\") \n",
    "        # torch.save(rnn_model, \"drive/My Drive/rnn.pt\")\n",
    "        torch.save(rnn_model, \"saved_models/rnn.pt\")\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "v4o5fRQELX7G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
