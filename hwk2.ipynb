{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSy-sfxOsclS"
   },
   "source": [
    "# CS 447 Homework 2 $-$ Text Classification with Neural Networks\n",
    "In this homework, you will build machine learning models to detect the sentiment of movie reviews using the IMDb movie reviews dataset. Specifically, you will implement classifiers based on Convolutional Neural Networks (CNN's) and Recurrent Neural Networks (RNN's).\n",
    "\n",
    "In addition to the Pytorch tutorial we have provided on Coursera, we highly recommend that you take a look at the PyTorch tutorials before starting this assignment:\n",
    "<ul>\n",
    "<li><a href=\"https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html</a>\n",
    "<li><a href=\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\">https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</a>\n",
    "<li><a href=\"https://github.com/yunjey/pytorch-tutorial\">https://github.com/yunjey/pytorch-tutorial</a>\n",
    "</ul>\n",
    "\n",
    "<font color='green'>While you work, we suggest that you keep your hardware accelerator set to \"CPU\" (the default for Colab). However, when you have finished debugging and are ready to train your models, you should select \"GPU\" as your runtime type. This will speed up the training of your models. You can find this by going to <TT>Runtime > Change Runtime Type</TT> and select \"GPU\" from the dropdown menu.</font>\n",
    "\n",
    "As usual, you should not import any other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EyCOvTRQ1nb-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHbJ1-aDsWCG"
   },
   "source": [
    "# Step 1: Download the Data\n",
    "First we will download the dataset using [torchtext](https://torchtext.readthedocs.io/en/latest/index.html), which is a package that supports NLP for PyTorch. \n",
    "\n",
    "Unfortunately, you have to install the <TT>torchdata</TT> package on the Colab machine in order to access the data. To do this, run the cell below (you may need to click the \"Restart Runtime\" button when it finishes). You will have to do this every time you return to work on the homework.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rT4n4QzHAYe_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (0.4.1)\r\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (1.26.11)\r\n",
      "Requirement already satisfied: portalocker>=2.0.0 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (2.5.1)\r\n",
      "Requirement already satisfied: torch==1.12.1 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (1.12.1)\r\n",
      "Requirement already satisfied: requests in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torchdata) (2.28.1)\r\n",
      "Requirement already satisfied: typing_extensions in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from torch==1.12.1->torchdata) (4.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from requests->torchdata) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from requests->torchdata) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kulbir/anaconda3/envs/nlp_cuda116_python3_9/lib/python3.9/site-packages (from requests->torchdata) (3.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMVBA0ijAUgt"
   },
   "source": [
    "The following cell will get you `train_data` and `test_data`. It also does some basic tokenization.\n",
    "\n",
    "*   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n",
    "*   To access the label for the *i*th example, use `train_data[i][0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dfX3bNby8FYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Train Examples: 20000\n",
      "Num. Test Examples: 5000\n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Zentropa', 'has', 'much', 'in', 'common', 'with', 'The', 'Third', 'Man', ',', 'another', 'noir-like', 'film', 'set', 'among', 'the', 'rubble', 'of', 'postwar', 'Europe', '.', 'Like', 'TTM', ',', 'there', 'is', 'much', 'inventive', 'camera', 'work', '.', 'There', 'is', 'an', 'innocent', 'American', 'who', 'gets', 'emotionally', 'involved', 'with', 'a', 'woman', 'he', \"doesn't\", 'really', 'understand', ',', 'and', 'whose', 'naivety', 'is', 'all', 'the', 'more', 'striking', 'in', 'contrast', 'with', 'the', 'natives.<br', '/><br', '/>But', \"I'd\", 'have', 'to', 'say', 'that', 'The', 'Third', 'Man', 'has', 'a', 'more', 'well-crafted', 'storyline', '.', 'Zentropa', 'is', 'a', 'bit', 'disjointed', 'in', 'this', 'respect', '.', 'Perhaps', 'this', 'is', 'intentional', ':', 'it', 'is', 'presented', 'as', 'a', 'dream/nightmare', ',', 'and', 'making', 'it', 'too', 'coherent', 'would', 'spoil', 'the', 'effect', '.', '<br', '/><br', '/>This', 'movie', 'is', 'unrelentingly', 'grim--\"noir', '\"', 'in', 'more', 'than', 'one', 'sense', ';', 'one', 'never', 'sees', 'the', 'sun', 'shine', '.', 'Grim', ',', 'but', 'intriguing', ',', 'and', 'frightening', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Zentropa', 'is', 'the', 'most', 'original', 'movie', \"I've\", 'seen', 'in', 'years', '.', 'If', 'you', 'like', 'unique', 'thrillers', 'that', 'are', 'influenced', 'by', 'film', 'noir', ',', 'then', 'this', 'is', 'just', 'the', 'right', 'cure', 'for', 'all', 'of', 'those', 'Hollywood', 'summer', 'blockbusters', 'clogging', 'the', 'theaters', 'these', 'days', '.', 'Von', \"Trier's\", 'follow-ups', 'like', 'Breaking', 'the', 'Waves', 'have', 'gotten', 'more', 'acclaim', ',', 'but', 'this', 'is', 'really', 'his', 'best', 'work', '.', 'It', 'is', 'flashy', 'without', 'being', 'distracting', 'and', 'offers', 'the', 'perfect', 'combination', 'of', 'suspense', 'and', 'dark', 'humor', '.', \"It's\", 'too', 'bad', 'he', 'decided', 'handheld', 'cameras', 'were', 'the', 'wave', 'of', 'the', 'future', '.', \"It's\", 'hard', 'to', 'say', 'who', 'talked', 'him', 'away', 'from', 'the', 'style', 'he', 'exhibits', 'here', ',', 'but', \"it's\", \"everyone's\", 'loss', 'that', 'he', 'went', 'into', 'his', 'heavily', 'theoretical', 'dogma', 'direction', 'instead', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Lars', 'Von', 'Trier', 'is', 'never', 'backward', 'in', 'trying', 'out', 'new', 'techniques', '.', 'Some', 'of', 'them', 'are', 'very', 'original', 'while', 'others', 'are', 'best', 'forgotten.<br', '/><br', '/>He', 'depicts', 'postwar', 'Germany', 'as', 'a', 'nightmarish', 'train', 'journey', '.', 'With', 'so', 'many', 'cities', 'lying', 'in', 'ruins', ',', 'Leo', 'Kessler', 'a', 'young', 'American', 'of', 'German', 'descent', 'feels', 'obliged', 'to', 'help', 'in', 'their', 'restoration', '.', 'It', 'is', 'not', 'a', 'simple', 'task', 'as', 'he', 'quickly', 'finds', 'out.<br', '/><br', '/>His', 'uncle', 'finds', 'him', 'a', 'job', 'as', 'a', 'night', 'conductor', 'on', 'the', 'Zentropa', 'Railway', 'Line', '.', 'His', 'job', 'is', 'to', 'attend', 'to', 'the', 'needs', 'of', 'the', 'passengers', '.', 'When', 'the', 'shoes', 'are', 'polished', 'a', 'chalk', 'mark', 'is', 'made', 'on', 'the', 'soles', '.', 'A', 'terrible', 'argument', 'ensues', 'when', 'a', \"passenger's\", 'shoes', 'are', 'not', 'chalked', 'despite', 'the', 'fact', 'they', 'have', 'been', 'polished', '.', 'There', 'are', 'many', 'allusions', 'to', 'the', 'German', 'fanaticism', 'of', 'adherence', 'to', 'such', 'stupid', 'details.<br', '/><br', '/>The', 'railway', 'journey', 'is', 'like', 'an', 'allegory', 'representing', \"man's\", 'procession', 'through', 'life', 'with', 'all', 'its', 'trials', 'and', 'tribulations', '.', 'In', 'one', 'sequence', 'Leo', 'dashes', 'through', 'the', 'back', 'carriages', 'to', 'discover', 'them', 'filled', 'with', 'half-starved', 'bodies', 'appearing', 'to', 'have', 'just', 'escaped', 'from', 'Auschwitz', '', '.', 'These', 'images', ',', 'horrible', 'as', 'they', 'are', ',', 'are', 'fleeting', 'as', 'in', 'a', 'dream', ',', 'each', 'with', 'its', 'own', 'terrible', 'impact', 'yet', 'unconnected.<br', '/><br', '/>At', 'a', 'station', 'called', 'Urmitz', 'Leo', 'jumps', 'from', 'the', 'train', 'with', 'a', 'parceled', 'bomb', '.', 'In', 'view', 'of', 'many', 'by-standers', 'he', 'connects', 'the', 'bomb', 'to', 'the', 'underside', 'of', 'a', 'carriage', '.', 'He', 'returns', 'to', 'his', 'cabin', 'and', 'makes', 'a', 'connection', 'to', 'a', 'time', 'clock', '.', 'Later', 'he', 'jumps', 'from', 'the', 'train', '(', 'at', 'high', 'speed', ')', 'and', 'lies', 'in', 'the', 'cool', 'grass', 'on', 'a', 'river', 'bank', '.', 'Looking', 'at', 'the', 'stars', 'above', 'he', 'decides', 'that', 'his', 'job', 'is', 'to', 'build', 'and', 'not', 'destroy', '.', 'Subsequently', 'as', 'he', 'sees', 'the', 'train', 'approaching', 'a', 'giant', 'bridge', 'he', 'runs', 'at', 'breakneck', 'speed', 'to', 'board', 'the', 'train', 'and', 'stop', 'the', 'clock', '.', 'If', 'you', 'care', 'to', 'analyse', 'the', 'situation', 'it', 'is', 'a', 'completely', 'impossible', 'task', '.', 'Quite', 'ridiculous', 'in', 'fact', '.', 'It', 'could', 'only', 'happen', 'in', 'a', 'dream.<br', '/><br', \"/>It's\", 'strange', 'how', 'one', 'remembers', 'little', 'details', 'such', 'as', 'a', 'row', 'of', 'cups', 'hanging', 'on', 'hooks', 'and', 'rattling', 'away', 'with', 'the', 'swaying', 'of', 'the', 'train.<br', '/><br', '/>Despite', 'the', 'fact', 'that', 'this', 'film', 'is', 'widely', 'acclaimed', ',', 'I', 'prefer', 'Lars', 'Von', \"Trier's\", 'later', 'films', '(', 'Breaking', 'the', 'Waves', 'and', 'The', 'Idiots)', '.', 'The', 'bomb', 'scene', 'described', 'above', 'really', 'put', 'me', 'off', '.', 'Perhaps', \"I'm\", 'a', 'realist', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['*Contains', 'spoilers', 'due', 'to', 'me', 'having', 'to', 'describe', 'some', 'film', 'techniques', ',', 'so', 'read', 'at', 'your', 'own', 'risk!*<br', '/><br', '/>I', 'loved', 'this', 'film', '.', 'The', 'use', 'of', 'tinting', 'in', 'some', 'of', 'the', 'scenes', 'makes', 'it', 'seem', 'like', 'an', 'old', 'photograph', 'come', 'to', 'life', '.', 'I', 'also', 'enjoyed', 'the', 'projection', 'of', 'people', 'on', 'a', 'back', 'screen', '.', 'For', 'instance', ',', 'in', 'one', 'scene', ',', 'Leopold', 'calls', 'his', 'wife', 'and', 'she', 'is', 'projected', 'behind', 'him', 'rather', 'than', 'in', 'a', 'typical', 'split', 'screen', '.', 'Her', 'face', 'is', 'huge', 'in', 'the', 'back', 'and', \"Leo's\", 'is', 'in', 'the', 'foreground.<br', '/><br', '/>One', 'of', 'the', 'best', 'uses', 'of', 'this', 'is', 'when', 'the', 'young', 'boys', 'kill', 'the', 'Ravensteins', 'on', 'the', 'train', ',', 'a', 'scene', 'shot', 'in', 'an', 'almost', 'political', 'poster', 'style', ',', 'with', 'facial', 'close', 'ups', '.', 'It', 'reminded', 'me', 'of', 'Battleship', 'Potemkin', ',', 'that', 'intense', 'constant', 'style', 'coupled', 'with', 'the', 'spray', 'of', 'red', 'to', 'convey', 'tons', 'of', 'horror', 'without', 'much', 'gore', '.', 'Same', 'with', 'the', 'scene', 'when', 'Katharina', 'finds', 'her', 'father', 'dead', 'in', 'the', 'bathtub...you', 'can', 'only', 'see', 'the', 'red', 'water', 'on', 'the', 'side', '.', 'It', 'is', 'one', 'of', 'the', 'things', 'I', 'love', 'about', 'Von', 'Trier', ',', 'his', 'understatement', 'of', 'horror', ',', 'which', 'ends', 'up', 'making', 'it', 'all', 'the', 'more', 'creepy.<br', '/><br', '/>The', 'use', 'of', 'text', 'in', 'the', 'film', 'was', 'unique', ',', 'like', 'when', \"Leo's\", 'character', 'is', 'pushed', 'by', 'the', 'word', ',', '\"', 'Werewolf.', '\"', 'I', 'have', 'never', 'seen', 'anything', 'like', 'that', 'in', 'a', 'film.<br', '/><br', '/>The', 'use', 'of', 'black', 'comedy', 'in', 'this', 'film', 'was', 'well', 'done', '.', 'Ernst-Hugo', 'Järegård', 'is', 'great', 'as', \"Leo's\", 'uncle', '.', 'It', 'brings', 'up', 'the', 'snickers', 'I', 'got', 'from', 'his', 'role', 'in', 'the', 'Kingdom', '(', 'Riget.', ')', 'This', 'humor', 'makes', 'the', 'plotline', 'of', 'absurd', 'anal', 'retentiveness', 'of', 'train', 'conductors', 'against', 'the', 'terrible', 'backdrop', 'of', 'WW2', 'and', 'all', 'the', 'chaos', ',', 'easier', 'to', 'take', '.', 'It', 'reminds', 'me', 'of', 'Riget', 'in', 'the', 'way', 'the', 'hospital', 'administrator', 'is', 'trying', 'to', 'maintain', 'a', 'normalcy', 'at', 'the', 'end', 'of', 'part', 'one', 'when', 'everything', 'is', 'going', 'crazy', '.', 'It', 'shows', 'that', 'some', 'people', 'are', 'truly', 'oblivious', 'to', 'the', 'awful', 'things', 'happening', 'around', 'them', '.', 'Yet', 'some', 'people', ',', 'like', 'Leo', ',', 'are', 'tuned', 'in', ',', 'but', 'do', 'nothing', 'positive', 'about', 'it.<br', '/><br', '/>The', 'voice', 'over', ',', 'done', 'expertly', 'well', 'by', 'Max', 'von', 'Sydow', ',', 'is', 'amusing', 'too', '.', 'It', 'draws', 'you', 'into', 'the', 'story', 'and', 'makes', 'you', 'jump', 'into', \"Leo's\", 'head', ',', 'which', 'at', 'times', 'is', 'a', 'scary', 'place', 'to', 'be.<br', '/><br', '/>The', 'movie', 'brings', 'up', 'the', 'point', 'that', 'one', 'is', 'a', 'coward', 'if', 'they', \"don't\", 'choose', 'a', 'side', '.', 'I', 'see', 'the', 'same', 'idea', 'used', 'in', 'Dancer', 'in', 'the', 'Dark', ',', 'where', \"Bjork's\", 'character', \"doesn't\", 'speak', 'up', 'for', 'herself', 'and', 'ends', 'up', 'being', 'her', 'own', 'destruction', '.', 'Actually', ',', 'at', 'one', 'time', ',', 'Von', 'Trier', 'seemed', 'anti-woman', 'to', 'me', ',', 'by', 'making', 'Breaking', 'the', 'Waves', 'and', 'Dancer', ',', 'but', 'now', 'I', 'know', 'his', 'male', 'characters', \"don't\", 'fare', 'well', 'either', '!', 'I', 'found', 'myself', 'at', 'the', 'same', 'place', 'during', 'the', 'end', 'of', 'Dancer', ',', 'when', 'you', 'seriously', 'want', 'the', 'main', 'character', 'to', 'rethink', 'their', 'actions', ',', 'but', 'of', 'course', ',', 'they', 'never', 'do', '!'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['That', 'was', 'the', 'first', 'thing', 'that', 'sprang', 'to', 'mind', 'as', 'I', 'watched', 'the', 'closing', 'credits', 'to', 'Europa', 'make', 'there', 'was', 'across', 'the', 'screen', ',', 'never', 'in', 'my', 'entire', 'life', 'have', 'I', 'seen', 'a', 'film', 'of', 'such', 'technical', 'genius', ',', 'the', 'visuals', 'of', 'Europa', 'are', 'so', 'impressive', 'that', 'any', 'film', 'I', 'watch', 'in', \"it's\", 'wake', 'will', 'only', 'pale', 'in', 'comparison', ',', 'forget', 'your', 'Michael', 'Bay', ',', 'Ridley', 'Scott', 'slick', 'Hollywood', 'cinematography', ',', 'Europa', 'has', 'more', 'ethereal', 'beauty', 'than', 'anything', 'those', 'two', 'could', 'conjure', 'up', 'in', 'a', 'million', 'years', '.', 'Now', \"I'd\", 'be', 'the', 'first', 'to', 'hail', 'Lars', 'von', 'Trier', 'a', 'genius', 'just', 'off', 'the', 'back', 'of', 'his', 'films', 'Breaking', 'the', 'Waves', 'and', 'Dancer', 'in', 'the', 'Dark', ',', 'but', 'this', 'is', 'stupid', ',', 'the', 'fact', 'that', 'Europa', 'has', 'gone', 'un-noticed', 'by', 'film', 'experts', 'for', 'so', 'long', 'is', 'a', 'crime', 'against', 'cinema', ',', 'whilst', 'overrated', 'rubbish', 'like', 'Crouching', 'Tiger', ',', 'Hidden', 'Dragon', 'and', 'Life', 'is', 'Beautiful', 'clean', 'up', 'at', 'the', 'academy', 'awards', '(', 'but', 'what', 'do', 'the', 'know', ')', 'Europa', 'has', 'been', 'hidden', 'away', ',', 'absent', 'form', 'video', 'stores', 'and', '(', 'until', 'recently', ')', 'any', 'British', 'TV', 'channels', '.', '<br', '/><br', '/>The', 'visuals', 'in', 'Europa', 'are', 'not', 'MTV', 'gloss', ';', \"it's\", 'not', 'a', 'case', 'of', 'style', 'over', 'substance', ',', 'its', 'more', 'a', 'case', 'of', 'substance', 'dictating', 'style', '.', 'Much', 'like', 'his', 'first', 'film', 'The', 'Element', 'of', 'Crime', ',', 'von', 'Trier', 'uses', 'the', 'perspective', 'of', 'the', 'main', 'character', 'to', 'draw', 'us', 'into', 'his', 'world', ',', 'and', 'much', 'like', 'Element', ',', 'the', 'film', 'begins', 'with', 'the', 'main', 'character', '(', 'or', 'in', 'the', 'case', 'of', 'Europa', ',', 'we', 'the', 'audience', ')', 'being', 'hypnotized', '.', 'As', 'we', 'move', 'down', 'the', 'tracks', ',', 'the', 'voice', 'of', 'the', 'Narrator', '(', 'Max', 'von', 'Sydow', ')', 'counts', 'us', 'down', 'into', 'a', 'deep', 'sleep', ',', 'until', 'we', 'awake', 'in', 'Europa', '.', 'This', 'allows', 'von', 'Trier', 'and', 'his', 'three', 'cinematographers', 'to', 'pay', 'with', 'the', 'conventions', 'of', 'time', 'and', 'imagery', ',', 'there', 'are', 'many', 'scenes', 'in', 'Europa', 'when', 'a', 'character', 'in', 'the', 'background', ',', 'who', 'is', 'in', 'black', 'and', 'white', ',', 'will', 'interact', 'with', 'a', 'person', 'in', 'the', 'foreground', 'who', 'will', 'be', 'colour', ',', 'von', 'Trier', 'is', 'trying', 'to', 'show', 'us', 'how', 'much', 'precedence', 'the', 'coloured', 'item', 'or', 'person', 'has', 'over', 'the', 'plot', ',', 'for', 'instance', ',', \"it's\", 'no', 'surprise', 'that', 'the', 'first', 'shot', 'of', 'Leopold', 'Kessler', '(', 'Jean-marc', 'Barr', ')', 'is', 'in', 'colour', ',', 'since', 'he', 'is', 'the', 'only', 'character', \"who's\", 'actions', 'have', 'superiority', 'over', 'the', 'film', '.', '<br', '/><br', '/>The', 'performances', 'are', 'good', ',', 'they', 'may', 'not', 'be', 'on', 'par', 'with', 'performances', 'in', 'later', 'von', 'Trier', 'films', ',', 'but', \"that's\", 'just', 'because', 'the', 'images', 'are', 'sometimes', 'so', 'distracting', 'that', 'you', \"don't\", 'really', 'pick', 'up', 'on', 'them', 'the', 'first', 'time', 'round', '.', 'But', 'I', 'would', 'like', 'to', 'point', 'out', 'the', 'fantastic', 'performance', 'of', 'Jean-Marc', 'Barr', 'in', 'the', 'lead', 'role', ',', 'whose', 'blind', 'idealism', 'is', 'slowly', 'warn', 'down', 'by', 'the', 'two', 'opposing', 'sides', ',', 'until', 'he', 'erupts', 'in', 'the', 'films', 'final', 'act', '.', 'Again', ',', 'muck', 'like', 'The', 'Element', 'of', 'Crime', ',', 'the', 'film', 'ends', 'with', 'our', 'hero', 'unable', 'to', 'wake', 'up', 'from', 'his', 'nightmare', 'state', ',', 'left', 'in', 'this', 'terrible', 'place', ',', 'with', 'only', 'the', 'continuing', 'narration', 'of', 'von', 'Sydow', 'to', 'seal', 'his', 'fate', '.', 'Europa', 'is', 'a', 'tremendous', 'film', ',', 'and', 'I', 'cant', 'help', 'thinking', 'what', 'a', 'shame', 'that', 'von', 'Trier', 'has', 'abandoned', 'this', 'way', 'of', 'filming', ',', 'since', 'he', 'was', 'clearly', 'one', 'of', 'the', 'most', 'talented', 'visual', 'directors', 'working', 'at', 'that', 'time', ',', 'Europa', ',', 'much', 'like', 'the', 'rest', 'of', 'his', 'cinematic', 'cannon', 'is', 'filled', 'with', 'a', 'wealth', 'of', 'iconic', 'scenes', '.', 'His', 'dedication', 'to', 'composition', 'and', 'mise-en-scene', 'is', 'unrivalled', ',', 'not', 'to', 'mention', 'his', 'use', 'of', 'sound', 'and', 'production', 'design', '.', 'But', 'since', 'his', 'no-frills', 'melodramas', 'turned', 'out', 'to', 'be', 'Breaking', 'the', 'Waves', 'and', 'Dancer', 'in', 'the', 'Dark', 'then', 'who', 'can', 'argue', ',', 'but', 'it', 'does', 'seems', 'like', 'a', 'waste', 'of', 'an', 'imaginative', 'talent', '.', '10/10'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['I', 'had', 'started', 'to', 'lose', 'my', 'faith', 'in', 'films', 'of', 'recent', 'being', 'inundated', 'with', 'the', 'typical', 'Genre', 'Hollywood', 'film', '.', 'Story', 'lines', 'fail', ',', 'and', 'camera', 'work', 'is', 'merely', 'copied', 'from', 'the', 'last', 'film', 'of', 'similiar', 'taste', '.', 'But', ',', 'then', 'I', 'saw', 'Zentropa', '(', 'Europa', ')', 'and', 'my', 'faith', 'was', 'renewed', '.', 'Not', 'only', 'is', 'the', 'metaphorical', 'storyline', 'enthralling', 'but', 'the', 'use', 'of', 'color', 'and', 'black', 'and', 'white', 'is', 'visually', 'stimulating', '.', 'The', 'narrator', '(', 'Max', 'Von', 'Sydow', ')', 'takes', 'you', 'through', 'a', 'spellbounding', 'journey', 'every', 'step', 'of', 'the', 'way', 'and', 'engrosses', 'you', 'into', 'Europa', '1945', '.', 'We', 'have', 'all', 'seen', 'death', 'put', 'on', 'screen', 'in', 'a', 'hundred', 'thousand', 'ways', 'but', 'the', 'beauty', 'of', 'this', 'film', 'is', 'how', 'it', 'takes', 'you', 'through', 'every', 'slow-moving', 'moment', 'that', 'leads', 'you', 'to', 'death', '.', 'Unlike', 'many', 'films', 'it', \"doesn't\", 'cut', 'after', 'one', 'second', 'of', 'showing', '(', 'for', 'example', ')', 'a', 'knife', 'but', 'forces', 'you', 'to', 'watch', 'the', 'devastating', 'yet', 'sensuous', 'beauty', 'of', 'a', \"man's\", 'final', 'moments', '.', 'I', 'think', 'we', 'can', 'all', 'take', 'something', 'different', 'away', 'from', 'what', 'this', 'movie', 'is', 'trying', 'to', 'say', 'but', 'it', 'is', 'definitely', 'worth', 'taking', 'the', 'time', 'to', 'find', 'out', 'what', 'it', 'all', 'really', 'means', '.', 'I', 'would', 'love', 'to', 'talk', 'more', 'in', 'depth', 'about', 'the', 'film', 'for', 'any', 'one', 'who', 'wishes', 'to', 'send', 'me', 'an', 'email', '.', 'Enjoy', 'it', '!'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Critics', 'need', 'to', 'review', 'what', 'they', 'class', 'as', 'a', 'quality', 'movie', '.', 'I', 'think', 'the', 'critics', 'have', 'seen', 'too', 'many', 'actions', 'films', 'and', 'have', 'succumbed', 'to', 'the', 'Matrix', 'style', 'of', 'films', '.', 'Europa', 'is', 'a', 'breath', 'of', 'fresh', 'air', ',', 'a', 'film', 'with', 'so', 'many', 'layers', 'that', 'one', 'viewing', 'is', 'not', 'enough', 'to', 'understand', 'or', 'appreciate', 'this', 'outstanding', 'film', '.', 'Lars', 'von', 'Trier', 'shows', 'that', 'old', 'styles', 'of', 'filming', 'can', 'produce', 'marvellous', 'cinema', 'and', 'build', 'drama', 'and', 'tension', '.', 'The', 'back', 'projection', 'effect', 'he', 'uses', 'during', 'the', 'film', 'arouses', 'and', 'enhances', 'the', 'characters', ',', 'and', 'the', 'focus', 'of', 'the', 'conversation', 'they', 'are', 'having', '.', 'Other', 'effects', 'he', 'uses', 'such', 'as', 'the', 'colour', 'and', 'black', 'and', 'white', 'in', 'one', 'scene', 'much', 'like', 'Hitchcock', 'and', 'the', 'girl', 'with', 'the', 'red', 'coat', 'grabs', 'attention', 'and', 'enhances', 'the', 'drama', 'and', 'meaning', 'of', 'the', 'scene', '.', 'The', 'commentary', 'is', 'superb', 'and', 'has', 'a', 'hypnotic', 'effect', ',', 'again', 'maintaining', 'the', 'focus', 'on', 'the', 'central', 'characters', 'in', 'the', 'scene', 'and', 'there', 'actions.<br', '/><br', '/>I', 'could', 'talk', 'about', 'the', 'effects', 'more', 'but', 'I', 'think', 'you', 'all', 'would', 'agree', 'they', 'push', 'this', 'film', 'into', 'a', 'category', 'of', 'its', 'own', ',', 'and', 'really', 'heighten', 'the', 'drama', 'of', 'the', 'film', '.', 'A', 'film', 'to', 'buy', 'if', 'you', \"don't\", 'own', 'already', 'and', 'one', 'to', 'see', 'if', 'you', 'have', 'not.<br', '/><br', '/>10/10', \"Don't\", 'miss', 'this', 'artistic', 'noir', 'film', 'from', 'one', 'of', 'the', 'great', 'film', 'directors', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['It', 'is', 'not', 'every', \"film's\", 'job', 'to', 'stimulate', 'you', 'superficially', '.', 'I', 'will', 'take', 'an', 'ambitious', 'failure', 'over', 'a', 'mass-market', 'hit', 'any', 'day', '.', 'While', 'this', 'really', \"can't\", 'be', 'described', 'as', 'a', 'failure', ',', 'the', 'sum', 'of', 'its', 'parts', 'remains', 'ambiguous', '.', 'That', 'indecipherable', 'quality', 'tantalizes', 'me', 'into', 'watching', 'it', 'again', 'and', 'again', '.', 'This', 'is', 'a', 'challenging', ',', 'provocative', 'movie', 'that', 'does', 'not', 'wrap', 'things', 'up', 'neatly', '.', 'The', 'problem', 'with', 'the', 'movie', 'is', 'in', 'its', 'structure', '.', 'Its', 'inpenetrable', 'plot', 'seems', 'to', 'be', 'winding', 'up', ',', 'just', 'as', 'a', 'second', 'ending', 'is', 'tacked', 'on', '.', 'Though', 'everything', 'is', 'technically', 'dazzling', ',', 'the', 'movie', 'is', 'exactly', 'too', 'long', 'by', 'that', 'unit', '.', 'The', 'long-delayed', 'climax', 'of', \"Leo's\", 'awakening', 'comes', 'about', '20', 'minutes', 'late.<br', '/><br', '/>Great', 'cinematography', 'often', 'comes', 'at', 'the', 'expense', 'of', 'a', 'decent', 'script', ',', 'but', 'here', 'the', 'innovative', 'camera', 'technique', 'offers', 'a', 'wealth', 'of', 'visual', 'ideas', '.', 'The', 'compositing', 'artifice', 'is', 'provocative', 'and', 'engaging', ';', 'A', 'character', 'is', 'rear-projected', 'but', 'his', 'own', 'hand', 'in', 'the', 'foreground', \"isn't\", '.', 'The', 'world', 'depicted', 'is', 'deliberate', ',', 'treacherous', 'and', 'absurd', '.', 'Keep', 'your', 'eyes', 'peeled', 'for', 'a', 'memorable', ',', 'technically', 'astonishing', 'assassination', 'that', 'will', 'make', 'your', 'jaw', 'drop.<br', '/><br', '/>The', 'compositions', 'are', 'stunning', '.', 'Whomever', 'chose', 'to', 'release', 'the', '(', 'out', 'of', 'print', ')', 'videotape', 'in', 'the', 'pan', '&', 'scan', 'format', 'must', 'have', 'never', 'seen', 'it', '.', 'Where', 'is', 'the', 'DVD?<br', '/><br', '/>It', 'is', 'unfathomable', 'how', 'anyone', 'could', 'give', 'this', 'much', 'originality', 'a', 'bad', 'review', '.', 'You', 'should', 'see', 'it', 'at', 'least', 'once', '.', 'You', 'get', 'the', 'sense', 'that', 'von', 'Trier', 'bit', 'off', 'more', 'than', 'he', 'could', 'chew', ',', 'but', 'this', 'movie', 'ends', 'up', 'being', 'richer', 'for', 'it', '.', 'I', 'suspect', 'he', 'is', 'familiar', 'with', \"Hitchcock's\", 'Foreign', 'Correspondent', 'in', 'which', 'devious', 'Europeans', 'also', 'manipulate', 'an', 'American', 'dupe', 'and', 'several', 'Welles', 'movies', 'that', 'take', 'delirious', 'joy', 'in', 'technique', 'as', 'much', 'as', 'he', 'does', '.', 'All', 'von', 'Trier', 'movies', 'explore', 'the', 'plight', 'of', 'the', 'naif', 'amidst', 'unforgiving', 'societies', '.', 'After', 'Zentropa', ',', 'von', 'Trier', 'moved', 'away', 'from', 'this', 'type', 'of', 'audacious', 'technical', 'experiment', 'towards', 'dreary', ',', 'over-rated', ',', 'un-nuanced', 'sap', 'like', 'Breaking', 'the', 'Waves', 'and', 'Dancer', 'in', 'the', 'Dark', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['The', 'best', 'way', 'for', 'me', 'to', 'describe', 'Europa', ',', 'which', 'is', 'high', 'on', 'the', 'list', 'of', 'my', 'favourite', 'films', ',', 'is', 'the', 'exclamation', 'that', 'came', 'from', 'a', 'companion', 'after', 'the', 'film', 'ended', ':', '\"', 'I', \"didn't\", 'know', 'films', 'could', 'be', 'made', 'like', 'that\"', '.', 'Entirely', 'original', 'in', \"it's\", 'visual', 'style', ',', 'it', 'is', 'one', 'of', 'the', 'best', 'examples', 'of', 'what', 'cinema', 'can', 'be', '.', \"It's\", 'as', 'far', 'away', 'from', 'the', '\"', 'master', 'and', 'coverage', '\"', 'style', 'of', 'shooting', 'as', 'one', 'can', 'get', ';', 'perfectly', 'integrating', 'many', 'layers', 'of', 'image', ',', 'sound', ',', 'effects', ',', 'props', ',', 'dialogue', ',', 'voice', 'over', ',', 'performance', ',', 'editing', ',', 'lighting', ',', 'etc..', '.', 'all', 'equal', ',', 'none', 'predominant', '.', 'Despite', \"Hollywood's\", '\"', 'dialogue', '\"', 'myopia', ',', 'cinema', 'is', 'not', 'about', 'dialogue', ',', 'nor', 'is', 'it', 'about', 'beautiful', 'lighting', ',', 'action', 'or', 'music', '.', 'It', 'works', 'best', 'when', 'all', 'the', 'elements', 'are', 'on', 'an', 'equal', 'footing', ',', 'where', 'ONLY', 'the', 'BLENDING', 'of', 'those', 'elements', ',', 'in', 'the', 'order', 'or', 'combination', 'in', 'which', 'they', 'are', 'presented', ',', 'will', 'communicate', 'the', 'idea', '.', 'Reduce', 'or', 'eliminate', 'the', 'contribution', 'of', 'one', 'element', ',', 'and', 'the', 'film', 'has', 'no', 'meaning', '.', '\"', 'Europa', '\"', 'is', 'what', 'cinema', 'should', 'strive', 'to', 'be', '.'] \n",
      "the label for the *i*th example: pos \n",
      "list of textual tokens for the *i*th example: ['Released', 'as', 'Zentropa', 'in', 'North', 'America', 'to', 'avoid', 'confusion', 'with', 'Agniezska', \"Holland's\", 'own', 'Holocaust', 'film', 'Europa', 'Europa', ',', 'this', 'third', 'theatrical', 'feature', 'by', 'a', 'filmmaker', 'who', 'never', 'ceases', 'to', 'surprise', ',', 'inspire', 'or', 'downright', 'shock', 'is', 'a', 'bizarre', ',', 'nostalgic', ',', 'elaborate', 'film', 'about', 'a', 'naive', 'American', 'in', 'Germany', 'shortly', 'following', 'the', 'end', 'of', 'WWII', '.', 'The', 'American', ',', 'named', 'Leo', ',', \"doesn't\", 'fully', 'get', 'what', \"he's\", 'doing', 'there', '.', 'He', 'has', 'come', 'to', 'take', 'part', 'in', 'fixing', 'up', 'the', 'country', 'since', ',', 'in', 'his', 'mind', ',', \"it's\", 'about', 'time', 'Germany', 'was', 'shown', 'some', 'charity', '.', 'No', 'matter', 'how', 'that', 'sounds', ',', 'he', 'is', 'not', 'a', 'Nazi', 'sympathizer', 'or', 'so', 'much', 'as', 'especially', 'pro-German', ',', 'merely', 'mixed', 'up', '.', 'His', 'uncle', ',', 'who', 'works', 'on', 'the', 'railroad', ',', 'gets', 'Leo', 'a', 'job', 'as', 'a', 'helmsman', 'on', 'a', 'sleeping', 'car', ',', 'and', 'he', 'is', 'increasingly', 'enmeshed', 'in', 'a', 'vortex', 'of', '1945', \"Germany's\", 'horrors', 'and', 'enigmas.<br', '/><br', '/>This', 'progression', 'starts', 'when', 'Leo', ',', 'played', 'rather', 'memorably', 'by', 'the', 'calm', 'yet', 'restless', 'actor', 'Jean-Marc', 'Barr', ',', 'meets', 'a', 'sultry', 'heiress', 'on', 'the', 'train', 'played', 'by', 'Barbara', 'Sukowa', ',', 'an', 'actress', 'with', 'gentility', 'on', 'the', 'surface', 'but', 'internal', 'vigor', '.', 'She', 'seduces', 'him', 'and', 'then', 'takes', 'him', 'home', 'to', 'meet', 'her', 'family', ',', 'which', 'owns', 'the', 'company', 'which', 'manufactures', 'the', 'trains', '.', 'These', 'were', 'the', 'precise', 'trains', 'that', 'took', 'Jews', 'to', 'their', 'deaths', 'during', 'the', 'war', ',', 'but', 'now', 'they', 'run', 'a', 'drab', 'day-to-day', 'timetable', ',', 'and', 'the', \"woman's\", 'Uncle', 'Kessler', 'postures', 'as', 'another', 'one', 'of', 'those', 'good', 'Germans', 'who', 'were', 'just', 'doing', 'their', 'jobs', '.', 'There', 'is', 'also', 'Udo', 'Kier', ',', 'the', 'tremendous', 'actor', 'who', 'blew', 'me', 'away', 'in', 'Von', \"Trier's\", 'shocking', 'second', 'film', 'Epidemic', ',', 'though', 'here', 'he', 'is', 'mere', 'scenery.<br', '/><br', '/>Another', 'guest', 'at', 'the', 'house', 'is', 'Eddie', 'Constantine', ',', 'an', 'actor', 'with', 'a', 'quiet', 'strength', ',', 'playing', 'a', 'somber', 'American', 'intelligence', 'man', '.', 'He', 'can', 'confirm', 'that', 'Uncle', 'Kessler', 'was', 'a', 'war', 'criminal', ',', 'though', 'it', 'is', 'all', 'completely', 'baffling', 'to', 'Leo', '.', 'Americans', 'have', 'been', 'characterized', 'as', 'gullible', 'rubes', 'out', 'of', 'their', 'element', 'for', 'decades', ',', 'but', 'little', 'have', 'they', 'been', 'more', 'blithely', 'unconcerned', 'than', 'Leo', ',', 'who', 'goes', 'back', 'to', 'his', 'job', 'on', 'what', 'gradually', 'looks', 'like', 'his', 'own', 'customized', 'death', 'train.<br', '/><br', '/>The', 'story', 'is', 'told', 'in', 'a', 'purposely', 'uncoordinated', 'manner', 'by', 'the', \"film's\", 'Danish', 'director', ',', 'Lars', 'Von', 'Trier', ',', 'whose', 'anchor', 'is', 'in', 'the', \"film's\", 'breathtaking', 'editing', 'and', 'cinematography', '.', 'He', 'shoots', 'in', 'black', 'and', 'white', 'and', 'color', ',', 'he', 'uses', 'double-exposures', ',', 'optical', 'effects', 'and', 'trick', 'photography', ',', 'having', 'actors', 'interact', 'with', 'rear-projected', 'footage', ',', 'he', 'places', 'his', 'characters', 'inside', 'a', 'richly', 'shaded', 'visceral', 'world', 'so', 'that', 'they', 'sometimes', 'feel', 'like', 'insects', ',', 'caught', 'between', 'glass', 'for', 'our', 'more', 'precise', 'survey.<br', '/><br', '/>This', 'Grand', 'Jury', 'Prize-winning', 'surrealist', 'work', 'is', 'allegorical', ',', 'but', 'maybe', 'in', 'a', 'distinct', 'tone', 'for', 'every', 'viewer', '.', 'I', 'interpret', 'it', 'as', 'a', 'film', 'about', 'the', 'last', 'legs', 'of', 'Nazism', ',', 'symbolized', 'by', 'the', 'train', ',', 'and', 'the', 'ethical', 'accountability', 'of', 'Americans', 'and', 'others', 'who', 'appeared', 'too', 'late', 'to', 'salvage', 'the', 'martyrs', 'of', 'these', 'trains', 'and', 'the', 'camps', 'where', 'they', 'distributed', 'their', 'condemned', 'shiploads', '.', 'During', 'the', 'time', 'frame', 'of', 'the', 'movie', ',', 'and', 'the', 'Nazi', 'state', ',', 'and', 'such', 'significance', 'to', 'the', 'train', ',', 'are', 'dead', ',', 'but', 'like', 'decapitated', 'chickens', 'they', 'persist', 'in', 'jolting', 'through', 'their', 'reflexes.<br', '/><br', '/>The', 'characters', ',', 'music', ',', 'dialogue', ',', 'and', 'plot', 'are', 'deliberately', 'hammy', 'and', 'almost', 'satirically', 'procured', 'from', 'film', 'noir', 'conventions', '.', 'The', 'most', 'entrancing', 'points', 'in', 'the', 'movie', 'are', 'the', 'entirely', 'cinematographic', 'ones', '.', 'Two', 'trains', 'halting', 'back', 'and', 'forth', ',', 'Barr', 'on', 'one', 'and', 'Sukowa', 'on', 'another', '.', 'An', 'underwater', 'shot', 'of', 'proliferating', 'blood', '.', 'An', 'uncommonly', 'expressive', 'sequence', 'on', 'what', 'it', 'must', 'be', 'like', 'to', 'drown', '.', 'And', 'most', 'metaphysically', 'affecting', 'of', 'all', ',', 'an', 'anesthetic', 'shot', 'of', 'train', 'tracks', ',', 'as', 'Max', 'von', \"Sydow's\", 'voice', 'allures', 'us', 'to', 'hark', 'back', 'to', 'Europe', 'with', 'him', ',', 'and', 'abandon', 'our', 'personal', 'restraint', '.'] \n",
      "\n",
      "SAMPLE DATA:\n",
      "Sample text: ['This', 'movie', 'is', 'based', 'on', 'the', 'art', 'of', 'Frank', 'Frazetta', ',', 'the', 'mythical', 'fantasy', 'illustrator', '.', 'Some', 'of', 'the', 'characters', 'are', 'straight', 'out', 'of', 'his', 'paintings', '(', 'the', 'Death', 'Dealer', 'being', 'the', 'best', 'example)', '.', 'Surprisingly', ',', 'the', 'animation', 'manages', 'to', 'keep', 'the', 'feeling', 'of', 'the', 'original', 'art', '.', 'Bakshi', 'is', 'well', 'known', 'for', 'his', 'heavy', 'use', 'of', 'rotoscope', '(', 'the', 'technique', 'of', 'tracing', 'a', 'live', 'action', 'sequence', ')', 'and', 'this', 'film', 'is', 'no', 'exception', '.', 'However', ',', 'since', 'the', 'subject', 'of', 'the', 'movie', 'is', 'quite', 'realistic', '(', 'all', 'characters', 'are', 'humans)', ',', 'this', 'works', 'pretty', 'well.<br', '/><br', '/>But', 'what', 'I', 'really', 'like', 'here', 'is', 'the', 'plot', ':', 'for', 'once', 'we', 'have', 'a', 'story', 'with', 'interesting', 'characters', 'and', 'nice', 'action', 'sequences', ',', 'a', 'really', 'hideous', 'villain', 'and', 'a', 'gorgeous', 'babe', '.', 'This', 'movie', 'has', 'the', 'feeling', 'of', 'the', 'best', 'Conan', 'comics', ',', 'not', 'surprisingly', 'since', 'Roy', 'Thomas', 'is', 'the', 'writer', 'of', 'the', 'Marvel', 'series', 'of', 'our', 'favourite', 'Cimmerian', '!', 'This', 'is', 'a', 'far', 'cry', 'from', 'the', 'crappy', 'live', 'action', 'Conan', ',', 'not', 'to', 'speak', 'of', 'all', 'the', 'B-movie', 'of', 'the', 'genre.<br', '/><br', '/>Definitely', 'recommended', '!']\n",
      "Sample label: pos \n",
      "\n",
      "Sample text: ['Really', 'bad', 'movie', ',', 'the', 'story', 'is', 'too', 'simple', 'and', 'predictable', 'and', 'poor', 'acting', 'as', 'a', 'complement.<br', '/><br', '/>This', \"vampire's\", 'hunter', 'story', 'is', 'the', 'worst', 'that', 'i', 'have', 'seen', 'so', 'far', ',', 'Derek', 'Bliss', '(', 'Jon', 'Bon', 'Jovi)', ',', 'travels', 'to', 'Mexico', 'in', 'search', 'for', 'some', 'blood', 'suckers!', ',', 'he', 'use', 'some', 'interesting', 'weapons', '(', 'but', 'nothing', 'compared', 'to', 'Blade)', ',', 'and', 'is', 'part', 'of', 'some', 'Van', 'Helsig', \"vampire's\", 'hunters', 'net?', ',', 'OK', ',', 'but', 'he', 'work', 'alone', '.', \"He's\", 'assigned', 'to', 'the', 'pursuit', 'of', 'a', 'powerful', 'vampire', 'queen', 'that', 'is', 'searching', 'some', 'black', 'crucifix', 'to', 'perform', 'a', 'ritual', 'which', 'will', 'enable', 'her', 'to', 'be', 'invulnerable', 'to', 'sunlight', '(', 'is', 'almost', 'a', 'sequel', 'of', 'Vampires', '(', '1998', ')', 'directed', 'by', 'John', 'Carpenter', 'and', 'starred', 'by', 'James', 'Woods)', ',', 'Derek', 'start', 'his', 'quest', 'in', 'the', 'search', 'of', 'the', 'queen', 'with', 'some', 'new', 'friends', ':', 'Sancho', '(', 'Diego', 'Luna', ',', 'really', 'bad', 'acting', 'also', ')', 'a', 'teenager', 'without', 'experience', ',', 'Father', 'Rodrigo', '(', 'Cristian', 'De', 'la', 'Fuente', ')', 'a', 'catholic', 'priest', ',', 'Zoey', '(', 'Natasha', 'Wagner', ')', 'a', 'particular', 'vampire', 'and', 'Ray', 'Collins', '(', 'Darius', 'McCrary', ')', 'another', 'expert', 'vampire', 'hunter', '.', 'So', 'obviously', 'in', 'this', 'adventure', 'he', \"isn't\", 'alone.<br', '/><br', '/>You', 'can', 'start', 'feeling', 'how', 'this', 'movie', 'would', 'be', 'just', 'looking', 'at', 'his', 'lead', 'actor', '(', 'Jon', 'Bon', 'Jovi)', ';', 'is', 'a', 'huge', 'difference', 'in', 'the', 'acting', 'quality', 'compared', 'to', 'James', 'Woods', ',', 'and', 'then', ',', 'if', 'you', 'watch', 'the', 'film', '(', 'i', \"don't\", 'recommend', 'this', 'part)', ',', 'you', 'will', 'get', 'involved', 'in', 'one', 'of', 'the', 'more', 'simplest', 'stories', ',', 'totally', 'predictable', ',', 'with', 'terrible', 'acting', 'performances', ',', 'really', 'bad', 'special', 'effects', 'and', 'incoherent', 'events!.<br', '/><br', '/>I', 'deeply', 'recommend', 'not', 'to', 'see', 'this', 'film!', ',', 'rent', 'another', 'movie', ',', 'see', 'another', 'channel', ',', 'go', 'out', 'with', 'your', 'friends', ',', 'etc.<br', '/><br', '/>3/10']\n",
      "Sample label: neg \n",
      "\n",
      "Sample text: ['That', 'shall', 'be', 'a', 'documentary', '?', 'I', 'saw', 'it', '(', 'which', 'is', 'forbidden', 'in', 'Germany', ')', 'and', 'I', 'have', 'to', 'say', ',', 'that', 'it', 'was', 'the', 'worst', 'documentary', \"I've\", 'ever', 'seen', '.', 'It', 'is', 'nothing', 'but', 'one', 'big', 'lie', 'from', 'the', 'beginning', 'to', 'the', 'end', '.', 'Who', 'can', 'doubt', 'after', 'this', 'trash', 'that', 'all', 'Jews', 'were', 'supposed', 'to', 'be', 'killed', 'in', 'the', 'concentration', 'camps', '?']\n",
      "Sample label: neg \n",
      "\n",
      "Sample text: ['Thanks', 'to', 'Warner', 'Archive', ',', 'I', 'can', 'once', 'again', 'see', 'this', 'mammoth', 'variety', 'show', 'which', 'throws', 'in', 'everything', 'but', 'the', 'kitchen', 'sink', '.', '(', 'The', 'bathtub', ',', 'however', 'is', 'present.', ')', 'This', 'film', 'gives', 'screen', 'time', 'to', 'every', 'person', 'who', 'was', 'under', 'contract', 'to', 'Warners', 'at', 'the', 'time', '.', 'If', 'some', 'of', 'the', 'artists', 'seem', 'unfamiliar', 'to', 'some', ',', 'it', 'is', 'because', 'they', 'were', 'big', 'in', 'the', 'silent', 'days', ',', 'and', 'most', 'faded', 'with', 'the', 'popularity', 'of', 'the', 'talkies', '.', 'There', 'are', 'some', 'truly', 'remarkable', 'artists', 'from', 'the', 'vaudeville', 'era', 'as', 'well', '.', 'You', 'will', 'be', 'most', 'impressed', 'with', 'Winnie', 'Lightner', ',', 'who', 'performs', 'two', 'numbers', '.', 'Also', 'there', 'is', 'that', 'French', 'star', ',', 'Irene', 'Bordoni', 'who', 'croons', 'a', 'love', 'song', 'in', 'a', 'sexy', 'manner', '.', 'Perhaps', 'one', 'of', 'the', 'biggest', 'highlights', 'is', 'the', 'two-strip', 'Technicolor', '\"', 'Chinese', 'Fantasy,', '\"', 'which', 'has', 'been', 'restored', 'for', 'this', 'version', '.', 'It', 'is', 'truly', 'beautiful', 'and', 'it', 'stars', 'Myrna', 'Loy', 'and', 'Nick', 'Lucas', '.', 'Finally', ',', 'there', 'is', 'the', 'massive', '\"', 'Lady', 'Luck', '\"', 'finale', 'which', 'goes', 'on', 'for', 'nearly', 'a', 'quarter', 'of', 'an', 'hour', '.', 'This', 'is', 'truly', 'an', 'epic', 'of', 'the', 'early-talkie', 'era', '.', 'Any', 'old-movie', 'buff', 'will', 'love', 'this', '.']\n",
      "Sample label: pos \n",
      "\n",
      "Sample text: ['Enjoyed', 'the', 'movie', 'very', 'much', '.', 'Certainly', 'will', 'leave', 'the', 'audience', 'wanting', 'to', 'know', 'more', ',', 'and', 'there', 'is', 'truly', 'a', 'lot', 'more', 'historically', 'to', 'find', 'out!<br', '/><br', '/>Did', 'the', 'production', 'team', 'fall', 'to', 'the', 'temptation', 'of', 'over', 'dramatization', ',', 'particularly', 'of', 'the', 'shooting', 'event', '?', 'There', 'is', 'a', 'ton', 'of', 'interesting', 'accurate', 'material', 'hinted', 'at', '?', 'Prince', \"Albert's\", 'contribution', 'to', 'UK', 'and', 'the', 'monarchy', 'warrants', 'a', 'movie', 'on', \"it's\", 'own', 'but', 'granted', 'that', 'was', 'apparently', 'not', 'part', 'of', 'the', 'intention', 'here.<br', '/><br', '/>The', 'costumes', 'and', 'sets', 'are', 'especially', 'good', 'but', 'am', 'I', 'alone', 'in', 'thinking', 'that', 'this', 'production', '(', 'which', 'judging', 'by', 'the', 'length', 'of', 'titles', 'at', 'the', 'end', 'was', 'certainly', 'not', 'a', 'cheap', 'one', ')', 'wanted', 'badly', 'for', 'a', 'British', 'Court', 'historical', 'etiquette', 'expert', 'beyond', 'the', 'Duchess', 'of', 'York', '?', 'i.e', '.', 'Did', 'Princess', 'Victoria', 'really', 'stuff', 'an', 'entire', 'truffle/rissole(?', ')', 'into', 'her', 'mouth', 'while', 'speaking', 'to', 'the', 'Prime', 'Minister', 'in', 'the', 'company', 'of', 'His', 'Majesty', 'with', 'her', 'mouth', 'full', '?', '<br', '/><br', \"/>'Could\", 'never', 'really', 'felt', 'that', 'sympathetic', 'to', 'Victoriain', 'this', 'movie', ',', 'or', 'indeed', 'in', 'her', 'shoes', 'at', 'all', '.', 'Yet', 'loved', 'the', 'casting', 'of', 'the', 'principals', ',', 'whose', 'acting', 'was', 'convincing', ',', 'so', 'did', 'the', 'script', 'really', 'allow', 'us', 'to', 'really', 'get', 'to', 'know', 'them', 'well', '?', 'I', 'always', 'felt', 'like', 'a', 'totally', 'detached', ',', 'uninformed', 'outside', 'observer', ',', 'much', 'more', 'so', 'than', 'with', '\"', 'Mrs', '.', 'Brown', '\"', 'or', 'even', '\"', 'The', 'Queen\"', '.', 'Yet', 'to', 'be', 'honest', 'I', 'still', 'could', 'not', 'take', 'my', 'eyes', 'off', 'the', 'screen', ',', 'except', 'that', 'is', 'for', 'some', 'of', 'the', 'more', 'avant-garde', 'camera', 'techniques', 'which', 'were', 'distracting', 'from', 'time', 'to', 'time', '.']\n",
      "Sample label: pos \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "import torchtext\n",
    "import random\n",
    "\n",
    "def preprocess(review):\n",
    "    '''\n",
    "    Simple preprocessing function.\n",
    "    '''\n",
    "    res = []\n",
    "    for x in review.split(' '):\n",
    "        remove_beg=True if x[0] in {'(', '\"', \"'\"} else False\n",
    "        remove_end=True if x[-1] in {'.', ',', ';', ':', '?', '!', '\"', \"'\", ')'} else False\n",
    "        if remove_beg and remove_end: res += [x[0], x[1:-1], x[-1]]\n",
    "        elif remove_beg: res += [x[0], x[1:]]\n",
    "        elif remove_end: res += [x[:-1], x[-1]]\n",
    "        else: res += [x]\n",
    "    return res\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_data = torchtext.datasets.IMDB(root='.data', split='train')\n",
    "    train_data = list(train_data)\n",
    "    train_data = [(x[0], preprocess(x[1])) for x in train_data]\n",
    "    train_data, test_data = train_data[0:10000] + train_data[12500:12500+10000], train_data[10000:12500] + train_data[12500+10000:], \n",
    "\n",
    "    print('Num. Train Examples:', len(train_data))\n",
    "    print('Num. Test Examples:', len(test_data))\n",
    "\n",
    "\n",
    "    # for i in range(len(train_data)):\n",
    "    for i in range(0,10,1):\n",
    "        print(f\"the label for the *i*th example: {train_data[i][0]} \")\n",
    "        print(f\"list of textual tokens for the *i*th example: {train_data[i][1]} \")\n",
    "\n",
    "\n",
    "    # *   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n",
    "    # *   To access the label for the *i*th example, use `train_data[i][0]`\n",
    "\n",
    "\n",
    "    print(\"\\nSAMPLE DATA:\")\n",
    "    for x in random.sample(train_data, 5):\n",
    "        print('Sample text:', x[1])\n",
    "        print('Sample label:', x[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kfg8RcyskyU"
   },
   "source": [
    "# Step 2: Create Dataloader [20 points]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TODO:</font> Define the Dataset Class [20 Points]\n",
    "\n",
    "In the following cell, we will define the <b>dataset</b> class. The dataset contains the tokenized data for your model. You need to implement the following functions: \n",
    "\n",
    "*   <b>` build_dictionary(self)`:</b>  <b>[10 points]</b> Creates the dictionaries `idx2word` and `word2idx`. You will represent each word in the dataset with a unique index, and keep track of this in these dictionaries. Use the hyperparameter `threshold` to control which words appear in the dictionary: a training word’s frequency should be `>= threshold` to be included in the dictionary.\n",
    "\n",
    "* <b>`convert_text(self)`:</b> Converts each review in the dataset to a list of indices, given by your `word2idx` dictionary. You should store this in the `textual_ids` variable, and the function does not return anything. If a word is not present in the  `word2idx` dictionary, you should use the `<UNK>` token for that word. Be sure to append the `<END>` token to the end of each review.\n",
    "\n",
    "*   <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
    "\n",
    "*   <b>`get_label(self, idx) `</b>: Return the value `1` if the label for `idx` in the dataset is `positive`, and should return `0` if it is `negative`. The return type should be `torch.LongTensor`.\n",
    "\n",
    "*  <b> ` __len__(self) `:</b> Return the total number of reviews in the dataset as an `int`.\n",
    "\n",
    "*   <b>` __getitem__(self, idx)`:</b> <b>[10 points]</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here.\n",
    "\n",
    "\n",
    "<b>Note:</b> You should convert all words to lower case in your functions.\n",
    "\n",
    "<font color='green'><b>Hint:</b> Make sure that you use instance variables such as `self.threshold` throughout your code, rather than the global variable `THRESHOLD` (defined later on). The variable `THRESHOLD` will not be known to the autograder, and the use of it within the class will cause an autograder error.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1irMn3LX2YDB"
   },
   "outputs": [],
   "source": [
    "PAD = '<PAD>'\n",
    "END = '<END>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "from torch.utils import data\n",
    "from collections import defaultdict\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "    def __init__(self, examples, split, threshold, max_len, idx2word=None, word2idx=None):\n",
    "        ### DO NOT EDIT ###\n",
    "        \n",
    "        self.examples = examples\n",
    "        assert split in {'train', 'val', 'test'}\n",
    "        self.split = split\n",
    "        self.threshold = threshold\n",
    "        self.max_len = max_len\n",
    "\n",
    "        #custom\n",
    "        self.map_token_to_unigram_frequency = {}\n",
    "\n",
    "        # Dictionaries\n",
    "        self.idx2word = idx2word\n",
    "        self.word2idx = word2idx\n",
    "        if split == 'train':\n",
    "            self.build_dictionary()\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "        \n",
    "        # Convert text to indices\n",
    "        self.textual_ids = []\n",
    "        self.convert_text()\n",
    "\n",
    "    \n",
    "    def build_dictionary(self): \n",
    "        '''\n",
    "        Build the dictionaries idx2word and word2idx. This is only called when split='train', as these\n",
    "        dictionaries are passed in to the __init__(...) function otherwise. Be sure to use self.threshold\n",
    "        to control which words are assigned indices in the dictionaries.\n",
    "        Returns nothing.\n",
    "        '''\n",
    "        assert self.split == 'train'\n",
    "        \n",
    "        # Don't change this\n",
    "        self.idx2word = {0:PAD, 1:END, 2: UNK}\n",
    "        self.word2idx = {PAD:0, END:1, UNK: 2}\n",
    "\n",
    "        ##### TODO #####\n",
    "        # Count the frequencies of all words in the training data (self.examples)\n",
    "        # Assign idx (starting from 3) to all words having word_freq >= self.threshold\n",
    "        # Make sure you call word.lower() on each word to convert it to lowercase\n",
    "        # print(\" BUILDING DICT\")\n",
    "        # print(f\"training dataset is: {self.examples[0]}\")\n",
    "\n",
    "        # ('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
    "\n",
    "        for data in self.examples:           #iterate through preprocessed sentences\n",
    "            # print(f\"data: {data}\")\n",
    "            testset_label, preprocessed_sentence = data[0], data[1]\n",
    "            # print(f\"testset_label: {testset_label}, preprocessed_sentence:{preprocessed_sentence}\")\n",
    "            for token in preprocessed_sentence:             #iterate through each token\n",
    "                # print(f\"lowercase token is: {token}\")\n",
    "                token = token.lower()\n",
    "\n",
    "                if token not in self.map_token_to_unigram_frequency.keys():\n",
    "                    self.map_token_to_unigram_frequency[token] = 0          # add token as key if not present as a key in map_token_to_unigram_frequency\n",
    "                self.map_token_to_unigram_frequency[token] += 1             # increment the frequency of unigram\n",
    "\n",
    "\n",
    "        # print(f\"self.map_token_to_unigram_frequency: {self.map_token_to_unigram_frequency}\")\n",
    "        index = 3\n",
    "        for token, freq in self.map_token_to_unigram_frequency.items():\n",
    "            if freq >= self.threshold:\n",
    "                self.idx2word[index] = token\n",
    "                self.word2idx[token] = index\n",
    "                index += 1\n",
    "        #\n",
    "        # print(f\"self.idx2word: {self.idx2word}\")\n",
    "        # print(f\"self.word2idx: {self.word2idx}\")\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def convert_text(self):\n",
    "        '''\n",
    "        Convert each review in the dataset (self.examples) to a list of indices, given by self.word2idx.\n",
    "        Store this in self.textual_ids; returns nothing.\n",
    "        '''\n",
    "\n",
    "        ##### TODO #####\n",
    "        # Remember to replace a word with the <UNK> token if it does not exist in the word2idx dictionary.\n",
    "        # Remember to append the <END> token to the end of each review.\n",
    "        for data in self.examples:           #iterate through preprocessed sentences\n",
    "            # print(f\"data: {data}\")\n",
    "            testset_label, preprocessed_sentence = data[0], data[1]\n",
    "            converted_preprocessed_sentence = []\n",
    "            # print(f\"testset_label: {testset_label}, preprocessed_sentence:{preprocessed_sentence}\")\n",
    "            for token_index in range(len(preprocessed_sentence)):             #iterate through each token\n",
    "                token = preprocessed_sentence[token_index]\n",
    "                # print(f\"IN CONVERT TEXT: token: {token}\")\n",
    "                token = token.lower()\n",
    "                # print(f\"lowercase token is: {token}\")\n",
    "                if token not in self.word2idx.keys():\n",
    "                    # preprocessed_sentence[token_index] = self.word2idx[UNK]\n",
    "                    converted_preprocessed_sentence.append(self.word2idx[UNK])\n",
    "                if token in self.word2idx.keys():\n",
    "                    # preprocessed_sentence[token_index] = self.word2idx[token]\n",
    "                    converted_preprocessed_sentence.append(self.word2idx[token])\n",
    "\n",
    "            converted_preprocessed_sentence.append(self.word2idx[END])\n",
    "\n",
    "            # print(f\"testset_label: {testset_label}, converted preprocessed_sentence:{converted_preprocessed_sentence}\")\n",
    "            # self.textual_ids.append([testset_label,converted_preprocessed_sentence])\n",
    "            self.textual_ids.append(converted_preprocessed_sentence)\n",
    "            # print(f\"self.textual_ids is: {self.textual_ids}\")\n",
    "\n",
    "        pass\n",
    "\n",
    "    def get_text(self, idx):\n",
    "        '''\n",
    "        Return the review at idx as a long tensor (torch.LongTensor) of integers corresponding to the words in the review.\n",
    "        You may need to pad as necessary (see above).\n",
    "\n",
    "        <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
    "        '''\n",
    "\n",
    "        ##### TODO #####\n",
    "        review = self.examples[idx]\n",
    "        indice_review = self.textual_ids[idx]\n",
    "        # print(f\"indice review is: {indice_review}\")\n",
    "\n",
    "        if len(indice_review) >= self.max_len:\n",
    "            indice_review_long_tensor = torch.LongTensor(indice_review[0:self.max_len])\n",
    "\n",
    "        elif len(indice_review) < self.max_len:\n",
    "            padding = [self.word2idx[PAD]] * (self.max_len - len(indice_review))\n",
    "            padded_version = indice_review + padding\n",
    "            # print(f\"padding list is: {padding} and padded version: {padded_version}\")\n",
    "            indice_review_long_tensor = torch.LongTensor(padded_version)\n",
    "            # indice_review_long_tensor = torch.Tensor(padded_version)\n",
    "\n",
    "\n",
    "        # print('Content of indice_review_long_tensor:', indice_review_long_tensor)\n",
    "        # print('Shape of indice_review_long_tensor:', indice_review_long_tensor.shape, '\\n')\n",
    "        # print('Type of indice_review_long_tensor:', indice_review_long_tensor.dtype, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "        return (indice_review_long_tensor)\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        '''\n",
    "        This function should return the value 1 if the label for idx in the dataset is 'positive', \n",
    "        and 0 if it is 'negative'. The return type should be torch.LongTensor.\n",
    "        '''\n",
    "        ##### TODO #####\n",
    "        review_label = self.examples[idx][0]\n",
    "        # print(f\"review label: {review_label}\")\n",
    "\n",
    "        if review_label == 'pos':\n",
    "            return torch.squeeze(torch.LongTensor([1]))\n",
    "            # print('Shape of torch.squeeze(torch.Tensor(1)):', torch.squeeze(torch.Tensor(1)).shape, '\\n')\n",
    "            # return torch.squeeze(torch.Tensor([1]))\n",
    "\n",
    "        elif review_label == 'neg':\n",
    "            return torch.squeeze(torch.LongTensor([0]))\n",
    "            # print('Shape of torch.squeeze(torch.Tensor(0)):', torch.squeeze(torch.Tensor(0)).shape, '\\n')\n",
    "            # return torch.squeeze(torch.Tensor([0]))\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return the number of reviews (int value) in the dataset\n",
    "        '''\n",
    "        ##### TODO #####\n",
    "        return int(len(self.examples))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Return the review, and label of the review specified by idx.\n",
    "\n",
    "        *   <b>` __getitem__(self, idx)`:</b> <b>[10 points]</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here.\n",
    "        '''\n",
    "        ##### TODO #####\n",
    "        # return self.examples[idx][1], self.examples[idx][0]\n",
    "        return self.get_text(idx), self.get_label(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxVxiGGbFJAj"
   },
   "source": [
    "##Sanity Check: Dataset Class\n",
    "\n",
    "The code below runs a sanity check for your `Dataset` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bvHIZt8Z-RzK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset:\n",
      "('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
      "('neg', ['Life', 'is', 'bad', 'when', 'you', 'got', 'not', 'a', 'lot'])\n",
      "\n",
      "--- TEST: idx2word and word2idx dictionaries ---\n",
      "\tthreshold: 1 \tmax_len: 3 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 3 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 3 \tPASSED \t\n",
      "\n",
      "--- TEST: len(dataset) ---\n",
      "\tPASSED\n",
      "\n",
      "--- TEST: __getitem__(self, idx) ---\n",
      "\tthreshold: 1 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 15 \tidx: 1 \tPASSED \t\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "def sanityCheckDataSet():\n",
    "    #\tRead in the sample corpus\n",
    "    reviews = [('pos', 'Your life is good when you have money, success and health'),\n",
    "               ('neg', 'Life is bad when you got not a lot')]\n",
    "    data = [(x[0], preprocess(x[1])) for x in reviews]\n",
    "    print(\"Sample dataset:\")\n",
    "    for x in data: print(x)\n",
    "\n",
    "    thresholds = [1,2,3]\n",
    "    print('\\n--- TEST: idx2word and word2idx dictionaries ---') # max_len does not matter for this test\n",
    "    correct = [[',', '<END>', '<PAD>', '<UNK>', 'a', 'and', 'bad', 'good', 'got', 'have', 'health', 'is', 'life', 'lot', 'money', 'not', 'success', 'when', 'you', 'your'], ['<END>', '<PAD>', '<UNK>', 'is', 'life', 'when', 'you'], ['<END>', '<PAD>', '<UNK>']]\n",
    "    for i in range(len(thresholds)):\n",
    "        dataset = TextDataset(data, 'train', threshold=thresholds[i], max_len=3)\n",
    "\n",
    "        has_passed, message = True, ''\n",
    "        if has_passed and (dataset.vocab_size != len(dataset.word2idx) or dataset.vocab_size != len(dataset.idx2word)):\n",
    "            has_passed, message = False, 'dataset.vocab_size (' + str(dataset.vocab_size) + ') must be the same length as dataset.word2idx (' + str(len(dataset.word2idx)) + ') and dataset.idx2word ('+str(len(dataset.idx2word)) +').'\n",
    "        if has_passed and (dataset.vocab_size != len(correct[i])):\n",
    "            has_passed, message = False, 'Your vocab size is incorrect. Expected: ' + str(len(correct[i])) + '\\tGot: ' + str(dataset.vocab_size)\n",
    "        if has_passed and sorted(list(dataset.idx2word.keys())) != list(range(0, dataset.vocab_size)):\n",
    "            has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(dataset.idx2word.keys())))\n",
    "        if has_passed and sorted(list(dataset.word2idx.keys())) != correct[i]:\n",
    "            has_passed, message = False, 'Your dataset.word2idx has incorrect keys. Expected: ' + str(correct[i]) + '\\tGot: ' + str(sorted(list(dataset.word2idx.keys())))\n",
    "        if has_passed: # Check that word2idx and idx2word are consistent\n",
    "            widx = sorted(list(dataset.word2idx.items())) \n",
    "            idxw = sorted(list([(v,k) for k,v in dataset.idx2word.items()]))\n",
    "            if not (len(widx) == len(idxw) and all([widx[q] == idxw[q] for q in range(len(widx))])):\n",
    "                has_passed, message = False, 'Your dataset.word2idx and dataset.idx2word are not consistent. dataset.idx2word: ' + str(dataset.idx2word) + '\\tdataset.word2idx: ' + str(dataset.word2idx)\n",
    "\n",
    "        status = 'PASSED' if has_passed else 'FAILED'\n",
    "        print('\\tthreshold:', thresholds[i], '\\tmax_len:', 3, '\\t'+status, '\\t'+message)\n",
    "    \n",
    "    print('\\n--- TEST: len(dataset) ---')\n",
    "    has_passed = len(dataset) == 2\n",
    "    if has_passed: print('\\tPASSED')\n",
    "    else: print('\\tlen(dataset) is incorrect. Expected: 2\\tGot: ' + str(len(dataset)))\n",
    "\n",
    "    print('\\n--- TEST: __getitem__(self, idx) ---')\n",
    "    max_lens = [3,8,15]\n",
    "    idxes = [0,1]\n",
    "    combos = [{'threshold': t, 'max_len': m, 'idx': idx} for t in thresholds for m in max_lens for idx in idxes]\n",
    "    correct = [(torch.tensor([3, 4, 5]), torch.tensor(1)), (torch.tensor([ 4,  5, 15]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  1,  0,  0]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18, 19,  1,  0,  0,  0,  0,  0]), torch.tensor(0)), (torch.tensor([2, 3, 4]), torch.tensor(1)), (torch.tensor([3, 4, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0)), (torch.tensor([2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0))]\n",
    "    for i in range(len(combos)):\n",
    "        combo = combos[i]\n",
    "        dataset = TextDataset(data, 'train', threshold=combo['threshold'], max_len=combo['max_len'])\n",
    "        returned = dataset.__getitem__(combo['idx'])\n",
    "\n",
    "        has_passed, message = True, ''\n",
    "        if has_passed and len(returned) != 2:\n",
    "            has_passed, message = False, 'dataset.__getitem__(idx) must return 2 things. Got ' + str(len(returned)) +' things instead.'\n",
    "        if has_passed and (type(returned[0]) != torch.Tensor or type(returned[1]) != torch.Tensor):\n",
    "            has_passed, message = False, 'Both returns must be of type torch.Tensor. Got: (' + str(type(returned[0])) + ', ' + str(type(returned[1])) + ')'\n",
    "        if has_passed and (returned[0].shape != correct[i][0].shape):\n",
    "            has_passed, message = False, 'Shape of first return is incorrect. Expected: ' + str(correct[i][0].shape) + '.\\tGot: ' + str(returned[0].shape)\n",
    "        if has_passed and (returned[1].shape != correct[i][1].shape):\n",
    "            has_passed, message = False, 'Shape of second return is incorrect. Expected: ' + str(correct[i][1].shape) + '.\\tGot: ' + str(returned[1].shape) + '\\n\\t\\tHint: torch.Size([]) means that the tensor should be dimensionless (just a number). Try squeezing your result.'\n",
    "        if has_passed and (returned[1] != correct[i][1]):\n",
    "            has_passed, message = False, 'Label (second return) is incorrect. Expected: ' + str(correct[i][1]) + '.\\tGot: ' + str(returned[1])\n",
    "        if has_passed:\n",
    "            correct_padding_idxes, your_padding_idxes = torch.where(correct[i][0] == 0)[0], torch.where(returned[0] == dataset.word2idx[PAD])[0]\n",
    "            if not (correct_padding_idxes.shape == your_padding_idxes.shape and torch.all(correct_padding_idxes == your_padding_idxes)):\n",
    "                has_passed, message = False, 'Padding is not correct. Expected padding indxes: ' + str(correct_padding_idxes) + '.\\tYour padding indexes: ' + str(your_padding_idxes)\n",
    "\n",
    "        status = 'PASSED' if has_passed else 'FAILED'\n",
    "        print('\\tthreshold:', combo['threshold'], '\\tmax_len:', combo['max_len'] , '\\tidx:', combo['idx'], '\\t'+status, '\\t'+message)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sanityCheckDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR4VQbQCNZH6"
   },
   "source": [
    "The following cell builds the dataset on the IMDb movie reviews and prints an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HSxpGXj6ml9N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 19002 \n",
      "\n",
      "Example text:\n",
      "['Of', 'course', 'the', 'plot', ',', 'script', ',', 'and', ',', 'especially', 'casting', 'are', 'strong', 'in', 'the', 'film', '.', 'So', 'many', 'fine', 'things', 'to', 'see', '.', 'One', 'aspect', 'I', 'liked', 'especially', 'is', 'the', 'idea', 'of', 'the', \"antagonist--Luzhini's\", '(', \"Turturro's)--ex-mentor\", 'working', 'his', 'evil', 'on', 'the', 'sidelines', '.', 'His', 'chess', 'opponent--an', 'Italian', 'dandy', 'in', 'three', 'piece', 'and', 'cane--turns', 'out', 'to', 'be', 'a', 'real', 'gent', ',', 'and', 'a', 'truly', 'fine', 'chess', 'player', '.', 'To', 'his', 'credit', 'the', '\"', 'opponent', '\"', 'nobly', 'goes', 'along', 'with', 'the', 'plan', 'at', 'the', 'end', 'to', 'complete', 'the', 'final', 'game', 'for', 'the', 'championship', 'posthumously', '(', 'Luzhin', 'has', 'taken', 'a', 'flyer', 'out', 'a', 'window--sad', ',', 'but', 'so', 'releasing', 'to', 'him)by', 'way', 'of', 'the', 'unstable', 'genius', \"'\", 'widow', '(', 'Emily', 'Watson.', ')', 'In', 'death', ',', 'then', ',', 'because', 'of', 'the', 'gallantry', 'of', 'an', 'honorable', 'chess', 'master', ',', \"Luzhin's\", 'defence', '(', 'which', 'he', 'worked', 'out', 'in', 'a', 'late', 'moment', 'of', 'lucidity', ')', 'is', 'allowed', 'to', 'be', 'played', '.', 'The', 'Italian', 'gent', 'commends', 'the', 'play', 'and', 'calls', 'it', 'brilliant', '.', 'Talk', 'about', 'a', 'dramatic', '\"', 'end', 'game!', '\"']\n",
      "tensor([  18,  474,    9,  570,   12,  778,   12,   41,   12,  907, 2856,   98,\n",
      "        3429,    6,    9,   14,   21,  174,  175, 2000,  378,   52,  375,   21,\n",
      "          78, 1150,  309, 1760,  907,   24,    9,  450,   18,    9,    2,  263,\n",
      "           2,  620,  120, 2118,  200,    9,    2,   21,  120, 7858,    2, 3305,\n",
      "        8111,    6,  557, 1164,   41,    2,  160,   52,  506,   35, 1316,    2,\n",
      "          12,   41,   35,  422, 2000, 7858, 1695,   21,   52,  120, 3050,    9,\n",
      "          76, 7874,   76,    2,  967, 2466,    8,    9, 3613,  264,    9,  416,\n",
      "          52, 1315,    9,  597, 1940,  106,    9, 8032,    2,  263, 7852,    4,\n",
      "        1348,   35,    2,  160,   35,    2,   12,   86,  174, 8112,   52,    2,\n",
      "         412,   18,    9, 8113,  487, 1284, 1987,  263, 7877,    2,  267,    6,\n",
      "         664,   12,  102,   12,  583,   18,    9,    2,   18,   28, 8114, 7858,\n",
      "         851,   12, 7870, 7904,  263,  382,   37, 4467,  160,    6,   35, 1002,\n",
      "         669,   18,    2,  267,   24, 2050])\n",
      "\n",
      "Example label:\n",
      "pos\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_dataset = TextDataset(train_data, 'train', threshold=10, max_len=150)\n",
    "    print('Vocab size:', train_dataset.vocab_size, '\\n')\n",
    "\n",
    "    randidx = random.randint(0, len(train_dataset)-1)\n",
    "    text, label = train_dataset[randidx]\n",
    "    print('Example text:')\n",
    "    print(train_data[randidx][1])\n",
    "    print(text)\n",
    "    print('\\nExample label:')\n",
    "    print(train_data[randidx][0])\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_4FFhulaAod"
   },
   "source": [
    "# Step 3: Train a Convolutional Neural Network (CNN) [40 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcSKydlClwOC"
   },
   "source": [
    "## <font color='red'>TODO:</font> Define the CNN Model [20 points]\n",
    "Here you will define your convolutional neural network for text classification. We provide you with the CNN class, you need to fill in parts of the `__init__(...)` and `forward(...)` functions. Each of these functions is worth 10 points.\n",
    "\n",
    "We have provided you with instructions and hints in the comments. In particular, pay attention to the desired shapes; you may find it helpful to print the shape of the tensors as you code. It may also help to keep PyTorch documentation open for the modules & functions you are using, since they describe input and output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0ztuy2hUaAof"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, out_channels, filter_heights, stride, dropout, num_classes, pad_idx):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        ##### TODO #####\n",
    "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
    "        # print(f\" vocab size is: {vocab_size}, embed size is: {embed_size}, filter heights: {filter_heights}\")\n",
    "        # number of embeddings = vocab size??\n",
    "        # embedding size = embed size? = max len??\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=pad_idx)\n",
    "        # self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        #self.embedding is learnable\n",
    "\n",
    "        # print(f\"weights of embedding: {self.embedding.weight}\")\n",
    "\n",
    "\n",
    "        # Define multiple Convolution layers (nn.Conv2d) with filter (kernel) size [filter_height, embed_size] based on your \n",
    "        #   different filter_heights.\n",
    "        # Input channels will be 1 and output channels will be out_channels (these many different filters will be trained\n",
    "        #   for each convolution layer)\n",
    "\n",
    "\n",
    "        # If you want, you can store a list of modules inside nn.ModuleList.\n",
    "        self.conv_module_list = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(filter_height, embed_size), stride=stride) for filter_height in filter_heights])\n",
    "        # print(f\"conv module list is: {self.conv_module_list}\")\n",
    "\n",
    "        self.conv_model_outputs = {}\n",
    "\n",
    "        # conv module list is: ModuleList(\n",
    "        #                                   (0): Conv2d(1, 32, kernel_size=(3, 32), stride=(1, 1))\n",
    "        #                                   (1): Conv2d(1, 32, kernel_size=(4, 32), stride=(1, 1))\n",
    "        #                                   (2): Conv2d(1, 32, kernel_size=(5, 32), stride=(1, 1))\n",
    "        #                                 )\n",
    "\n",
    "        # self.maxpool = nn.MaxPool1d(2)\n",
    "\n",
    "        # Note: even though your conv layers are nn.Conv2d, we are doing a 1d convolution since we are only moving the filter \n",
    "        #   in one direction\n",
    "\n",
    "        # Create a dropout layer (nn.Dropout) using dropout\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "        # Define a linear layer (nn.Linear) that consists of num_classes units\n",
    "        #   and takes as input the $concatenated output$ for all cnn layers (out_channels * num_of_cnn_layers units) ???\n",
    "        # print(f\"out_channels * len(filter_heights), :{out_channels * len(filter_heights)}\")\n",
    "        self.dense_layer = nn.Linear(out_channels * len(filter_heights), num_classes)\n",
    "        # another dense layer\n",
    "        # self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, texts):\n",
    "        \"\"\"\n",
    "        texts: LongTensor [batch_size, max_len]\n",
    "        \n",
    "        Returns output: Tensor [batch_size, num_classes]\n",
    "\n",
    "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
    "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
    "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
    "        #   Apply non-linearity on it (F.relu() is a commonly used one. Feel free to try others)\n",
    "        #   Take the max value across last dimension to have shape [batch_size, out_channels]\n",
    "        # Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
    "        #\n",
    "        \"\"\"\n",
    "        ##### TODO #####\n",
    "\n",
    "        # print('Content of texts:', texts)\n",
    "        # print('Shape of texts:', texts.shape, '\\n')\n",
    "        # print('Type of texts:', texts.dtype, '\\n')\n",
    "\n",
    "        texts = texts.type(torch.int64)\n",
    "        final_embedding = self.embedding(texts)\n",
    "\n",
    "        # print('Content of embedding:', final_embedding)\n",
    "        # print('Shape of embedding:', final_embedding.shape, '\\n')\n",
    "        # print('Type of embedding:', final_embedding.dtype, '\\n')\n",
    "        # Resulting: shape: [batch_size, max_len, embed_size]\n",
    "        # Shape of embedding: torch.Size([1, 150, 16])\n",
    "\n",
    "\n",
    "        # Input to conv should have 1 channel. Take a look at torch's unsqueeze() function\n",
    "        #   Resulting shape: [batch_size, 1, MAX_LEN, embed_size]\n",
    "        y = torch.unsqueeze(final_embedding, 1)\n",
    "        # print('Shape of unsqueeze:', y.shape, '\\n')  #CORRECT\n",
    "\n",
    "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
    "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
    "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
    "        #   Apply non-linearity on it (F.relu() is a commonly used\n",
    "        #   one. Feel free to try others)\n",
    "\n",
    "        list_to_be_concatenated = []\n",
    "\n",
    "        for i, conv_model in enumerate(self.conv_module_list):\n",
    "\n",
    "            # Shape of x: torch.Size([1, 32, 148, 1])   #148 = * = depends on filter_height and stride\n",
    "            # Shape of x1_squeezed: torch.Size([1, 32, 148])\n",
    "            # Shape of x1_squeezed_relu: torch.Size([1, 32, 148])\n",
    "\n",
    "            # print(f\"i: {i}, conv_model: {conv_model}\")\n",
    "            x = conv_model(y)\n",
    "            # print('Shape of x:', x.shape, '\\n')  #\n",
    "\n",
    "            x1_squeezed = torch.squeeze(x, dim=3)\n",
    "            # print('Shape of x1_squeezed:', x1_squeezed.shape, '\\n')\n",
    "\n",
    "            x1_squeezed_relu = F.relu(x1_squeezed) #??? #TODO: apply non linearity here??\n",
    "            # print('Shape of x1_squeezed_relu:', x1_squeezed_relu.shape, '\\n')\n",
    "\n",
    "            #   Take the max value across last dimension to have shape [batch_size, out_channels] ??? #TODO: how and why?\n",
    "            # torch.nn.functional.max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)\n",
    "            maxpool_values, maxpool_indices = F.max_pool1d(x1_squeezed_relu, x1_squeezed_relu.shape[2], return_indices=True)\n",
    "            # print(f\"maxpool_values is: {maxpool_values}\")\n",
    "            # print(f\"maxpool_values.shape: {maxpool_values.shape}\")\n",
    "\n",
    "            # print(f\"maxpool_indices is: {maxpool_indices}, maxpool_indices.shape: {maxpool_indices.shape}\")\n",
    "\n",
    "            maxpool_values_squeezed = torch.squeeze(maxpool_values, dim=2)\n",
    "            # print(f\" maxpool_values_squeezed is: {maxpool_values_squeezed}, maxpool_values_squeezed.shape: {maxpool_values_squeezed.shape}\")\n",
    "            list_to_be_concatenated.append(maxpool_values_squeezed)\n",
    "\n",
    "        ##########\n",
    "        # i: 0, conv_model: Conv2d(1, 32, kernel_size=(3, 16), stride=(1, 1))\n",
    "        # i: 1, conv_model: Conv2d(1, 32, kernel_size=(4, 16), stride=(1, 1))\n",
    "        # i: 2, conv_model: Conv2d(1, 32, kernel_size=(5, 16), stride=(1, 1))\n",
    "        # shape of tensor: torch.Size([1, 32, 148])\n",
    "        # shape of tensor: torch.Size([1, 32, 147])\n",
    "        # shape of tensor: torch.Size([1, 32, 146])\n",
    "        ##########\n",
    "        #  Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
    "        list_to_be_concatenated_tensor = torch.cat([i for i in list_to_be_concatenated], dim=1)\n",
    "\n",
    "        # print(f\"list_to_be_concatenated_tensor is: {list_to_be_concatenated_tensor}, shape: {list_to_be_concatenated_tensor.shape}\")\n",
    "        # print(f\"list_to_be_concatenated_tensor: {list_to_be_concatenated_tensor.shape}\")\n",
    "\n",
    "        #  #print shapes\n",
    "        # for tensor in list_to_be_concatenated:\n",
    "        #     print(f\"shape of tensor: {tensor.shape}\")\n",
    "\n",
    "        #[batch_size, (out_channels*num_of_cnn_layers)]\n",
    "        # shape of tensor: torch.Size([20, 32])\n",
    "        # shape of tensor: torch.Size([20, 32])\n",
    "        # shape of tensor: torch.Size([20, 32])\n",
    "        # list_to_be_concatenated_tensor: torch.Size([20, 96])\n",
    "\n",
    "\n",
    "        # Let's understand what you just did:\n",
    "        #   Since each cnn is of different filter_height, it will look at different number of words at a time\n",
    "        #     So, a filter_height of 3 means your cnn looks at 3 words (3-grams) at a time and tries to extract some information from it\n",
    "        #   Each cnn will learn out_channels number of features from the words it sees at a time\n",
    "        #   Then you applied a non-linearity and took the max value for all channels\n",
    "        #     You are essentially trying to find important n-grams from the entire text\n",
    "        # Everything happens on a batch simultaneously hence you have that additional batch_size as the first dimension\n",
    "\n",
    "\n",
    "        # flattened_tensor = torch.flatten(list_to_be_concatenated_tensor)\n",
    "        # print(f\"flattened_tensor is: {flattened_tensor}, shape: {flattened_tensor.shape}\")\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = self.dropout_layer(list_to_be_concatenated_tensor)\n",
    "        # print(f\"dropout is: {dropout}, shape: {dropout.shape}\")\n",
    "\n",
    "        # Pass your output through the linear layer and return its output \n",
    "        #   Resulting shape: [batch_size, num_classes]\n",
    "        # x = self.dense_layer(self.relu(x))\n",
    "\n",
    "        linear = (self.dense_layer(dropout))\n",
    "        # print(f\"linear is: {linear}, shape: {linear.shape}, linear dtype: {linear.dtype}\")\n",
    "\n",
    "\n",
    "        # linear = linear.type(torch.int32)\n",
    "\n",
    "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
    "\n",
    "\n",
    "        return linear\n",
    "        # return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mVE_ujfnh0w"
   },
   "source": [
    "##Sanity Check: CNN Model\n",
    "\n",
    "The code below runs a sanity check for your `CNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yy9oF6qUUHvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
      "\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "count_parameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def sanityCheckModel(all_test_params, NN, expected_outputs, init_or_forward, data_loader):\n",
    "    # print('--- TEST: ' + ('Number of Model Parameters (tests __init__(...))' if init_or_forward=='init' else 'Output shape of forward(...)') + ' ---')\n",
    "    \n",
    "    if init_or_forward == \"forward\":\n",
    "        # Reading the first batch of data for testing\n",
    "        for texts_, labels_ in data_loader:\n",
    "            texts_batch, labels_batch = texts_, labels_\n",
    "            break\n",
    "\n",
    "    for tp_idx, (test_params, expected_output) in enumerate(zip(all_test_params, expected_outputs)):       \n",
    "        if init_or_forward == \"forward\":\n",
    "            batch_size = test_params['batch_size']\n",
    "            texts = texts_batch[:batch_size]\n",
    "\n",
    "        # Construct the student model\n",
    "        tps = {k:v for k, v in test_params.items() if k != 'batch_size'}\n",
    "        stu_nn = NN(**tps)\n",
    "\n",
    "        if init_or_forward == \"forward\":\n",
    "            with torch.no_grad(): \n",
    "                stu_out = stu_nn(texts)\n",
    "            ref_out_shape = expected_output\n",
    "\n",
    "            has_passed = torch.is_tensor(stu_out)\n",
    "            if not has_passed: msg = 'Output must be a torch.Tensor; received ' + str(type(stu_out))\n",
    "            else: \n",
    "                has_passed = stu_out.shape == ref_out_shape\n",
    "                msg = 'Your Output Shape: ' + str(stu_out.shape)\n",
    "            \n",
    "\n",
    "            status = 'PASSED' if has_passed else 'FAILED'\n",
    "            message = '\\t' + status + \"\\t Init Input: \" + str({k:v for k,v in tps.items()}) + '\\tForward Input Shape: ' + str(texts.shape) + '\\tExpected Output Shape: ' + str(ref_out_shape) + '\\t' + msg\n",
    "            print(message)\n",
    "        else:\n",
    "            stu_num_params = count_parameters(stu_nn)\n",
    "            ref_num_params = expected_output\n",
    "            comparison_result = (stu_num_params == ref_num_params)\n",
    "\n",
    "            status = 'PASSED' if comparison_result else 'FAILED'\n",
    "            message = '\\t' + status + \"\\tInput: \" + str({k:v for k,v in test_params.items()}) + ('\\tExpected Num. Params: ' + str(ref_num_params) + '\\tYour Num. Params: '+ str(stu_num_params))\n",
    "            print(message)\n",
    "\n",
    "        del stu_nn\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test init\n",
    "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}]\n",
    "    expected_outputs = [22434, 22531, 22434, 22531, 23874, 23939, 23874, 23939, 41730, 42115, 41730, 42115, 47490, 47747, 47490, 47747, 44578, 44675, 44578, 44675, 47554, 47619, 47554, 47619, 82306, 82691, 82306, 82691, 94210, 94467, 94210, 94467]\n",
    "\n",
    "    sanityCheckModel(inputs, CNN, expected_outputs, \"init\", None)\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}]\n",
    "    expected_outputs = [torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2])]\n",
    "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
    "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    sanityCheckModel(inputs, CNN, expected_outputs, \"forward\", sanity_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyModule(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MyModule, self).__init__()\n",
    "#         self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         # ModuleList can act as an iterable, or be indexed using ints\n",
    "#         for i, l in enumerate(self.linears):\n",
    "#             print(f\"i: {i}, l: {l}\")\n",
    "#\n",
    "#             first_part = self.linears[i // 2](x)\n",
    "#             second_part =  l(x)\n",
    "#             x = first_part + second_part\n",
    "#\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_object = MyModule()\n",
    "# test_object.forward(torch.ones(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FupiBIfasCu_"
   },
   "source": [
    "## Train CNN Model\n",
    "\n",
    "First, we initialize the train and test <b>dataloaders</b>. A dataloader is responsible for providing batches of data to your model. Notice how we first instantiate datasets for the train and test data, and that we use the training vocabulary for both.\n",
    "\n",
    "You do not need to edit this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J2QYl334n9ON"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    THRESHOLD = 5 # Don't change this\n",
    "    MAX_LEN = 200 # Don't change this\n",
    "    BATCH_SIZE = 64 # Feel free to try other batch sizes\n",
    "\n",
    "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvsctopWmeoY"
   },
   "source": [
    "Now we provide you with a function that takes your model and trains it on the data.\n",
    "\n",
    "You do not need to edit this cell. However, you may want to write code to save your model periodically, as Colab connections are not permanent. See the tutorial here if you wish to do this: https://pytorch.org/tutorials/beginner/saving_loading_models.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LD-Jj2rUFOzr"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(model, num_epochs, data_loader, optimizer, criterion):\n",
    "    print('Training Model...')\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for texts, labels in data_loader:\n",
    "            texts = texts.to(DEVICE) # shape: [batch_size, MAX_LEN]\n",
    "            labels = labels.to(DEVICE) # shape: [batch_size]\n",
    "            # print(f\"labels is: {labels}, labels shape: {labels.shape}, labels dtype: {labels.dtype}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(texts)\n",
    "            # print(f\"output is: {output}, output shape: {output.shape}, output dtype: {output.dtype}\")\n",
    "\n",
    "            acc = accuracy(output, labels)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}\\t Train Accuracy: {:.2f}%'.format(epoch+1, epoch_loss/len(data_loader), 100*epoch_acc/len(data_loader)))\n",
    "    print('Model Trained!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyIZS0WUhFA6"
   },
   "source": [
    "Here are some other helper functions we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zVP2scuyhG5f"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    output: Tensor [batch_size, n_classes]\n",
    "    labels: LongTensor [batch_size]\n",
    "    \"\"\"\n",
    "    preds = output.argmax(dim=1) # find predicted class\n",
    "    correct = (preds == labels).sum().float() # convert into float for division \n",
    "    acc = correct / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjvX5c6Isw9e"
   },
   "source": [
    "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M5UtdjGDuBty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,879,746 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    cnn_model = CNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
    "                embed_size = 128, \n",
    "                out_channels = 64, \n",
    "                filter_heights = [2, 3, 4], \n",
    "                stride = 1, \n",
    "                dropout = 0.5, \n",
    "                num_classes = 2, # Don't change this\n",
    "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
    "\n",
    "    # Put your model on the device (cuda or cpu)\n",
    "    cnn_model = cnn_model.to(DEVICE)\n",
    "    \n",
    "    print('The model has {:,d} trainable parameters'.format(count_parameters(cnn_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeHpqw6zvkhI"
   },
   "source": [
    "Next, we create the **criterion**, which is our loss function: it is a measure of how well the model matches the empirical distribution of the data. We use cross-entropy loss (https://en.wikipedia.org/wiki/Cross_entropy).\n",
    "\n",
    "We also define the **optimizer**, which performs gradient descent. We use the Adam optimizer (https://arxiv.org/pdf/1412.6980.pdf), which has been shown to work well on these types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FoeyQL4PoNoH"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':    \n",
    "    LEARNING_RATE = 6e-4 # Feel free to try other learning rates\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RopLfAJ9wOHN"
   },
   "source": [
    "Finally, we can train the model. If the model is implemented correctly and you're using the GPU, this cell should take around <b>4 minutes</b> (or less). Feel free to change the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b82114f88a24057b17424b5fa5c42aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]\t Epoch:  1\t Loss: 0.6979\t Train Accuracy: 59.85%\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.5604\t Train Accuracy: 70.98%\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.5049\t Train Accuracy: 75.31%\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.4623\t Train Accuracy: 77.95%\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.4277\t Train Accuracy: 80.37%\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.3992\t Train Accuracy: 82.04%\n",
      "[TRAIN]\t Epoch:  7\t Loss: 0.3707\t Train Accuracy: 83.51%\n",
      "[TRAIN]\t Epoch:  8\t Loss: 0.3333\t Train Accuracy: 85.33%\n",
      "[TRAIN]\t Epoch:  9\t Loss: 0.3009\t Train Accuracy: 87.17%\n",
      "[TRAIN]\t Epoch: 10\t Loss: 0.2704\t Train Accuracy: 88.47%\n",
      "[TRAIN]\t Epoch: 11\t Loss: 0.2380\t Train Accuracy: 90.42%\n",
      "[TRAIN]\t Epoch: 12\t Loss: 0.2045\t Train Accuracy: 91.78%\n",
      "Model Trained!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    N_EPOCHS = 12 # Feel free to change this == 20 == best\n",
    "\n",
    "    # train model for N_EPOCHS epochs\n",
    "    train_model(cnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-OJbZ72t6Yq"
   },
   "source": [
    "## Evaluate CNN Model [20 points]\n",
    "\n",
    "Now that we have trained a model for text classification, it is time to evaluate it. We have provided you with a function to do this; you do not need to modify anything.\n",
    "\n",
    "To pass the autograder for the CNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vTiiYDZIF--7"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "import random\n",
    "\n",
    "def evaluate(model, data_loader, criterion, use_tqdm=False):\n",
    "    print('Evaluating performance on the test dataset...')\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    all_predictions = []\n",
    "    print(\"\\nSOME PREDICTIONS FROM THE MODEL:\")\n",
    "    iterator = tqdm(data_loader) if use_tqdm else data_loader\n",
    "    total = 0\n",
    "    for texts, labels in iterator:\n",
    "        bs = texts.shape[0]\n",
    "        total += bs\n",
    "        texts = texts.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        output = model(texts)\n",
    "        acc = accuracy(output, labels) * len(labels)\n",
    "        pred = output.argmax(dim=1)\n",
    "        all_predictions.append(pred)\n",
    "        \n",
    "        loss = criterion(output, labels) * len(labels)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        if random.random() < 0.0015 and bs == 1:\n",
    "            print(\"Input: \"+' '.join([data_loader.dataset.idx2word[idx] for idx in texts[0].tolist() if idx not in {data_loader.dataset.word2idx[PAD], data_loader.dataset.word2idx[END]}]))\n",
    "            print(\"Prediction:\", pred.item(), '\\tCorrect Output:', labels.item(), '\\n')\n",
    "\n",
    "    full_acc = 100*epoch_acc/total\n",
    "    full_loss = epoch_loss/total\n",
    "    print('[TEST]\\t Loss: {:.4f}\\t Accuracy: {:.2f}%'.format(full_loss, full_acc))\n",
    "    predictions = torch.cat(all_predictions)\n",
    "    return predictions, full_acc, full_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Z718w8e0oNoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance on the test dataset...\n",
      "\n",
      "SOME PREDICTIONS FROM THE MODEL:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "378830df72ab44019b3231cc24b8f3ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i'm 60 years old , a guitarist , ( <UNK> , and over the last forty years , i've been in four bands , it's all there , the fights , the <UNK> , the rotten food , the worse <UNK> , always travelling , little or no money , and every one was drunk or high . but , the clubs , the fans , and the music , made it all worth it ! just like strange fruit ! i'm too damn old for it now , and the <UNK> in the hands and hips mean no more rocking , but for the length of that video , it all came back , and it was all there ! the birds , the brawls , and the booze ! and i was young again ! it's just like billy <UNK> voice over , god likes that 70's stuff ! rock on forever !\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: this comedy with much underlying pain and sadness succeeds where most others fail . there have been many films of this genre with more notable actors attempting to achieve this elusive mixture which haven't come anywhere near the depth and <UNK> of this one . this is surely because the exceptional cast with outstanding performances by reg rogers and ally <UNK> seem so spontaneous that the reality of their characters rapidly grip your interest and emotions and hold them throughout the film . at first , the action seems rather off-the-wall and <UNK> but one gradually learns that these two rather pathetic damaged people are desperately and unwillingly trying to heal themselves , even if grudgingly , through each other . rogers ' heartrending facial expressions of numb hurt and <UNK> angry outbursts are so eloquent that one feels them as one observes them . you will care about these two likable but deeply suffering people and hope that they will succeed because it's in doubt and all hangs on a tenuous emotional thread . hopefully audiences will get to see more of reg rogers and ally <UNK> as this film proves their merit as very accomplished actors beyond doubt\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: bette davis ' electrifying performance is such that it is hard to remember the other female players . they were as perfect in their parts as davis was in hers - they just didn't have as much to do . some of the reviewers felt that the book was so much better - it was but to give the film it's due , to <UNK> a 600 page book down to 83 minutes is no mean feat . the first part of the book didn't even make it to the screen - it told of <UNK> childhood , then moved to germany and paris , where phillip had gone to try to make good as an artist . it also chronicles his first romance - with fanny price , who kills herself when she realises phillip cannot return her feelings of love . it is a wonderful book but rambling and i think that anyone who does not think too highly of the film should read the book and will realise how good the film is.<br /><br />after realising that he will only ever be a mediocre painter , phillip carey ( leslie howard ) comes back to england hoping\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: <UNK> the bette davis version of this film was better than the kim novak version.<br /><br />despite all of the other comments written here , i really prefer the bette davis version , even though the novak version has a more coherent story line.<br /><br />however : davis ' <UNK> raw emotions seem to me to be more apt to a sluttish girl who seems easily to become a <UNK> /><br />and it is those raw emotions that constitute <UNK> of what the poor doctor falls in love with . he has emotions of despair , of failure , of \" <UNK> \" - strong emotions that he <UNK> . davis ' mildred , on the other hand , displays her emotions immediately and without <UNK> . she has no feelings of despair , or of failure , or of \" <UNK> ; rather , she is merely surviving as a poor cockney woman in the victorian era.<br /><br <UNK> portrayal was a more vulnerable mildred than was <UNK> , almost through the the whole movie . davis ' mildred was <UNK> vulnerable until she actually had to go to the doctor and beg for assistance . and when he\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: i love the book , \" jane eyre \" and have seen many versions of it . all have their strong points and their faults . however , this was one of the worst i have seen . i didn't care about jane or mr . rochester . charlotte gainsbourg ( jane ) was almost tolerable and certainly looked the plain part , but she had no emotion in any of her lines . i couldn't imagine what mr . rochester saw in her . <br /><br />that brings us to mr . rochester . william hurt had even less emotion than jane , if that were possible . how two such insipid people could fall in love is a mystery , but it certainly didn't hold my attention . perhaps the director ( <UNK> ) fell asleep during the production.<br /><br />the timothy dalton ( too handsome for mr . <UNK> ) version is far more faithful to the book , but ciaran hinds plays the perfect mr . rochester in the 1997 <UNK> version ( which is not all that true to the <UNK> /><br <UNK> to find something positive about this movie : geraldine <UNK> was perfect\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: ever since i was eight years old i have been a big wrestling fan . it didn't matter what federation i watched . <UNK> . to me the action is all i watched it for.<br /><br />may <UNK> 1999 . that was my 19 birthday . i ordered over the edge and i was just expecting another pay per view . but this time . i was wrong . instead that was the night one of the best wrestlers to come out of canada a true human being fell to his death due to a stunt gone wrong . not much you can do to change the situation . but what happened <UNK> <UNK> death made me very <UNK> /><br />rather then ending the pay per view and doing the right thing as human beings the wwe decided to protect what comes first and that was the money by keeping the pay per view going as if <UNK> death never happened.<br /><br />i gotta tell you . vince <UNK> has made some stupid decisions in his life but this was by far the stupidest decision he ever made.<br /><br />and this crap with saying owen would have wanted the pay\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "[TEST]\t Loss: 0.4111\t Accuracy: 82.30%\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    evaluate(cnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRCFvjwDthiA"
   },
   "source": [
    "# Step 4: Train a Recurrent Neural Network (RNN) [40 points]\n",
    "You will now build a text clasification model that is based on **recurrences**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-t8tlZviV2x"
   },
   "source": [
    "## <font color='red'>TODO:</font> Define the RNN Model [20 points]\n",
    "\n",
    "First, you will define the RNN. As with the CNN, we provide you with the skeleton of the class, and you need to fill in parts of the `__init__(...)` and `forward(...)` methods. Each of these functions is worth 10 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2nc_HxbP6klI"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional, dropout, num_classes, pad_idx):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        ##### TODO #####\n",
    "\n",
    "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=pad_idx)\n",
    "        self.embed_size = embed_size\n",
    "        # Create a recurrent network (use nn.GRU, not nn.LSTM) with batch_first = True\n",
    "        # Make sure you use hidden_size, num_layers, dropout, and bidirectional here.\n",
    "        self.GRU = nn.GRU(input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout, bidirectional=bidirectional).to(DEVICE)\n",
    "\n",
    "\n",
    "        if bidirectional==True:\n",
    "            self.D =2\n",
    "        elif bidirectional==False:\n",
    "            self.D=1\n",
    "\n",
    "        # self.initial_state_h0 = 0\n",
    "\n",
    "\n",
    "        # Create a dropout layer (nn.Dropout) using dropout\n",
    "        self.dropout_layer = nn.Dropout(dropout).to(DEVICE)\n",
    "\n",
    "        # Define a linear layer (nn.Linear) that consists of num_classes units\n",
    "        #   and takes as input the output of the last timestep. In the bidirectional case, you should concatenate\n",
    "        #   the output of the last timestep of the forward direction with the output of the last timestep of the backward direction).\n",
    "\n",
    "        self.dense_layer = nn.Linear(hidden_size*self.D, num_classes).to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, texts):\n",
    "        \"\"\"\n",
    "        texts: LongTensor [batch_size, MAX_LEN]\n",
    "        \n",
    "        Returns output: Tensor [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        ##### TODO #####\n",
    "        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
    "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
    "        texts = texts.type(torch.int64)\n",
    "        final_embedding = (self.embedding(texts))\n",
    "        final_embedding_gpu = final_embedding.to(DEVICE)\n",
    "        # print(f\"  final_embedding_gpu: {final_embedding_gpu.shape}, final_embedding_gpu dtype: {final_embedding_gpu.dtype}, final_embedding_gpu device: {final_embedding_gpu.get_device()}\")\n",
    "\n",
    "        # print('Content of embedding:', final_embedding)\n",
    "        # print('Shape of embedding:', final_embedding.shape, '\\n')\n",
    "        # print('Type of embedding:', final_embedding.dtype, '\\n')\n",
    "        batch_size, max_len = texts.shape\n",
    "        # print(f\"batch_size: {batch_size}, max_len: {max_len}\")\n",
    "        # print(f\"(batch_size, max_len, self.hidden_size): ({batch_size}, {max_len}, {self.hidden_size})\")\n",
    "\n",
    "        initial_state_h0 = torch.nn.parameter.Parameter(torch.randn(self.D*self.num_layers, batch_size, self.hidden_size)).to(DEVICE)\n",
    "        # print(f\"  initial_state_h0: {initial_state_h0.shape}, initial_state_h0 dtype: {initial_state_h0.dtype}, initial_state_h0 device: {initial_state_h0.get_device()}\")\n",
    "\n",
    "        # gru_input = torch.randn(batch_size, max_len, self.hidden_size).to(device)\n",
    "        # print(f\"  gru_input: {gru_input.shape}, gru_input dtype: {gru_input.dtype}, gru_input device: {gru_input.get_device()}\")\n",
    "        # # h_out = 32\n",
    "\n",
    "\n",
    "\n",
    "        # Pass the result through your recurrent network\n",
    "        #   See PyTorch documentation for resulting shape for nn.GRU\n",
    "        output, hn = self.GRU(final_embedding_gpu, initial_state_h0)\n",
    "        # print(f\"  output: {output.shape}, output dtype: {output.dtype}\")\n",
    "        # print(f\" hn: {hn.shape}, hn dtype: {hn.dtype}\")\n",
    "\n",
    "\n",
    "        # Concatenate the outputs of the last timestep for each direction (see torch.cat(...))\n",
    "        #   This depends on whether or not your model is bidirectional.\n",
    "        #   Resulting shape: [batch_size, num_dirs*hidden_size]\n",
    "        # concatenated_output = torch.cat([h for h in output], dim=0)\n",
    "        concatenated_output = output[:, -1, :]\n",
    "        # print(f\"concatenated_output: {concatenated_output.shape}, concatenated_output dtype: {concatenated_output.dtype}\")\n",
    "\n",
    "        # batch_size: 1, max_len: 150\n",
    "        # (batch_size, max_len, self.hidden_size): (1, 150, 32)\n",
    "        #   gru_input: torch.Size([1, 150, 16]), gru_input dtype: torch.float32\n",
    "        #   initial_state_h0: torch.Size([4, 1, 32]), initial_state_h0 dtype: torch.float32\n",
    "        #   output: torch.Size([1, 150, 64]), output dtype: torch.float32\n",
    "        #  hn: torch.Size([4, 1, 32]), hn dtype: torch.float32\n",
    "        #  concatenated_output: torch.Size([4, 32]), concatenated_output dtype: torch.float32\n",
    "        #  dropout: torch.Size([4, 32]), dropout dtype: torch.float32\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = self.dropout_layer(concatenated_output)\n",
    "        # print(f\" dropout: {dropout.shape}, dropout dtype: {dropout.dtype}\")\n",
    "\n",
    "        # Pass your output through the linear layer and return its output \n",
    "        #   Resulting shape: [batch_size, num_classes]\n",
    "        linear_output = self.dense_layer(dropout)\n",
    "        # print(f\" linear_output: {linear_output.shape}, linear_output dtype: {linear_output.dtype}\")\n",
    "\n",
    "\n",
    "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
    "\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDLTiJMyoLxJ"
   },
   "source": [
    "##Sanity Check: RNN Model\n",
    "\n",
    "The code below runs a sanity check for your `RNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Duq7X2ClwXga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44546\tYour Num. Params: 44546\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 44676\tYour Num. Params: 44676\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 27202\tYour Num. Params: 27202\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 27268\tYour Num. Params: 27268\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82178\tYour Num. Params: 82178\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 82308\tYour Num. Params: 82308\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 39874\tYour Num. Params: 39874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 39940\tYour Num. Params: 39940\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1620610\tYour Num. Params: 1620610\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1621636\tYour Num. Params: 1621636\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 621698\tYour Num. Params: 621698\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 622212\tYour Num. Params: 622212\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 3986050\tYour Num. Params: 3986050\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 3987076\tYour Num. Params: 3987076\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1411202\tYour Num. Params: 1411202\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1411716\tYour Num. Params: 1411716\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 101762\tYour Num. Params: 101762\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 101892\tYour Num. Params: 101892\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 79810\tYour Num. Params: 79810\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 79876\tYour Num. Params: 79876\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 139394\tYour Num. Params: 139394\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 139524\tYour Num. Params: 139524\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 92482\tYour Num. Params: 92482\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 92548\tYour Num. Params: 92548\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1742338\tYour Num. Params: 1742338\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1743364\tYour Num. Params: 1743364\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 706562\tYour Num. Params: 706562\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 707076\tYour Num. Params: 707076\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 4107778\tYour Num. Params: 4107778\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 4108804\tYour Num. Params: 4108804\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1496066\tYour Num. Params: 1496066\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1496580\tYour Num. Params: 1496580\n",
      "\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test init\n",
    "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}]\n",
    "    expected_outputs = [44546, 44676, 27202, 27268, 82178, 82308, 39874, 39940, 1620610, 1621636, 621698, 622212, 3986050, 3987076, 1411202, 1411716, 101762, 101892, 79810, 79876, 139394, 139524, 92482, 92548, 1742338, 1743364, 706562, 707076, 4107778, 4108804, 1496066, 1496580]\n",
    "\n",
    "    sanityCheckModel(inputs, RNN, expected_outputs, \"init\", None)\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}]\n",
    "    expected_outputs = [torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4])]\n",
    "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
    "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    sanityCheckModel(inputs, RNN, expected_outputs, \"forward\", sanity_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baD8lYAytdTV"
   },
   "source": [
    "## Train RNN Model\n",
    "First, we initialize the train and test dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WCzNm8LDM5aT"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    THRESHOLD = 5 # Don't change this\n",
    "    MAX_LEN = 200 # Don't change this\n",
    "    BATCH_SIZE = 64 # Feel free to try other batch sizes\n",
    "\n",
    "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lp5pAz8emxi2"
   },
   "source": [
    "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CA-UairGErap"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,300,546 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    rnn_model = RNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
    "                embed_size = 128, \n",
    "                hidden_size = 128, \n",
    "                num_layers = 2,\n",
    "                bidirectional = True,\n",
    "                dropout = 0.5,\n",
    "                num_classes = 2, # Don't change this\n",
    "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
    "\n",
    "    # Put your model on device\n",
    "    rnn_model = rnn_model.to(DEVICE)\n",
    "\n",
    "    print('The model has {:,d} trainable parameters'.format(count_parameters(rnn_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqngFY4MoLec"
   },
   "source": [
    "Here, we create the criterion and optimizer; as with the CNN, we use cross-entropy loss and Adam optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "em6Rs58OlJ3Z"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':    \n",
    "    LEARNING_RATE = 6e-4 # Feel free to try other learning rates\n",
    "\n",
    "    # Define your loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "    # Define your optimizer\n",
    "    optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEPsi3choUm5"
   },
   "source": [
    "Finally, we can train the model. We use the same `train_model(...)` function that we defined for the CNN. If the model is implemented correctly and you're using the GPU, this cell should take around <b>2 minutes</b> (or less). Feel free to change the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NR8Wckf0l2G7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a24206af68a4b7e96635bb8deb401a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]\t Epoch:  1\t Loss: 0.7108\t Train Accuracy: 50.08%\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.6885\t Train Accuracy: 54.02%\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.6991\t Train Accuracy: 50.29%\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.6777\t Train Accuracy: 56.75%\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.6253\t Train Accuracy: 62.22%\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.3814\t Train Accuracy: 83.53%\n",
      "[TRAIN]\t Epoch:  7\t Loss: 0.2702\t Train Accuracy: 89.25%\n",
      "[TRAIN]\t Epoch:  8\t Loss: 0.1994\t Train Accuracy: 92.58%\n",
      "Model Trained!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    N_EPOCHS = 8 # Feel free to change this\n",
    "    \n",
    "    # train model for N_EPOCHS epochs\n",
    "    train_model(rnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-SRIFfooYk6"
   },
   "source": [
    "## Evaluate RNN Model [20 points]\n",
    "\n",
    "Now we can evaluate the RNN. \n",
    "\n",
    "To pass the autograder for the RNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HYon4AbHl5_M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance on the test dataset...\n",
      "\n",
      "SOME PREDICTIONS FROM THE MODEL:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84735f85194f4e9a8703cfdfe2a9c8ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: every time this film is on the bbc somebody in the radio times says how it is a satire against the post war world of <UNK> and the welfare state . i do not think this is the point of the film at all . the film parodies the <UNK> time criminals who ran the <UNK> ) and the housewives league who <UNK> against government restrictions but were really a <UNK> front <UNK> /><br />yes of course the film sends up the <UNK> situation but in the end the people realise that they need all the controls to ensure a fair <UNK> want to be british and muddle through rather than <UNK> /><br />but i don't think they go back to being exactly like they were before .\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: fascinating yet unsettling look at edith <UNK> <UNK> ( big <UNK> ) and her daughter ( little <UNK> ) aunt and first cousin to the late <UNK> kennedy <UNK> . they live in a rodent infested , rundown mansion which was considered a health hazard by the city . it becomes quite clear very quickly that these two are well past eccentric . little <UNK> seems to be the most off as she acts with the mindset of a ten year old even though she is actually 53 . the content is pretty much made up of two things . the first are the conversations were little <UNK> <UNK> big <UNK> for driving away all her potential suitors and ruining her aspiring career as writer , actress , and dancer . these discussions usually become very <UNK> , nonsensical , and often times amusing . the second part consists of long bouts of attempted singing by both parties . each of course thinks their singing is perfect and it's only the other who sounds bad . in one amazing scene big <UNK> actually physically attacks little <UNK> with her cane just to get her to stop her warbling . very\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: if you love kung-fu films and you haven't seen this movie , you are cheating yourself . this movie is one of the only kung-fu <UNK> that could be recommended for fans of all types of film . normally , it takes a die-hard fan of the genre to see anything in these films , but this one has it all ! the story is well told , and complete . the fight scenes are great , and tend to end before you're completely bored with them ( unlike crouching <UNK> . throw in a little mystery and torture and you've got yourself one heck of a movie . see this one at all costs . heck , my wife even enjoyed it.<br /><br <UNK> du it!<br /><br />9 out of 10<br /><br />\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: \" jared diamond made a point in the first episode that other peoples of the world didn't have animals to <UNK> but europeans did , and that accounts for why we were able to make steel and invent complex <UNK> . --- it is obvious that the person who wrote this comment hasn't understood the reasoning behind this documentary or the original book . please don't ruin this great piece by your simple <UNK> . the reasons are far more complex than the single thing you mentioned . please read the book as is it a great source of information . i enjoyed it a lot . this book is even a taught as a text book at some universities .\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: i really thought they did an <UNK> job , there was nothing wrong with it at all , i don't know how the first commenter could have said it was terrible , it moved me to tears ( i guess it moved about everyone to tears ) but i try not to cry in a movie because it's embarrassing but this one got me . it was sooo good ! i hope they release it on dvd because i will definitely buy a copy ! i feel like it renewed my faith and gave me a hope that i can't explain , it made me want to strive to be a better person , they went through so much and we kind of take that for granted , i guess . compared to that , i feel like our own trials are nothing . well , not nothing , but they hardly match what they had to go through . i loved it . who played <UNK> !\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: <br /><br />film dominated by <UNK> barbara steele , it was seen when i was seven or eight and created permanent images of <UNK> <UNK> men and women stalking a castle , seeking blood . steele is an icon of horror films and an otherworldly beauty , and the views of the walking dead <UNK> romero's night of the living dead <UNK> , <UNK> them in my mind.<br /><br />i don't see the connection between this film and the haunting , which is clever but ambiguous about the forces present . la danza macabre is a b-movie without <UNK> , daring you to fall in love with barbara steele and suffer the consequences . there's no such draw to <UNK> overwrought claire bloom . the comparisons to the haunting are <UNK> /><br />and no , this movie does not need to be remade . not only is it a product of the sixties , but the large percentage of talentless <UNK> in hollywood cannot fathom <UNK> formula for terror . that formula is based on one overriding factor : good writing . low-grade classics like castle and corman's poe films with r . matheson and <UNK> out of the past\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: here's a decent <UNK> horror flick about a gate of hell in nyc that just happens to be an old <UNK> . seems like there's lots of gates of hell around , but of course this <UNK> model happens to decide she needs some space from her <UNK> and so she just happens to pick one , which is disguised as a nice and reasonably <UNK> apartment . she meets several strange neighbors , and even attends a birthday party for a cat . upon meeting with the <UNK> because she hears strange noises at night from upstairs , she finds out that she and an old priest are supposed to be the only tenants . whoa ! then who are all these weirdos ? her boyfriend ( a slimy lawyer , played by chris sarandon ) starts poking around and finds that things are not what they seem , not by a long shot . this has some decent creepy scenes and the idea of the creaky old folks that are her \" sometimes \" neighbors being other than what they appear is fairly intriguing . a bit of decent gore and even a parade of <UNK> folks towards\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: to be honest at the time i first heard of this show i though it may be a bad idea to make a show that makes muslims use racial jokes on themselves but it is the exact opposite . i realized that the show doing that can help people understand that if a muslim uses s a word like this in real life it doesn't mean it is a terrorist thing . it also show's how people give the muslims a bad name because they play on their stereotype , by watching the show regular people will realize that all though there may be bad muslims out it doesn't mean we are all bad we just try to live 1 day at a time , like how hard it was for <UNK> to get on a plane and how he used words like \" blow up \" or <UNK> saying we'll blow away the competition , and people took it the wrong way . being a muslim i know that stuff like this don't usually happen , but they do and many people think bad things about muslims or afghanistan or iraq , its not right things are not like\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: my family and i screened underdog the night before . and as bad as underdog is (  my four year old loved it) , hot rod makes it look like oscar worthy material . the only thing that could have saved this movie , was if <UNK> himself had come out of retirement to slap <UNK> in the face for making this movie . i will admit however , that the soundtrack was good . i wasn't sure if the movie was set in the 80's , but with the majority of the music coming from europe ? who knows . if i were you , i would take a pass . and just stay at home and watch the test pattern on your local tv station . or if you are dead set on watching this , people under the influence might enjoy it .\n",
      "Prediction: 1 \tCorrect Output: 0 \n",
      "\n",
      "Input: i had always been a big lynda <UNK> woman fan so when the sci-fi channel ran this <UNK> had to see it.i was bitterly <UNK> is a wonder woman movie in name <UNK> doesn't wear the right costume <UNK> must have refused to or had ordered major <UNK> and the plot runs like a poor man's james <UNK> none of the things that made the comic book heroine a success i.e . the superhuman strength or determined <UNK> just one long bad <UNK> don't even think cathy is all that attractive <UNK> wouldn't waste your time on this .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "[TEST]\t Loss: 0.4288\t Accuracy: 82.94%\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    evaluate(rnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WQAV6O2xHvS"
   },
   "source": [
    "# What to Submit\n",
    "\n",
    "To submit the assignment, download this notebook as a <TT>.py</TT> file. You can do this by going to <TT>File > Download > Download .py</TT>. Then (optionally) rename it to `hwk2.py`.\n",
    "\n",
    "You will also need to save the `cnn_model` and `rnn_model`. You can run the cell below to do this. After you save the files to your Google Drive, you need to manually download the files to your computer, and then submit them to the autograder.\n",
    "\n",
    "You will submit the following files to the autograder:\n",
    "1.   `hwk2.py`, the download of this notebook as a `.py` file (**not** a `.ipynb` file)\n",
    "1.   `cnn.pt`, the saved version of your `cnn_model`\n",
    "1.   `rnn.pt`, the saved version of your `rnn_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "abbbMNi8X_ai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving CNN model....\n",
      "Saving RNN model....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        cnn_model is None\n",
    "        cnn_exists = True\n",
    "    except:\n",
    "        cnn_exists = False\n",
    "\n",
    "    try:\n",
    "        rnn_model is None\n",
    "        rnn_exists = True\n",
    "    except:\n",
    "        rnn_exists = False\n",
    "\n",
    "    if cnn_exists:\n",
    "        print(\"Saving CNN model....\") \n",
    "        # torch.save(cnn_model, \"drive/My Drive/cnn.pt\")\n",
    "        torch.save(cnn_model, \"saved_models/cnn.pt\")\n",
    "    if rnn_exists:\n",
    "        print(\"Saving RNN model....\") \n",
    "        # torch.save(rnn_model, \"drive/My Drive/rnn.pt\")\n",
    "        torch.save(cnn_model, \"saved_models/rnn.pt\")\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "v4o5fRQELX7G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
