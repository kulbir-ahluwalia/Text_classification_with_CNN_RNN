{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "PyTorch_Tutorial.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVN-3zxT7XCy"
   },
   "source": [
    "# PyTorch Tutorial with Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwx8EqIqxqJO"
   },
   "source": [
    "\n",
    "In this tutorial, we will first review the mathematics behind vectors, matrics and tensors. Then we learn the PyTorch basics, and show you how to construct a simple deep neural network (DNN/CNN).\n",
    "\n",
    "After finishing this tutorial, you will able to create, transpose, squeeze, and change the order of a tensor. You will also be able to understand the basic structure of a neural network.\n",
    "\n",
    "Important: You need to run all cells in this notebook in order. Otherwise, you may not import the right libraries, and the code may not run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uulwYFv_7QmC"
   },
   "source": [
    "# Background: the mathematics of scalars, vectors, matrices and tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUve_YSvyKOi"
   },
   "source": [
    "\n",
    "\n",
    "In mathematics,  **tensors** are a multi-dimensional generalization of **scalars**, **vectors** and **matrices**. \n",
    "(NB: PyTorch, the `Tensor` data structure is used to implement tensors, vectors and matrices. We will get to that below)\n",
    "\n",
    "\n",
    "We assume that you have come across scalars, vectors, and matrices before: \n",
    "\n",
    "* **Scalar** is just a fancy term for a single (natural/integer/real/complex) number. You can think of a scalar as a **zero-dimensional arrays**.  We typically assume we are dealing with real-valued scalars $x\\in \\mathbb{R}$,  e.g. $x=3.4$ or $x=2.0$. \n",
    "\n",
    "* An **$n$-dimensional vector** $\\mathbf{x}$ is a **one-dimensional array** of $n$ scalars:  $$\\mathbf{x} = [2, 5, 10]$$ with elements $x_1 = 2$, $x_2 = 5$, $x_3 = 10$ and $n=3$. \n",
    "\n",
    "* Mathematically,  a vector represents a point in $n$-dimensional space, although we will sometimes just think of it as a list of $n$ numbers. We typically assume that all components of a vector $\\mathbf{x}$ are scalars of the same type (e.g. real numbers), which allows us to write $\\mathbf{x} \\in \\mathbb{R}^n$ (for a real vector)). \n",
    "\n",
    "* Note that the scalar $x$ is not the same as the one-dimensional vector $$\\mathbf{x} = [x]$$ (you can form a product of (multiply) any n-dimensional vector $\\mathbf{y}$ with a scalar $x$, but you cannot form any product of two vectors $\\mathbf{x}$ and $\\mathbf{y}$, unless they have the same dimensionality) \n",
    "\n",
    "* An $n\\!\\times\\!m$**-dimensional matrix** $X$ is a **two-dimensional array** of scalars with $n$ rows and $m$ columns, eg.: \n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "   1 & 2 \\\\\n",
    "   3 & 4 \\\\ \n",
    "   5 & 6 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "* Here, the matrix $A$ has three **rows** ($[1,2]$, $[3,4]$, and $[5,6]$) and two **columns** ($[1,3,5]$ and $[2,4,6])$. Note that each row and each column can be seen as a vector, so you can think of a matrix as an array of vectors. \n",
    "\n",
    "* However, rows and columns are not interchangeable. The **size**  of matrix $A$ is $3 \\times 2$ , corresponding to the product of number of rows and columns, while the size of matrix $B$ is $2 \\times 3$:\n",
    "\n",
    "$$B = \\begin{bmatrix}\n",
    "   1 & 3 & 5 \\\\\n",
    "   2 & 4 & 6\\\\ \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "* Mathematically,  a matrix $X$ maps points in an $n$-dimensional space to points in an $m$ dimensional space via matrix multiplication (more on that below).  We again assume that all $n\\times m$ elements of a matrix are scalars of the same type (typically reals) and write $X \\in \\mathbb{R}^{n \\times m}$)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* **Tensors** generalize vectors and matrices to **multi-dimensional arrays**. \n",
    "You can think of a three-dimensional tensor as a vector of matrices (or a matrix of vectors, depending on which way you look at it). \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZCU8GWZ7hGc"
   },
   "source": [
    "# Tensors as data structures in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwbtwXhmz4cn"
   },
   "source": [
    "\n",
    "\n",
    "In PyTorch,  a Tensor (`torch.Tensor`) is a multi-dimensional matrix containing elements of a **single data type** (typically floating point or integer).  \n",
    "\n",
    "PyTorch Tensors are similar to Numpy Arrays, but Tensors are  better suited for deep learning. Tensors can run on GPUs/TPUs, and are optimized for automatic differentiation, allowing us to compute gradients and update their values in a very straightforward manner. \n",
    "\n",
    "(Tensors on the CPU and Numpy arrays can share their underlying memory locations, and changing one will change the other. You can ignore that if you are just using PyTorch, or if you want to use GPUs, both of which we recommend).\n",
    "\n",
    "When we implement neural nets in PyTorch, we use tensors to encode the **inputs** and **outputs** of the model, as well as the model’s **parameters** (sets of weights).\n",
    "\n",
    "\n",
    "## Usefule attributes of Tensors:\n",
    "- The `type(x)` function and the `x.dtype` argument return the type of the Tensor `x`, and can be very useful for **debugging purposes**. \n",
    "\n",
    "- The `x.shape` argument indicates the size of each dimension of Tensor `x`.  \n",
    "\n",
    "- The `x.device` argument tells you what device Tensor `x` is stored on (cpu or gpu). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQq98KbFyD6A"
   },
   "source": [
    "# Setup: Import Libraries and Select Device (CPU/GPU)\n",
    "\n",
    "To use PyTorch, you need to import the necessary libraries and decide whether to use a CPU or GPU (Cuda). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8VXWCRsvOHc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632109951098,
     "user_tz": 300,
     "elapsed": 4775,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    },
    "outputId": "287498b3-4357-4df2-ad08-04814ab411e0"
   },
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "from torchtext import data, datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Using device:', device) \n",
    "# if you want to use cuda, you should select \"GPU\" in the mean bar -> Runtime -> Change runtime type"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzQ8zDEi07l8"
   },
   "source": [
    "# Creating vectors, matrices and tensors as `Torch.Tensor`s\n",
    "\n",
    "We will now walk through a few simple examples, showing you how to use Torch.Tensor to implement one-dimensional vectors, two-dimensional matrices, and finally three-dimensional tensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scEXUbiX6HaP"
   },
   "source": [
    "A **vector** (e.g. [1, 25, 30, 6]) can be represented as a one-dimensional Tensor, which you can create by passing a list of numbers to the `torch.tensor(list)` constructor. \n",
    "\n",
    "\n",
    "The `shape` attribute of any Tensor is a tuple. In the case of a one-dimensional Tensor the `shape` tuple has a single argument, indicating how mamny elements the Tensor (vector) has.  \n",
    "\n",
    "A Tensor's `dtype` attribute tells you the data type (e.g. 64-bit integers) of its elements, and the `device` attribute tells you whether the Tensor is stored on a CPU or GPU. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2X9_0eCyIIz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576037,
     "user_tz": 300,
     "elapsed": 14,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "61ea22b2-45d4-46f0-9d97-b3ad429cac2f"
   },
   "source": [
    "# create a tensor from a list and print out its properties\n",
    "# start from a vector (one-dimensional)\n",
    "data = [1,25,30,6] # create a list \n",
    "x_data = torch.tensor(data) # use torch.tensor to create a tensor from a list\n",
    "print(f\"Tensor x_data:\\n {x_data}\")  #print out the tensor \n",
    "print(f\"Shape of tensor x_data: {x_data.shape}\") # read the size of the tensor\n",
    "print(f\"Datatype of tensor x_data: {x_data.dtype}\") # what kind of datatype this tensor is stored\n",
    "print(f\"Device tensor is stored on x_data: {x_data.device}\") # this tensor is stored on cpu/gpu"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x_data:\n",
      " tensor([ 1, 25, 30,  6])\n",
      "Shape of tensor x_data: torch.Size([4])\n",
      "Datatype of tensor x_data: torch.int64\n",
      "Device tensor is stored on x_data: cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZc1BVzQptdN"
   },
   "source": [
    "\n",
    "A **matrix** can be implemented as two-dimensional Torch tensor. To read in the elements of the matrix, we assume we are given a list of rows vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OWd7A5OR-Peu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576038,
     "user_tz": 300,
     "elapsed": 12,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "18bd00f2-cb43-4ce2-ebad-52ae86327102"
   },
   "source": [
    "# Let us create a 3x2 matrix, consisting of 3 rows and 2 columns\n",
    "data = [[1, 2],[3, 4], [5,6]] # To create a matrix with specific elements, we need a list of row vectors. \n",
    "x = torch.tensor(data) # use torch.tensor to create a tensor from a list\n",
    "print(f\"Tensor x:\\n {x}\")  #print out the tensor \n",
    "print(f\"Shape of Tensor x: {x.shape}\") # read the size of the tensor\n",
    "print(f\"Data type of Tensor x: {x.dtype}\") # what kind of datatype this tensor is stored\n",
    "print(f\"Device that tensor x_data is stored on: {x.device}\") # this tensor is stored on cpu/gpu"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x:\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "Shape of Tensor x: torch.Size([3, 2])\n",
      "Data type of Tensor x: torch.int64\n",
      "Device that tensor x_data is stored on: cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akdiKj67rGyb"
   },
   "source": [
    "Finally, we also show the case of a **tensor** (a three-dimensional Tensor). The third dimension is just one more dimension in addition to rows and columns. In other words, if you consider a two dimensional matrix as a list inside a list (two layers), then a three dimensional one has three such layers of lists."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IopgFdJV-MTG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576038,
     "user_tz": 300,
     "elapsed": 11,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "eb51985b-5981-4e9b-b662-1b27091881df"
   },
   "source": [
    "# three dimensional matrix\n",
    "data = [[[1, 2],[3, 4]], [[5,6], [7,8]]] # create a list with lists inside\n",
    "x_data = torch.tensor(data) # use torch.tensor to create a tensor from a list\n",
    "print(f\"The Tensor x_data:\\n {x_data}\") # print the content of this tensor\n",
    "print(f\"Shape of tensor x_data: {x_data.shape}\") # read the size of the tensor, we have three numbers here with three dims\n",
    "print(f\"Datatype of tensor x_data: {x_data.dtype}\") # what kind of datatype this tensor is stored\n",
    "print(f\"Device that tensor x_data is stored on: {x_data.device}\") # this tensor is stored on cpu/gpu\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tensor x_data:\n",
      " tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "Shape of tensor x_data: torch.Size([2, 2, 2])\n",
      "Datatype of tensor x_data: torch.int64\n",
      "Device that tensor x_data is stored on: cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5apwXHEZ0u4T"
   },
   "source": [
    "#### Conversion between Numpy Array and Tensor\n",
    "\n",
    "You can also convert a Numpy Array to a Tensor."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpNnFPKr0xk3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576038,
     "user_tz": 300,
     "elapsed": 10,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "1b44028e-32ba-45d5-8787-3e39c3b1ca6e"
   },
   "source": [
    "# create a tensor from a numpy array\n",
    "np_array = np.array(data)\n",
    "print(f\"The content of this numpy array: \\n{np_array}\\n\")\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(f\"Shape of this tensor: {x_np.shape}\\n\")\n",
    "# convert a tensor to a numpy array\n",
    "np_array_convert = x_np.numpy()\n",
    "print(f\"The content of this converted numpy array: \\n{np_array_convert}\\n\")"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of this numpy array: \n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "\n",
      "Shape of this tensor: torch.Size([2, 2, 2])\n",
      "\n",
      "The content of this converted numpy array: \n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMU97zzm0rMi"
   },
   "source": [
    "#### Create Tensors with Certain Properties\n",
    "\n",
    "Below we will create tensors with all 1's and random numbers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XG7tXmbQ044l",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576038,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "46a3bb9a-cc18-44cc-da40-68749526c3ae"
   },
   "source": [
    "# create tensors with certain properties (ones, random)\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data (shape here)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\") # we will get a matrix of all 1's\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data, but retains the shape\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\") # we will get a matrix of random numbers"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[[1, 1],\n",
      "         [1, 1]],\n",
      "\n",
      "        [[1, 1],\n",
      "         [1, 1]]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[[0.2414, 0.0142],\n",
      "         [0.9550, 0.1825]],\n",
      "\n",
      "        [[0.8004, 0.5913],\n",
      "         [0.3267, 0.4749]]]) \n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5gn7RHk1fDE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576039,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "96296fbc-1311-4bff-f2fa-61f5bfe0eb4b"
   },
   "source": [
    "# create tensors with a specific \"shape\" (it should be a tuple)\n",
    "shape = (2,5,) # if you leave it blank for the third dimension, the tensor will only be two-dimensional\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} with shape {rand_tensor.shape}\\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} with shape {rand_tensor.shape}\\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor} with shape {rand_tensor.shape}\")"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6392, 0.0895, 0.5743, 0.6727, 0.0131],\n",
      "        [0.1716, 0.5617, 0.3447, 0.0994, 0.4144]]) with shape torch.Size([2, 5])\n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]) with shape torch.Size([2, 5])\n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]) with shape torch.Size([2, 5])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIm0_Zmq1Wva"
   },
   "source": [
    "# Operations on Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlfMnSQ542-a"
   },
   "source": [
    "#### Indexing and Slicing\n",
    "How can we access and change parts of a given Tensor `tensor`? (For now we will assume the tensor is two-dimensional)\n",
    "\n",
    "**Accessing the content of a tensor:**\n",
    "*   Note that indices start at 0, not at 1!\n",
    "*  `tensor[i,j]` accesses the element in the row $i$ and  column $j$.\n",
    "* `tensor[i]` selects the $i^{th}$ row of a tensor's content. Note that we can ignore the columns (which are specified after the rows).\n",
    "* `tensor[:, i]` or `tensor[..., i]` selects the $i^{th}$ column  (Note that we now need to select all rows, because they are specified before the columns). We do this with  `:` or `...`). \n",
    "* If we have a tensor with higher dimensions, then we need to specify more numbers to get the part we need.\n",
    "\n",
    "\n",
    "**Changing the content of a tensor:**\n",
    "\n",
    "First, we identify the part of the tensor that we want to change. After that, we assign a new value to it using `tensor[i] = new_tensor` or `tensor[i] = new_scalar`. If we provide a new tensor, it needs to have a **same shape** as the selected part. A new scalar will change **all** elements in the selected part to that scalar."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-INNQtB1MYP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576039,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "517c477d-3546-4022-abb0-75401db12734"
   },
   "source": [
    "tensor = torch.rand(2, 4)\n",
    "print('THE INPUT TENSOR WITH SHAPE', tensor.shape, ':\\n\\n', tensor)\n",
    "print('\\nACCESSING ELEMENTS OF THIS TENSOR\\n')\n",
    "print('-- The element in the 1st row and 2nd column (note that indices start at 0): ', tensor[0,1])\n",
    "\n",
    "print('-- The first row:\\n\\t',  tensor[0], 'or\\n\\t', tensor[0, :], 'or\\n\\t', tensor[0,...]) # three different ways to access the first row\n",
    "\n",
    "print('-- The last column:\\n\\t', tensor[:,-1], 'or\\n\\t', tensor[..., -1]) # ... is the same as : for selecting all\n",
    "tensor[1, :] = 0\n",
    "\n",
    "print('\\nCHANGING ELEMENTS OF THIS TENSOR\\n\\n')\n",
    "print('-- Setting the last row to a zero vector:\\n\\t', tensor)\n",
    "tensor[1, :] = torch.tensor([1,2,3,4])\n",
    "print('-- Setting the last row to the the vector (1, 2, 3, 4):\\n\\t', tensor)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE INPUT TENSOR WITH SHAPE torch.Size([2, 4]) :\n",
      "\n",
      " tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [0.0212, 0.3728, 0.0770, 0.9166]])\n",
      "\n",
      "ACCESSING ELEMENTS OF THIS TENSOR\n",
      "\n",
      "-- The element in the 1st row and 2nd column (note that indices start at 0):  tensor(0.0759)\n",
      "-- The first row:\n",
      "\t tensor([0.7109, 0.0759, 0.9195, 0.8146]) or\n",
      "\t tensor([0.7109, 0.0759, 0.9195, 0.8146]) or\n",
      "\t tensor([0.7109, 0.0759, 0.9195, 0.8146])\n",
      "-- The last column:\n",
      "\t tensor([0.8146, 0.9166]) or\n",
      "\t tensor([0.8146, 0.9166])\n",
      "\n",
      "CHANGING ELEMENTS OF THIS TENSOR\n",
      "\n",
      "\n",
      "-- Setting the last row to a zero vector:\n",
      "\t tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "-- Setting the last row to the the vector (1, 2, 3, 4):\n",
      "\t tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yahQPz5K46Dy"
   },
   "source": [
    "#### Concatenate the Tensors: `torch.cat` & `torch.stack`\n",
    "\n",
    "- `torch.cat`: \n",
    "\n",
    "  - Concatenates a given sequence of tensors in the **given** dimension. **All** tensors must either have the **same shape** (except in the concatenating dimension) or be **empty**.\n",
    "  - *When to use this operation?* You have several tensors with same shapes (except the concatenating dim) and you want to **extend** the concatenating dim.\n",
    "\n",
    "\n",
    "- `torch.stack`: \n",
    "  - Concatenates a sequence of tensors along a **new** dimension (inserted at a particular location). **All** tensors need to be of the **same** size.\n",
    "  - *When to use this operation?* You have several tensors with exactly same sizes and you want to **add a new axis** so as to combine these tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fzbFj_R3N8M",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576039,
     "user_tz": 300,
     "elapsed": 8,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "a4f6c25e-db0a-4c41-be3a-e31741962c56"
   },
   "source": [
    "# cat: dim specifies which dimension we cat, it should be small than the dims of given tensor\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=0)  # we cat three tensors at existing dim=0, so dim=0 becomes 2*3=6\n",
    "print('THE INPUT TENSOR WITH SHAPE', tensor.shape, ':\\n\\n', tensor, '\\n')\n",
    "\n",
    "print('AFTER WE CONCATENATE THREE COPIES OF THIS TENSOR AT DIM=0 (rows): new shape =', t1.shape, '\\n\\n', t1, '\\n')\n",
    "\n",
    "t2 = torch.cat([tensor, tensor], dim=1)  # we cat three tensors at existing dim=1, so dim=1 becomes 4*2=8\n",
    "print('AFTER WE CONCATENATE TWO COPIES OF THIS TENSOR AT DIM=1 (columns): new shape =', t2.shape, '\\n\\n', t2)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE INPUT TENSOR WITH SHAPE torch.Size([2, 4]) :\n",
      "\n",
      " tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000]]) \n",
      "\n",
      "AFTER WE CONCATENATE THREE COPIES OF THIS TENSOR AT DIM=0 (rows): new shape = torch.Size([6, 4]) \n",
      "\n",
      " tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000],\n",
      "        [0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000],\n",
      "        [0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000]]) \n",
      "\n",
      "AFTER WE CONCATENATE TWO COPIES OF THIS TENSOR AT DIM=1 (columns): new shape = torch.Size([2, 8]) \n",
      "\n",
      " tensor([[0.7109, 0.0759, 0.9195, 0.8146, 0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000, 1.0000, 2.0000, 3.0000, 4.0000]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ow79U7P969x5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576039,
     "user_tz": 300,
     "elapsed": 7,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "1325735e-3692-41a2-e9f8-04e9762c3ee3"
   },
   "source": [
    "# stack: dim to insert. Has to be between 0 and the number of dims of concatenated tensors\n",
    "t0 = torch.stack([tensor, tensor, tensor], dim=0) # we stack three tensors at a new dim=0, them we have dim=0 with size 1*3=3\n",
    "t1 = torch.stack([tensor, tensor, tensor], dim=1) # we stack three tensors at a new dim=1, them we have dim=1 with size 1*3=3\n",
    "t2 = torch.stack([tensor, tensor, tensor], dim=2) # we stack three tensors at a new dim=2, them we have dim=2 with size 1*3=3\n",
    "print('THE INPUT TENSOR WITH SHAPE', tensor.shape, ':\\n\\n', tensor, '\\n')\n",
    "print('AFTER WE STACK THREE COPIES OF THIS TENSOR AT DIM=0: new shape=', t0.shape, '\\n\\n', t0, '\\n\\n')\n",
    "print('AFTER WE STACK THREE COPIES OF THIS TENSOR AT DIM=1: new shape=', t1.shape, '\\n\\n', t1, '\\n\\n')\n",
    "print('AFTER WE STACK THREE COPIES OF THIS TENSOR AT DIM=2: new shape=', t2.shape, '\\n\\n', t2)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE INPUT TENSOR WITH SHAPE torch.Size([2, 4]) :\n",
      "\n",
      " tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000]]) \n",
      "\n",
      "AFTER WE STACK THREE COPIES OF THIS TENSOR AT DIM=0: new shape= torch.Size([3, 2, 4]) \n",
      "\n",
      " tensor([[[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "         [1.0000, 2.0000, 3.0000, 4.0000]],\n",
      "\n",
      "        [[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "         [1.0000, 2.0000, 3.0000, 4.0000]],\n",
      "\n",
      "        [[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "         [1.0000, 2.0000, 3.0000, 4.0000]]]) \n",
      "\n",
      "\n",
      "AFTER WE STACK THREE COPIES OF THIS TENSOR AT DIM=1: new shape= torch.Size([2, 3, 4]) \n",
      "\n",
      " tensor([[[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "         [0.7109, 0.0759, 0.9195, 0.8146],\n",
      "         [0.7109, 0.0759, 0.9195, 0.8146]],\n",
      "\n",
      "        [[1.0000, 2.0000, 3.0000, 4.0000],\n",
      "         [1.0000, 2.0000, 3.0000, 4.0000],\n",
      "         [1.0000, 2.0000, 3.0000, 4.0000]]]) \n",
      "\n",
      "\n",
      "AFTER WE STACK THREE COPIES OF THIS TENSOR AT DIM=2: new shape= torch.Size([2, 4, 3]) \n",
      "\n",
      " tensor([[[0.7109, 0.7109, 0.7109],\n",
      "         [0.0759, 0.0759, 0.0759],\n",
      "         [0.9195, 0.9195, 0.9195],\n",
      "         [0.8146, 0.8146, 0.8146]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000],\n",
      "         [2.0000, 2.0000, 2.0000],\n",
      "         [3.0000, 3.0000, 3.0000],\n",
      "         [4.0000, 4.0000, 4.0000]]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJVtb5PV-BhT"
   },
   "source": [
    "#### Change the Shape of a Tensor: Squeeze/Unsqueeze, Permute, View, Transpose\n",
    "\n",
    "**`torch.squeeze`**: \n",
    "  - Returns a tensor with **all** the dimensions of input of **size 1 removed**. For example, if the input has a shape of $(A × 1 × B × 1 × C)$, then the ouput after squeezing should have a shape of $(A × B × C)$. We can also squeeze a specific dimension: if we squeeze `dim=1`, then the output will have a shape of $(A × B × 1 × C)$.\n",
    "  - *When to use this operation?* You want to remove all dims with size 1 and make the tensor more succinct.\n",
    "  - *CAREFUL*: the new tensor will share memory with the old tensor, so if you change an element of the new tensor, you will also change it in the old tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAtj9a_L-GDx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576408,
     "user_tz": 300,
     "elapsed": 375,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "59018bb5-9b43-4512-e790-15968cddc441"
   },
   "source": [
    "\n",
    "# Squeeze: if the input Tensor has the shape (A×1×B×C×1×D),  the output Tensor will have the shape (A×B×C×D)\n",
    "x = torch.rand(1) # initialize a tensor x\n",
    "y = torch.squeeze(x) # remove all dimensions that only have a single element\n",
    "print('INPUT VECTOR WITH SHAPE', x.shape, '\\n' , x)\n",
    "print('SQUEEZED VECTOR HAS SHAPE', y.shape, '\\n', y, '\\n\\n')\n",
    "\n",
    "\n",
    "x = torch.rand(1,1) # initialize a tensor x\n",
    "y = torch.squeeze(x) # remove all dimensions that only have a single element\n",
    "print('INPUT VECTOR WITH SHAPE', x.shape, '\\n' , x)\n",
    "print('SQUEEZED VECTOR HAS SHAPE', y.shape, '\\n', y, '\\n\\n')\n",
    "\n",
    "x = torch.rand(2, 1) # initialize a tensor x\n",
    "y = torch.squeeze(x) # remove all dimensions that only have a single element\n",
    "print('INPUT VECTOR WITH SHAPE', x.shape, '\\n' , x)\n",
    "print('SQUEEZED VECTOR HAS SHAPE', y.shape, '\\n', y, '\\n\\n')\n",
    "\n",
    "x = torch.rand(1, 2) # initialize a tensor x\n",
    "y = torch.squeeze(x)\n",
    "print('INPUT VECTOR WITH SHAPE', x.shape, '\\n' , x)\n",
    "print('SQUEEZED VECTOR HAS SHAPE', y.shape, '\\n', y, '\\n\\n')\n",
    "\n",
    "\n",
    "x = torch.rand(2, 1, 2, 1) # initialize a tensor x\n",
    "print('INPUT VECTOR WITH SHAPE', x.shape)\n",
    "y = torch.squeeze(x) # let's remove all dimensions that only have a single element\n",
    "print('SQUEEZED VECTOR HAS SHAPE', y.shape)\n",
    "y = torch.squeeze(x, 1) #  now let's delete dim=1\n",
    "print('SQUEEZED VECTOR (dim=1) HAS SHAPE=', y.shape)\n",
    "y = torch.squeeze(x, 3) #  now let's delete dim=1\n",
    "print('SQUEEZED VECTOR (dim=3) HAS SHAPE=', y.shape)\n"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT VECTOR WITH SHAPE torch.Size([1]) \n",
      " tensor([0.4988])\n",
      "SQUEEZED VECTOR HAS SHAPE torch.Size([]) \n",
      " tensor(0.4988) \n",
      "\n",
      "\n",
      "INPUT VECTOR WITH SHAPE torch.Size([1, 1]) \n",
      " tensor([[0.8130]])\n",
      "SQUEEZED VECTOR HAS SHAPE torch.Size([]) \n",
      " tensor(0.8130) \n",
      "\n",
      "\n",
      "INPUT VECTOR WITH SHAPE torch.Size([2, 1]) \n",
      " tensor([[0.6143],\n",
      "        [0.2857]])\n",
      "SQUEEZED VECTOR HAS SHAPE torch.Size([2]) \n",
      " tensor([0.6143, 0.2857]) \n",
      "\n",
      "\n",
      "INPUT VECTOR WITH SHAPE torch.Size([1, 2]) \n",
      " tensor([[0.5680, 0.9584]])\n",
      "SQUEEZED VECTOR HAS SHAPE torch.Size([2]) \n",
      " tensor([0.5680, 0.9584]) \n",
      "\n",
      "\n",
      "INPUT VECTOR WITH SHAPE torch.Size([2, 1, 2, 1])\n",
      "SQUEEZED VECTOR HAS SHAPE torch.Size([2, 2])\n",
      "SQUEEZED VECTOR (dim=1) HAS SHAPE= torch.Size([2, 2, 1])\n",
      "SQUEEZED VECTOR (dim=3) HAS SHAPE= torch.Size([2, 1, 2])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIc2p7Me0opV"
   },
   "source": [
    "**`torch.unsqueeze`:**\n",
    "  - Returns a new tensor with **a** dimension of size **one** inserted at the **specified** position. This operation is the opposite of `torch.squeeze`. For example, if we have an input tensor with shape $(A × B × C)$ and we want to have unsqueezing operation with dim=1, then we will get the output with shape $(A × 1 × B × C)$.\n",
    "  - *When to use this operation?* When you want to add a dim to the current tensor. It is really useful when you want to setup a batch with individual datapoints."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdrksR7N0bny",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576408,
     "user_tz": 300,
     "elapsed": 11,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "a9f52b08-70a0-42f7-9f0e-9fa221720583"
   },
   "source": [
    "# Unsqueeze: create a new tensor with a dim of size \"1\" inserted at the specified position\n",
    "x = torch.tensor([[1, 2, 3], [1,2,3]])\n",
    "print('INPUT VECTOR WITH SHAPE=', x.shape, '\\n' , x)\n",
    "y = torch.unsqueeze(x,0) \n",
    "print('UNSQUEEZED VECTOR (DIM=0) HAS SHAPE', y.shape, '\\n', y, '\\n\\n')\n",
    "y = torch.unsqueeze(x, 1)\n",
    "print('UNSQUEEZED VECTOR (DIM=1) HAS SHAPE', y.shape, '\\n', y, '\\n\\n')\n",
    "y = torch.unsqueeze(x, 2)\n",
    "print('UNSQUEEZED VECTOR (DIM=2) HAS SHAPE', y.shape, '\\n', y, '\\n\\n')\n",
    "#print(torch.unsqueeze(x, 2)) # error: out of range, so just [-dim-1, dim+1] (dim is for the original tensor)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT VECTOR WITH SHAPE= torch.Size([2, 3]) \n",
      " tensor([[1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "UNSQUEEZED VECTOR (DIM=0) HAS SHAPE torch.Size([1, 2, 3]) \n",
      " tensor([[[1, 2, 3],\n",
      "         [1, 2, 3]]]) \n",
      "\n",
      "\n",
      "UNSQUEEZED VECTOR (DIM=1) HAS SHAPE torch.Size([2, 1, 3]) \n",
      " tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[1, 2, 3]]]) \n",
      "\n",
      "\n",
      "UNSQUEEZED VECTOR (DIM=2) HAS SHAPE torch.Size([2, 3, 1]) \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[1],\n",
      "         [2],\n",
      "         [3]]]) \n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pomf_5BSvbiV"
   },
   "source": [
    "**`permute`:**\n",
    "  - This creates a **rotated** copy of the original tensor in which the dimensions (0,1,3,...) of the original tensor are arranged according to the **desired ordering**.  For example, if we have a tensor with shape $(A × B × C)$ and we apply permutation $(1, 2, 0)$, then the tensor will change into $(B × C × A)$.\n",
    "  - You can use this operation to align tensors that have dimensions $(AxBxC)$ and $(CxAxB)$ so that you can then concatenate them: Use *Tensor.permute* to create a copy of the second tensor that has the same dimensions as the first before concatenation. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItuNg5NVAJze",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576408,
     "user_tz": 300,
     "elapsed": 10,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "65f2ad0b-f279-41ba-a429-392eece4fbf3"
   },
   "source": [
    "# Permute: change the orders of the orginal tensor, according to the given order\n",
    "x = torch.randn(0, 1, 2, 3, 4, 5) # Let us create a random tensor where the i-th dimension has size i:\n",
    "print('INPUT VECTOR: SHAPE=', x.shape)\n",
    "# We create a permuted copy of tensor x.\n",
    "y1 = x.permute(0, 1, 3, 2, 5, 4) # 2->dim0, 3->dim1, 1->dim2, 4->dim3, 6->dim4, 5->dim5\n",
    "print('PERMUTING DIMENSIONS  2 and 3, and 4 and 5:',y1.shape)\n",
    "# And now we create a second copy that reverses this permutation: \n",
    "y2 = y1.permute((0,1,3,2,5,4)) # 2->dim0, 3->dim1, 1->dim2, 4->dim3, 6->dim4, 5->dim5, use a tuple here\n",
    "print('PERMUTING DIMENSIONS 2 and 3 and 4 and 5 again: ',y2.shape, '\\n')"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT VECTOR: SHAPE= torch.Size([0, 1, 2, 3, 4, 5])\n",
      "PERMUTING DIMENSIONS  2 and 3, and 4 and 5: torch.Size([0, 1, 3, 2, 5, 4])\n",
      "PERMUTING DIMENSIONS 2 and 3 and 4 and 5 again:  torch.Size([0, 1, 2, 3, 4, 5]) \n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqGdRx51veA4"
   },
   "source": [
    "**`view`**: \n",
    "  - Returns a new tensor with the **same data** (and the same number of elements) as the **original tensor**, but of a **different shape**. For example, we can use this function to change a tensor with shape $(2, 8)$ into the shape $(4, 4)$.\n",
    "  - This operation can only be used if the resulting tensor has the same number of elements as the input tensor ($4 \\cdot 4 = 2 \\cdot 8 = 16$).\n",
    "  - *When to use this operation?* You want to change the shape of a tensor but want it to still the same data. This is very similar to `numpy.reshape` operation and we will also show it as follows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m91cmjbsdI27",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576409,
     "user_tz": 300,
     "elapsed": 10,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "9289ec12-5055-4d16-8d0e-4d01f08ac7eb"
   },
   "source": [
    "# View example in pytorch\n",
    "print('-------------Example of view() in PyTorch-------------')\n",
    "x = torch.randn(4, 4) # a random tensor with shape (4,4)\n",
    "print('Content of x:', tensor)\n",
    "print('Shape of x:', tensor.shape, '\\n')\n",
    "y = x.view(16) # it is like flatten x to y, and y will have shape (16,) (one dimensional)\n",
    "print('Shape of tensor y with only one dimension:', y.shape)\n",
    "# -1 here means after making second dim with size 8, it will just make the first dim with size 2\n",
    "# It is helpful since we do not need to calculate the number manually\n",
    "z = x.view(-1, 8) \n",
    "print('Shape of tensor z after view operation:', z.shape, '\\n')\n",
    "\n",
    "# Numpy reshape example\n",
    "print('-------------Example of reshape() in Numpy-------------')\n",
    "# first we initialize a numpy array with shape (4,4) of random integers between the interval (0,100)\n",
    "x = np.random.randint(0, 100, (4, 4)) \n",
    "print('Content of numpy array x:', tensor)\n",
    "print('Shape of numpy array x:', x.shape)\n",
    "x = x.reshape(2,8) # do the reshape operation\n",
    "print('Shape of x after reshape operation:', x.shape)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Example of view() in PyTorch-------------\n",
      "Content of x: tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000]])\n",
      "Shape of x: torch.Size([2, 4]) \n",
      "\n",
      "Shape of tensor y with only one dimension: torch.Size([16])\n",
      "Shape of tensor z after view operation: torch.Size([2, 8]) \n",
      "\n",
      "-------------Example of reshape() in Numpy-------------\n",
      "Content of numpy array x: tensor([[0.7109, 0.0759, 0.9195, 0.8146],\n",
      "        [1.0000, 2.0000, 3.0000, 4.0000]])\n",
      "Shape of numpy array x: (4, 4)\n",
      "Shape of x after reshape operation: (2, 8)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhthYDjYvlMk"
   },
   "source": [
    "- `torch.transpose`: \n",
    "  - Returns a tensor that is a **transposed** version of input. The given dimensions `dim0` and `dim1` are **swapped**. For example, $\\begin{bmatrix}\n",
    "   0 & -1 & 1 \\\\\n",
    "   1 & -1 & 0 \\\\\n",
    "   -1 & 2 & 1 \n",
    "\\end{bmatrix}^{\\top} = \\begin{bmatrix}\n",
    "   0 & 1 & -1 \\\\\n",
    "   -1 & -1 & 2 \\\\\n",
    "   1 & 0 & 1 \n",
    "\\end{bmatrix}$\n",
    "  - *When to use this operation?* You may want to transpose a matrix to prepare for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EK27pTRWwJUg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576409,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "c873485f-72f0-4aba-b1af-fea776ab1611"
   },
   "source": [
    "# torch.transpose: transposed version of input\n",
    "tensor = torch.tensor([[0,-1,1], [1,-1,0], [-1,2,1]]) # initializa a tensor same as the example above\n",
    "print('Content of tensor:', tensor)\n",
    "print('Shape of tensor:', tensor.shape, '\\n')\n",
    "print('Content of the output after the transpose operation:\\n', torch.transpose(tensor,0,1), '\\n')\n",
    "x = torch.randn(2, 3, 4)\n",
    "print('The shape of x:', x.shape, '\\n')\n",
    "# We have swapped the dim0 & dim2 to y.\n",
    "# Only two dimension can be swapped, no matter how many dimension x originally has.\n",
    "y = torch.transpose(x, 0, 2) \n",
    "print('The shape of y:', y.shape, '\\n')\n"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of tensor: tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]])\n",
      "Shape of tensor: torch.Size([3, 3]) \n",
      "\n",
      "Content of the output after the transpose operation:\n",
      " tensor([[ 0,  1, -1],\n",
      "        [-1, -1,  2],\n",
      "        [ 1,  0,  1]]) \n",
      "\n",
      "The shape of x: torch.Size([2, 3, 4]) \n",
      "\n",
      "The shape of y: torch.Size([4, 3, 2]) \n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUP46Dmk5Gt4"
   },
   "source": [
    "#### Arithmetic Operations\n",
    "- *Matrix addition*: You can use either `+` or `torch.add(t1, t2)` between two tensors. Either operation gives you the same output.\n",
    "- *Matrix multiplication*: You can use either `@` or `matmul` between two tensors.  Either operation gives you the same output.\n",
    "- *Element-wise product*: You can use either `*` or `mul` between two tensors.  Either operation gives you the same output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnnZ7-M63hxN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576409,
     "user_tz": 300,
     "elapsed": 8,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "feebb5cc-3792-4f4b-c83b-414ba44539c1"
   },
   "source": [
    "# matrix addition (+ and torch.add())\n",
    "print('Input tensor tensor:\\n', {tensor})\n",
    "\n",
    "print('-------------Matrix addition-------------')\n",
    "print(f\"Adding the following 2D tensor to itself\\n {tensor}\\n + {tensor}\")\n",
    "y1 = tensor + tensor\n",
    "print(\"tensor + tensor:\\n\", y1, '\\n')\n",
    "y2 = torch.add(tensor, tensor)\n",
    "print(\"Test if + gives the same result as tensor.add():\", torch.equal(y1, y2), '\\n')\n",
    "\n",
    "# matrix multiplication (@ and tensor.matmul())\n",
    "print('-------------Matrix multiplication-------------')\n",
    "print('Multiplying a 2D tensor with its transpose tensor.T')\n",
    "print('tensor\\n', tensor)\n",
    "print('tensor transpose\\n', tensor.T)\n",
    "y1 = tensor @ tensor.T  # matrix mul\n",
    "print(\"tensor @ tensor:\\n\", y1, '\\n')\n",
    "y2 = tensor.matmul(tensor.T) # matrix mul\n",
    "print(\"Test if @ gives the same results as tensor.matmul():\", torch.equal(y1, y2), '\\n')\n",
    "\n",
    "\n",
    "# This computes the element-wise product (* and tensor.mult())\n",
    "print('-------------Matrix element-wise product-------------')\n",
    "print('Elementwise multiplication of a tensor with itself:')\n",
    "print('tensor\\n', tensor)\n",
    "z1 = tensor * tensor # ele-wise product\n",
    "print(\"tensor * tensor\\n\", z1, '\\n')\n",
    "z2 = tensor.mul(tensor) # ele-wise product\n",
    "print(\"Test if * gives the same result as tensor.mul():\", torch.equal(z1, z2))"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor tensor:\n",
      " {tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]])}\n",
      "-------------Matrix addition-------------\n",
      "Adding the following 2D tensor to itself\n",
      " tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]])\n",
      " + tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]])\n",
      "tensor + tensor:\n",
      " tensor([[ 0, -2,  2],\n",
      "        [ 2, -2,  0],\n",
      "        [-2,  4,  2]]) \n",
      "\n",
      "Test if + gives the same result as tensor.add(): True \n",
      "\n",
      "-------------Matrix multiplication-------------\n",
      "Multiplying a 2D tensor with its transpose tensor.T\n",
      "tensor\n",
      " tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]])\n",
      "tensor transpose\n",
      " tensor([[ 0,  1, -1],\n",
      "        [-1, -1,  2],\n",
      "        [ 1,  0,  1]])\n",
      "tensor @ tensor:\n",
      " tensor([[ 2,  1, -1],\n",
      "        [ 1,  2, -3],\n",
      "        [-1, -3,  6]]) \n",
      "\n",
      "Test if @ gives the same results as tensor.matmul(): True \n",
      "\n",
      "-------------Matrix element-wise product-------------\n",
      "Elementwise multiplication of a tensor with itself:\n",
      "tensor\n",
      " tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]])\n",
      "tensor * tensor\n",
      " tensor([[0, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 4, 1]]) \n",
      "\n",
      "Test if * gives the same result as tensor.mul(): True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjhAvNJj64gy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576409,
     "user_tz": 300,
     "elapsed": 7,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "1272332f-b25a-42a2-8436-be4eafef0e9f"
   },
   "source": [
    "# sum/item/type\n",
    "print('Summing up all elements of tensor:\\n', tensor, '\\n')\n",
    "agg = tensor.sum() # get the sum of all elements of the tensor\n",
    "print('The sum of all elements of this tensor is 1x1 tensor: ', agg, '\\n') # a tensor with one element\n",
    "agg_item = agg.item() # item() will convert a tensor (single element) to a numerial value\n",
    "print('tensor.item() changes a tensor with single element to a scalar:', agg_item, '\\nCheck the type of the scalar:', type(agg_item))"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summing up all elements of tensor:\n",
      " tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]]) \n",
      "\n",
      "The sum of all elements of this tensor is 1x1 tensor:  tensor(2) \n",
      "\n",
      "tensor.item() changes a tensor with single element to a scalar: 2 \n",
      "Check the type of the scalar: <class 'int'>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GVTzl327AoU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632102576410,
     "user_tz": 300,
     "elapsed": 7,
     "user": {
      "displayName": "Julia Hockenmaier",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05170815012611082005"
     }
    },
    "outputId": "06f56a86-40fb-4842-b323-32f359488d48"
   },
   "source": [
    "# in-place operations\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5) # it will change all the elements in tensor itself by adding 5 to each.\n",
    "print(tensor)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, -1,  1],\n",
      "        [ 1, -1,  0],\n",
      "        [-1,  2,  1]]) \n",
      "\n",
      "tensor([[5, 4, 6],\n",
      "        [6, 4, 5],\n",
      "        [4, 7, 6]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH2d-Rkf6vw0"
   },
   "source": [
    "# Create a Neural Network\n",
    "\n",
    "Now we build a simple classical deep neural network model, which only has one convolutional layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf9S5nv62mpw"
   },
   "source": [
    "### Network Structure\n",
    "- We create a new class named `SimpleCNN`, which inherited from `nn.Module` (a built-in class from Pytorch).\n",
    "- The model below consists of an `__init__()` portion which is where you **include the layers and components of the neural network**. In our model, we have a convolutional layer denoted by `nn.Conv2d(...)`. We are dealing with an image dataset that is in a grayscale so we only need one channel going in, hence `in_channels=1`. We hope to get a nice representation of this layer, so we use `out_channels=32`. Kernel size is 3, and for the rest of parameters we use the default values which you can find [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d). \n",
    "- After the convolutional layer, we have a flatten operation on the incoming data, which will transform the tensor into a one-dimensional tensor by specifying the `start_dim` and `end_dim`. Here, we transform the tensor to a size of `(1, 26*26*32)`. If you would like to find out how to calculate those numbers refer to [this](https://pytorch.org/docs/stable/generated/torch.flatten.html?highlight=flatten#torch.flatten). \n",
    "- We use two back-to-back **dense layers** to the incoming data. Notice for `d1` we have a dimension 128 representing the size we want as output and `26*26*32` representing the dimension of the incoming data. In short, the dense layer transforms the input data into a specific dimension. The same applies for the second linear transformation (`d2`) where the dimension of the output of the previous linear layer was added as `in_features=128`, and `10` is just the size of the output which also corresponds to **the number of classes**.\n",
    "- After each one of those layers, we also apply an **activation function** such as `ReLU`. `ReLu` is a common and useful function for activation. The output has the same shape as the input. For prediction purposes, we then apply a `softmax` layer to the last transformation and return the output of that. If you want to know the math in these operations, you can search [Pytorch Doc](https://pytorch.org/docs/stable/index.html).\n",
    "- *Forword Pass* refers to the **calculation process**, values of the output layers from the inputs data. It's traversing through all neurons from first to last layer.\n",
    "- *Backward Pass* refers to the **counting changes in weights**, using **gradient descent algorithm **(or similar). Computation is made from last layer, backward to the first layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yw_ku9nz6MiZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110110683,
     "user_tz": 300,
     "elapsed": 269,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    }
   },
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channel=1): # default setting of channels to be 3 - color images\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # 28x28x1 => 26x26x32: why 26? (28-(3-1)=26), here we have stride=1, padding=0 (default setting)\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channels=32, kernel_size=3)\n",
    "        # we flatten as new num of channels*new_height*new_width with out dimension of 128\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        # another dense layer\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x, is_debug=True):\n",
    "        # 1x1(3)x28x28 => 1x32x26x26\n",
    "        if(is_debug):\n",
    "          print(\"The input of the convolutional layer has a shape of:\", x.shape, '\\n')\n",
    "        x = self.conv1(x)\n",
    "        if(is_debug):\n",
    "          print(\"The output of the convolutional layer has a shape of:\", x.shape, '\\n')\n",
    "        x = F.relu(x) \n",
    "        if(is_debug):\n",
    "          print(\"The output of the ReLU activation has a shape of:\", x.shape, '\\n')\n",
    "        # flatten => 1 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        if(is_debug):\n",
    "          print(\"The output of the flatten operation has a shape of:\", x.shape, '\\n')\n",
    "        # 1 x (32*26*26) => 1 x 128\n",
    "        x = self.d1(x)\n",
    "        if(is_debug):\n",
    "          print(\"The output of the first dense layer has a shape of:\", x.shape, '\\n')\n",
    "        x = F.relu(x)\n",
    "        if(is_debug):\n",
    "          print(\"The output of the ReLU activation has a shape of:\", x.shape, '\\n')\n",
    "        # logits => 1 x10\n",
    "        logits = self.d2(x)\n",
    "        if(is_debug):\n",
    "          print(\"The output of the second dense layer has a shape of:\", logits.shape, '\\n')\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        if(is_debug):\n",
    "          print(\"The output of the softmax operation has a shape of:\", out.shape, '\\n')\n",
    "        return out"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAdZEuxwxQT6"
   },
   "source": [
    "### A Simple Test Case\n",
    "MNIST contains grayscale images that have a height/width of 28x28 pixels.\n",
    "Grayscale images have only a single color channel (RGB color images would have three color channels). \n",
    "Each individual image can therefore be represented as a `(1,28,28)` tensor.\n",
    "But since we typically want to represent a set of images, we use a tensor whose first dimension we can use to index each image. \n",
    "So, even though we first want to just read in a single image, we use a tensor of shape `(1, 1, 28, 28)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cj5XIx4eG-r_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110113476,
     "user_tz": 300,
     "elapsed": 67,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    },
    "outputId": "d3741c0b-d215-4774-d308-9ebbeeea727b"
   },
   "source": [
    "# a simple test case with a grayscale image\n",
    "input_image = torch.rand((1, 1, 28, 28)) # (num_img, num_channel=1, height, width)\n",
    "CNN = SimpleCNN(in_channel=1)\n",
    "print('Final output shape:', CNN(input_image).shape) # the output shape should be (1,10)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input of the convolutional layer has a shape of: torch.Size([1, 1, 28, 28]) \n",
      "\n",
      "The output of the convolutional layer has a shape of: torch.Size([1, 32, 26, 26]) \n",
      "\n",
      "The output of the ReLU activation has a shape of: torch.Size([1, 32, 26, 26]) \n",
      "\n",
      "The output of the flatten operation has a shape of: torch.Size([1, 21632]) \n",
      "\n",
      "The output of the first dense layer has a shape of: torch.Size([1, 128]) \n",
      "\n",
      "The output of the ReLU activation has a shape of: torch.Size([1, 128]) \n",
      "\n",
      "The output of the second dense layer has a shape of: torch.Size([1, 10]) \n",
      "\n",
      "The output of the softmax operation has a shape of: torch.Size([1, 10]) \n",
      "\n",
      "Final output shape: torch.Size([1, 10])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZvli4LIlZh0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110117012,
     "user_tz": 300,
     "elapsed": 101,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    },
    "outputId": "11e7a64b-671f-487b-ee28-c043ceb67dfd"
   },
   "source": [
    "# a simple test case with a color image\n",
    "input_image = torch.rand((1, 3, 28, 28)) # (num_img, num_channel=3, height, width)\n",
    "CNN = SimpleCNN(in_channel=3)\n",
    "print('Final output shape:', CNN(input_image).shape) # the output shape should be (1,10)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input of the convolutional layer has a shape of: torch.Size([1, 3, 28, 28]) \n",
      "\n",
      "The output of the convolutional layer has a shape of: torch.Size([1, 32, 26, 26]) \n",
      "\n",
      "The output of the ReLU activation has a shape of: torch.Size([1, 32, 26, 26]) \n",
      "\n",
      "The output of the flatten operation has a shape of: torch.Size([1, 21632]) \n",
      "\n",
      "The output of the first dense layer has a shape of: torch.Size([1, 128]) \n",
      "\n",
      "The output of the ReLU activation has a shape of: torch.Size([1, 128]) \n",
      "\n",
      "The output of the second dense layer has a shape of: torch.Size([1, 10]) \n",
      "\n",
      "The output of the softmax operation has a shape of: torch.Size([1, 10]) \n",
      "\n",
      "Final output shape: torch.Size([1, 10])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgVP00CXxZRz"
   },
   "source": [
    "### Train/Test a Neural Network in Pytorch\n",
    "We use training and testing data of MINIST dataset to make you become familiar with the process of training a network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpwzmBRh5FO9"
   },
   "source": [
    "#### Prepare MNIST Data\n",
    "\n",
    "The first step before training the model is to import the data. We will use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) which is frequently used in deep learning.\n",
    "\n",
    "Apart from importing the data, we will also do a few more things:\n",
    "- We will **tranform** the data into tensors using the `transforms` module.\n",
    "- We will use `DataLoader` to build **convenient data loaders** in Pytorch, which makes it easy to efficiently feed data in batches to the neural network. We will create **batches** of the data by setting the `batch` parameter inside the data loader. Notice we use batches of `32` in this tutorial but you can change it to other values if you like. We encourage you to experiment with different batch size values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9wNjTldaeOGK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110119657,
     "user_tz": 300,
     "elapsed": 294,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    }
   },
   "source": [
    "BATCH_SIZE = 32 # here we set the batch size to 32\n",
    "\n",
    "# transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "# download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQS9bSdA6b_n"
   },
   "source": [
    "#### Before Training the Model\n",
    "We need to first set up a **loss function**, an **optimizer** and a function to **compute the accuracy** of the model. \n",
    "- Loss Function: cross entropy loss\n",
    "- Optimizer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8mEeU2ho6Z1e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110125373,
     "user_tz": 300,
     "elapsed": 79,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    }
   },
   "source": [
    "learning_rate = 0.001 # specify learning rate for the optimizer\n",
    "num_epochs = 5 # training epochs\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device is to determine where the model\n",
    "print('Using device:', device)\n",
    "print('torch.cuda.is_available():', torch.cuda.is_available())\n",
    "\n",
    "# will be trained on\n",
    "model = SimpleCNN() # instantiate a object\n",
    "model = model.to(device) # move the model to GPU (if we have)\n",
    "criterion = nn.CrossEntropyLoss() # we use cross entropy loss here, which is common in classfication task\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # use Adam optimizer which is also useful"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "torch.cuda.is_available(): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kulbir/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA GeForce RTX 3060 Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3060 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0qdC3ZE97oxy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110126558,
     "user_tz": 300,
     "elapsed": 83,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    }
   },
   "source": [
    "# Accuracy Function: it is calculating the number of correct predictions in a batch\n",
    "def get_correct_num(logit, target):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum() # get the number of correct answers\n",
    "    return corrects.item() # here .item() will change the tensor into a number"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjJRQj_l75Sp"
   },
   "source": [
    "#### Training and Testing\n",
    "- Training: We will train the model on training data for five epoches. For each epoch, we will print the accuracy  that this model has on the training fata."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JmR6789e8RDI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110227727,
     "user_tz": 300,
     "elapsed": 98689,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    },
    "outputId": "f775f743-9b6f-436d-f383-e542dfa7dbe1"
   },
   "source": [
    " for epoch in range(num_epochs):\n",
    "    # initialize the loss & correct count to record the training performance\n",
    "    train_running_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    # set the model to the training mode\n",
    "    model = model.train()\n",
    "\n",
    "    # training step\n",
    "    for i, (images, labels) in enumerate(trainloader): # loop through batches of the training data\n",
    "        \n",
    "        # here we copy the images and labels to the device where we are doing training (GPU if available)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass, we don't print out the debug info here\n",
    "        logits = model(images, False)\n",
    "        # after we get the logits (classification results), we use the criterion to compute the loss\n",
    "        loss = criterion(logits, labels)\n",
    "        # sets the gradients of all optimized torch.Tensor to zero\n",
    "        optimizer.zero_grad()\n",
    "        # this step will compute the gradiants of tensors in this network\n",
    "        loss.backward()\n",
    "\n",
    "        # update model params using the gradiants computed\n",
    "        optimizer.step()\n",
    "\n",
    "        # update training loss & correct count\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_correct += get_correct_num(logits, labels)\n",
    "\n",
    "    model.eval() # set the model to the evaluation mode (we don't update params of the network)\n",
    "    # print average loss and accuracy of the training data via correct counts / total num of the training data\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %2f' \\\n",
    "          %(epoch, train_running_loss / i, train_correct/len(trainloader.dataset)))    "
   ],
   "execution_count": 25,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     14\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# forward pass, we don't print out the debug info here\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# after we get the logits (classification results), we use the criterion to compute the loss\u001B[39;00m\n\u001B[1;32m     19\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(logits, labels)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36mSimpleCNN.forward\u001B[0;34m(self, x, is_debug)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(is_debug):\n\u001B[1;32m     15\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe input of the convolutional layer has a shape of:\u001B[39m\u001B[38;5;124m\"\u001B[39m, x\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(is_debug):\n\u001B[1;32m     18\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe output of the convolutional layer has a shape of:\u001B[39m\u001B[38;5;124m\"\u001B[39m, x\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    450\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    451\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    452\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfBEvqdC9Bvz"
   },
   "source": [
    "- Testing: We also compute the accuracy on the test set to see how well the model performs on the unseen data. As you can see below, our simple CNN model achieves a good performance on the MNIST classification task."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lsQoSGeQ9Daq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1632110230517,
     "user_tz": 300,
     "elapsed": 2422,
     "user": {
      "displayName": "Enyi Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje3egUt8mv75zF8qOSdnltStU7QCrdAykPbf4o=s64",
      "userId": "08621821819525398785"
     }
    },
    "outputId": "cc3e1724-1710-4167-cb21-f100a4b0ab86"
   },
   "source": [
    "test_correct = 0 # set the correct count to zero\n",
    "for i, (images, labels) in enumerate(testloader, 0): # loop through batches of testing data\n",
    "    # same as the training process; we copy the data to the specified device\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # forward pass: to get the classification results\n",
    "    outputs = model(images, False)\n",
    "    # here we do not need to update the network params; just count the correct number of classification\n",
    "    test_correct += get_correct_num(outputs, labels)\n",
    "\n",
    "# print test accuracy via correct number of classification / the total number of the testing data\n",
    "print('Test Accuracy: %2f'%( test_correct/len(testloader.dataset)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KXQLcqKJfB2"
   },
   "source": [
    "## The End\n",
    "\n",
    "Congrats! You have reached the end of this notebook. We hope you have understood the basic operations of Pytorch, the process of concstructing a neural network with detailed changes of the shape for each step,  as well as the process of training a CNN/DNN model. If you have any further questions about Pytorch, please feel free to read the following references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ2rDnK7Cf2Q"
   },
   "source": [
    "## References\n",
    "- [Pytorch Tutorials](https://pytorch.org/tutorials/)\n",
    "- [Pytorch Doc](https://pytorch.org/docs/stable/index.html)\n",
    "- [Forward and Backword Pass](https://stackoverflow.com/questions/36740533/what-are-forward-and-backward-passes-in-neural-networks)\n",
    "- [Another Useful Colab Notebook](https://colab.research.google.com/github/omarsar/pytorch_notebooks/blob/master/pytorch_quick_start.ipynb)"
   ]
  }
 ]
}
